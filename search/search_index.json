{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Kamaji Simulation Environment Kamaji is a flexible and extensible multi-agent simulation environment designed for research and development in autonomous systems, control theory, and coordination strategies. It enables the modeling of large-scale, heterogeneous agent systems with support for custom dynamics, control architectures, and interaction mechanisms like auctions or barrier functions. Kamaji is built for: Simulating realistic multi-agent behavior in 2D/3D space Testing control strategies like PID, CBF, geometric, or learned controllers Implementing and evaluating fairness-based coordination and resource allocation Running large simulations for urban air mobility (UAM), swarming, or multi-robot planning Features Modular Agent Architecture : Each agent can be assigned custom dynamics, goals, and control models. Controller Support : Includes PID, Control Barrier Functions (CBFs), and auction-based control allocation mechanisms. Simulation Core : A flexible time-stepped engine that supports integration with advanced control loops and interaction constraints. Real-time GUI (WIP) : PyQt-based interface for visualizing and interacting with simulations. Logging & Analysis : Integrated support for logging states and control inputs, with HDF5 export and analysis tools. Extensible Models : Easily add new dynamics, control types, or interaction rules. Project Structure kamaji/ \u251c\u2500\u2500 agent/ # Core agent logic and update routines \u251c\u2500\u2500 dynamics/ # Definitions for single/double integrators, unicycle models, etc. \u251c\u2500\u2500 controllers/ # PID, CBF, and geometric control implementations \u251c\u2500\u2500 simulation/ # Time-stepping simulator logic \u251c\u2500\u2500 auctions/ # Auction mechanisms for resource allocation and fairness \u251c\u2500\u2500 plotting/ # Tools for trajectory visualization \u251c\u2500\u2500 gui/ # PyQt-based interface (in development) \u251c\u2500\u2500 tools/ # Logging, ODE solvers, and utility functions Documentation Navigate the sidebar to learn about: Agent configuration and initialization Control schemes and switching logic Simulation loop and how to run batch experiments Auction-based fairness and coordination mechanisms API reference for customizing and extending the framework Getting Started To launch your first simulation: pip install -e . python examples/basic_simulation.py Or use the GUI: python kamaji/gui/gui_main.py Authors & Acknowledgments Created and maintained by Johnathan (Jack) Corbin With guidance from Georgia Tech's robotics and control faculty. Kamaji is inspired by the need for scalable, interpretable, and fair multi-agent coordination tools \u2014 and borrows its name from the many-armed boiler master in Spirited Away , who utilizes an army of sootballs to run a complex but beautifully organized machine.","title":"Home"},{"location":"#kamaji-simulation-environment","text":"Kamaji is a flexible and extensible multi-agent simulation environment designed for research and development in autonomous systems, control theory, and coordination strategies. It enables the modeling of large-scale, heterogeneous agent systems with support for custom dynamics, control architectures, and interaction mechanisms like auctions or barrier functions. Kamaji is built for: Simulating realistic multi-agent behavior in 2D/3D space Testing control strategies like PID, CBF, geometric, or learned controllers Implementing and evaluating fairness-based coordination and resource allocation Running large simulations for urban air mobility (UAM), swarming, or multi-robot planning","title":"Kamaji Simulation Environment"},{"location":"#features","text":"Modular Agent Architecture : Each agent can be assigned custom dynamics, goals, and control models. Controller Support : Includes PID, Control Barrier Functions (CBFs), and auction-based control allocation mechanisms. Simulation Core : A flexible time-stepped engine that supports integration with advanced control loops and interaction constraints. Real-time GUI (WIP) : PyQt-based interface for visualizing and interacting with simulations. Logging & Analysis : Integrated support for logging states and control inputs, with HDF5 export and analysis tools. Extensible Models : Easily add new dynamics, control types, or interaction rules.","title":"Features"},{"location":"#project-structure","text":"kamaji/ \u251c\u2500\u2500 agent/ # Core agent logic and update routines \u251c\u2500\u2500 dynamics/ # Definitions for single/double integrators, unicycle models, etc. \u251c\u2500\u2500 controllers/ # PID, CBF, and geometric control implementations \u251c\u2500\u2500 simulation/ # Time-stepping simulator logic \u251c\u2500\u2500 auctions/ # Auction mechanisms for resource allocation and fairness \u251c\u2500\u2500 plotting/ # Tools for trajectory visualization \u251c\u2500\u2500 gui/ # PyQt-based interface (in development) \u251c\u2500\u2500 tools/ # Logging, ODE solvers, and utility functions","title":"Project Structure"},{"location":"#documentation","text":"Navigate the sidebar to learn about: Agent configuration and initialization Control schemes and switching logic Simulation loop and how to run batch experiments Auction-based fairness and coordination mechanisms API reference for customizing and extending the framework","title":"Documentation"},{"location":"#getting-started","text":"To launch your first simulation: pip install -e . python examples/basic_simulation.py Or use the GUI: python kamaji/gui/gui_main.py","title":"Getting Started"},{"location":"#authors-acknowledgments","text":"Created and maintained by Johnathan (Jack) Corbin With guidance from Georgia Tech's robotics and control faculty. Kamaji is inspired by the need for scalable, interpretable, and fair multi-agent coordination tools \u2014 and borrows its name from the many-armed boiler master in Spirited Away , who utilizes an army of sootballs to run a complex but beautifully organized machine.","title":"Authors &amp; Acknowledgments"},{"location":"about/","text":"About Kamaji Kamaji is a flexible, research-focused simulation environment for multi-agent systems. It supports the development and testing of distributed control strategies, coordination algorithms, and fairness mechanisms for safety-critical domains such as Urban Air Mobility (UAM) and robotics. This page includes project development instructions, license terms, contact details, and citation information. Development Kamaji is an actively developed multi-agent simulation environment intended for research and experimentation. Contributions are welcome! How to Contribute Fork the repository on GitHub. Create a new feature branch: git checkout -b feature/your-feature-name Make your changes and commit with clear messages. Push your branch and open a pull request (PR) to the main branch. Code Guidelines Follow PEP8 for Python code style. Use type hints and clear docstrings. Test your changes when possible (unit test support coming soon). License Kamaji is released under the MIT License. You are free to use, modify, and distribute this software in accordance with the terms outlined in the LICENSE file. Contact We\u2019d love to hear from you! Whether you have questions, feature requests, bug reports, or want to contribute to the Kamaji project, here\u2019s how you can get in touch. Project Maintainer Johnathan (Jack) Corbin PhD Student, Georgia Institute of Technology Email: jcorbin33@gatech.edu GitHub: @JCorbin406 Bug Reports and Questions Please use the GitHub Issues page for: Bug reports Feature requests Usage questions Citation If you use Kamaji in your research or academic work, please cite it using the following BibTeX entry: @misc { kamaji2025 , author = {Jack Corbin} , title = {Kamaji: Multi-agent Simulation Environment for Research} , year = 2025 , howpublished = {GitHub} , url = {https://github.com/JCorbin406/kamaji} } Related Publications If Kamaji is part of a larger research project or publication, please also cite the associated paper(s): Corbin, J., Li, S.H.Q., and Rogers, J., \"Auction-Driven Fairness in Collision Avoidance for Urban Air Mobility Systems Using Control Barrier Functions\", Georgia Institute of Technology , 2025. How to Include This in LaTeX Copy the BibTeX snippet above into your .bib file and use: \\cite { kamaji2025 } in your LaTeX document. Thank you for supporting open-source simulation and collaborative research!","title":"About"},{"location":"about/#about-kamaji","text":"Kamaji is a flexible, research-focused simulation environment for multi-agent systems. It supports the development and testing of distributed control strategies, coordination algorithms, and fairness mechanisms for safety-critical domains such as Urban Air Mobility (UAM) and robotics. This page includes project development instructions, license terms, contact details, and citation information.","title":"About Kamaji"},{"location":"about/#development","text":"Kamaji is an actively developed multi-agent simulation environment intended for research and experimentation. Contributions are welcome!","title":"Development"},{"location":"about/#how-to-contribute","text":"Fork the repository on GitHub. Create a new feature branch: git checkout -b feature/your-feature-name Make your changes and commit with clear messages. Push your branch and open a pull request (PR) to the main branch.","title":"How to Contribute"},{"location":"about/#code-guidelines","text":"Follow PEP8 for Python code style. Use type hints and clear docstrings. Test your changes when possible (unit test support coming soon).","title":"Code Guidelines"},{"location":"about/#license","text":"Kamaji is released under the MIT License. You are free to use, modify, and distribute this software in accordance with the terms outlined in the LICENSE file.","title":"License"},{"location":"about/#contact","text":"We\u2019d love to hear from you! Whether you have questions, feature requests, bug reports, or want to contribute to the Kamaji project, here\u2019s how you can get in touch. Project Maintainer Johnathan (Jack) Corbin PhD Student, Georgia Institute of Technology Email: jcorbin33@gatech.edu GitHub: @JCorbin406","title":"Contact"},{"location":"about/#bug-reports-and-questions","text":"Please use the GitHub Issues page for: Bug reports Feature requests Usage questions","title":"Bug Reports and Questions"},{"location":"about/#citation","text":"If you use Kamaji in your research or academic work, please cite it using the following BibTeX entry: @misc { kamaji2025 , author = {Jack Corbin} , title = {Kamaji: Multi-agent Simulation Environment for Research} , year = 2025 , howpublished = {GitHub} , url = {https://github.com/JCorbin406/kamaji} }","title":"Citation"},{"location":"about/#related-publications","text":"If Kamaji is part of a larger research project or publication, please also cite the associated paper(s): Corbin, J., Li, S.H.Q., and Rogers, J., \"Auction-Driven Fairness in Collision Avoidance for Urban Air Mobility Systems Using Control Barrier Functions\", Georgia Institute of Technology , 2025.","title":"Related Publications"},{"location":"about/#how-to-include-this-in-latex","text":"Copy the BibTeX snippet above into your .bib file and use: \\cite { kamaji2025 } in your LaTeX document. Thank you for supporting open-source simulation and collaborative research!","title":"How to Include This in LaTeX"},{"location":"api/","text":"API Reference This section documents the main modules of the Kamaji simulation environment. View Agent class kamaji.agent.Agent Source code in kamaji/agent/agent.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 class Agent : def __init__ ( self , agent_config , t = 0.0 , dt = 0.01 , ** kwargs ): for key , value in kwargs . items (): setattr ( self , key , value ) self . budget = 1 self . _agent_config = agent_config self . manual_control_input = None self . _dt = dt self . _id = agent_config [ 'id' ] self . _state = agent_config [ 'initial_state' ] self . _state_list = list ( self . _state . keys ()) self . _state_history = pd . DataFrame ( columns = [ 'time' ] + self . _state_list ) self . _state_history . loc [ len ( self . _state_history )] = { 'time' : t } | self . _state self . assign_dynamics () self . assign_controller () self . _control_list = self . dynamics_model . control_variables () self . _control_history = pd . DataFrame ( columns = [ 'time' ] + self . _control_list ) # Validate control alignment required_controls = len ( self . _control_list ) if hasattr ( self , 'control_model' ) and isinstance ( self . control_model , dict ): provided = len ( self . control_model ) if required_controls != provided : raise ValueError ( f \"[Agent: { self . _id } ] Control mismatch: dynamics model expects { required_controls } controls \" f \"but controller provides { provided } .\" ) def assign_dynamics ( self ): model_map = { \"Unicycle\" : Unicycle , \"CruiseControl\" : CruiseControl , \"SingleIntegrator1DOF\" : SingleIntegrator1DOF , \"SingleIntegrator2DOF\" : SingleIntegrator2DOF , \"SingleIntegrator3DOF\" : SingleIntegrator3DOF , \"DoubleIntegrator1DOF\" : DoubleIntegrator1DOF , \"DoubleIntegrator2DOF\" : DoubleIntegrator2DOF , \"DoubleIntegrator3DOF\" : DoubleIntegrator3DOF , } model_name = self . _agent_config [ 'dynamics_model' ] if model_name not in model_map : raise NotImplementedError ( f \" { model_name } is not a valid dynamics model.\" ) self . dynamics_model = model_map [ model_name ]( self . _dt ) # def assign_controller(self): # controller_cfg = self._agent_config.get(\"controller\", {}) # if not isinstance(controller_cfg, dict): # raise ValueError(\"Controller must be a dictionary of control channels with 'type' fields.\") # self.control_model = {} # for ctrl_name, ctrl_data in controller_cfg.items(): # ctrl_type = ctrl_data[\"type\"] # if ctrl_type == \"Constant\": # val = ctrl_data[\"value\"] # self.control_model[ctrl_name] = lambda t, state, v=val: v # elif ctrl_type == \"PID\": # spec = ctrl_data.get(\"specs\", [])[0] # self.control_model[ctrl_name] = PID( # [spec[\"state\"]], # [spec[\"goal\"]], # [spec[\"kp\"]], # [spec[\"ki\"]], # [spec[\"kd\"]], # dt=self._dt # ) # else: # raise ValueError(f\"Unknown controller type '{ctrl_type}' for {ctrl_name}\") def assign_controller ( self ): controller_cfg = self . _agent_config . get ( \"controller\" , {}) if not isinstance ( controller_cfg , dict ): raise ValueError ( \"Controller must be a dictionary of control channels with 'type' and 'specs'.\" ) self . control_model = {} for ctrl_name , ctrl_data in controller_cfg . items (): ctrl_type = ctrl_data [ \"type\" ] specs = ctrl_data . get ( \"specs\" , []) if not isinstance ( specs , list ) or len ( specs ) != 1 : raise ValueError ( f \"[Agent: { self . _id } ] Controller ' { ctrl_name } ' must have a single-item specs list.\" ) spec = specs [ 0 ] if ctrl_type == \"Constant\" : if \"value\" not in spec : raise ValueError ( f \"Constant controller for ' { ctrl_name } ' must specify 'value'\" ) val = spec [ \"value\" ] self . control_model [ ctrl_name ] = lambda t , state , v = val : v elif ctrl_type == \"PID\" : required_keys = [ \"state\" , \"goal\" , \"kp\" , \"ki\" , \"kd\" ] if not all ( k in spec for k in required_keys ): raise ValueError ( f \"PID controller for ' { ctrl_name } ' must contain { required_keys } \" ) self . control_model [ ctrl_name ] = PID ( [ spec [ \"state\" ]], [ spec [ \"goal\" ]], [ spec [ \"kp\" ]], [ spec [ \"ki\" ]], [ spec [ \"kd\" ]], dt = self . _dt ) else : raise ValueError ( f \"Unknown controller type ' { ctrl_type } ' for { ctrl_name } \" ) def compute_control ( self , t ) -> np . ndarray : \"\"\" Compute the full control vector by combining per-channel control outputs. Args: t (float): Current simulation time. Returns: np.ndarray: Control vector of shape (n_controls,) \"\"\" current_state = self . _state # For backward compatibility, support legacy controller format if isinstance ( self . control_model , dict ): control_channels = sorted ( self . control_model . keys ()) control_vector = [] for channel in control_channels : controller = self . control_model [ channel ] val = controller . update ( t , current_state ) if hasattr ( controller , \"update\" ) else controller ( t , current_state ) if isinstance ( val , ( list , tuple , np . ndarray )): control_vector . extend ( np . asarray ( val ) . flatten ()) else : control_vector . append ( val ) return np . array ( control_vector ) else : # Fallback for legacy single controller return self . control_model . update ( t , current_state ) def compute_dynamics ( self , t , control_input : np . ndarray ) -> np . ndarray : return self . dynamics_model . dynamics ( t , self . _state , control_input ) def step ( self , t : float , control_input : np . ndarray ) -> None : self . _state_order = list ( self . _state . keys ()) state_vec = np . array ([ self . _state [ k ] for k in self . _state_order ]) def compute_dynamics ( t_local , y , u ): return self . dynamics_model . dynamics ( t_local , { k : y [ i ] for i , k in enumerate ( self . _state_order )}, u ) _ , new_state_vec = ode . rk4_step ( compute_dynamics , t , state_vec , control_input , self . _dt ) new_state_dict = { k : new_state_vec [ i ] for i , k in enumerate ( self . _state_order )} self . _state = new_state_dict self . _state_history . loc [ len ( self . _state_history )] = { 'time' : t } | self . _state control_row = { 'time' : t } control_row . update ({ name : control_input [ i ] for i , name in enumerate ( self . _control_list )}) self . _control_history . loc [ len ( self . _control_history )] = control_row def set_valuation ( self , fn : Callable ): self . valuation_fn = fn def set_marginal_valuation ( self , fn : Callable ): self . marginal_valuation_fn = fn def valuation ( self , x ): return self . valuation_fn ( x ) def marginal_valuation ( self , x ): return self . marginal_valuation_fn ( x ) @property def state ( self ): return self . _state @property def state_log ( self ): return self . _state_history @property def control_log ( self ): return self . _control_history compute_control ( t ) Compute the full control vector by combining per-channel control outputs. Parameters: t ( float ) \u2013 Current simulation time. Returns: ndarray \u2013 np.ndarray: Control vector of shape (n_controls,) Source code in kamaji/agent/agent.py 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def compute_control ( self , t ) -> np . ndarray : \"\"\" Compute the full control vector by combining per-channel control outputs. Args: t (float): Current simulation time. Returns: np.ndarray: Control vector of shape (n_controls,) \"\"\" current_state = self . _state # For backward compatibility, support legacy controller format if isinstance ( self . control_model , dict ): control_channels = sorted ( self . control_model . keys ()) control_vector = [] for channel in control_channels : controller = self . control_model [ channel ] val = controller . update ( t , current_state ) if hasattr ( controller , \"update\" ) else controller ( t , current_state ) if isinstance ( val , ( list , tuple , np . ndarray )): control_vector . extend ( np . asarray ( val ) . flatten ()) else : control_vector . append ( val ) return np . array ( control_vector ) else : # Fallback for legacy single controller return self . control_model . update ( t , current_state ) View Simulator class kamaji.simulation.simulator.Simulator A class to manage and run multi-agent simulations with configurable dynamics, control, and collision avoidance mechanisms. Includes support for agent tracking, control input updates, manual overrides, logging, and visualization. Attributes: sim_time ( float ) \u2013 Current simulation time. active_agents ( list ) \u2013 List of currently active agents. inactive_agents ( list ) \u2013 List of agents that have completed simulation. agent_ids ( set ) \u2013 Set of agent IDs in the simulation. verbose ( bool ) \u2013 Flag for printing debug/output information. plot ( SimulationPlotter ) \u2013 Visualization utility. logger ( SimulationLogger ) \u2013 Logging utility for simulation data. Source code in kamaji/simulation/simulator.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 class Simulator : \"\"\" A class to manage and run multi-agent simulations with configurable dynamics, control, and collision avoidance mechanisms. Includes support for agent tracking, control input updates, manual overrides, logging, and visualization. Attributes: sim_time (float): Current simulation time. active_agents (list): List of currently active agents. inactive_agents (list): List of agents that have completed simulation. agent_ids (set): Set of agent IDs in the simulation. verbose (bool): Flag for printing debug/output information. plot (SimulationPlotter): Visualization utility. logger (SimulationLogger): Logging utility for simulation data. \"\"\" def __init__ ( self , config = None ) -> None : \"\"\" Initialize the simulation with optional configuration parameters. Args: config (dict, optional): Dictionary containing simulation, agent, and logging parameters. \"\"\" self . _config = config self . _current_real_time = time () self . _elapsed_real_time = 0.0 self . sim_time = 0.0 self . active_agents = [] self . inactive_agents = [] self . agent_ids = set () self . verbose = True self . plot = SimulationPlotter ( self ) self . logging_params = config . get ( \"logging\" , {}) if config else {} self . logger = SimulationLogger ( self ) self . cbf_system = None # Will be set later, if needed if config is not None : self . load_from_config ( config ) else : if self . verbose : print ( \"No config provided, using default values.\" ) def set_cbf_system ( self , cbf_system ): \"\"\" Set an external CBF system to be used during simulation. Args: cbf_system (CBFSystem): A configured CBFSystem instance. \"\"\" self . cbf_system = cbf_system def set_sim_params ( self , sim_params = None ): \"\"\" Set core simulation parameters such as timestep, duration, and integration method. Args: sim_params (dict, optional): Dictionary with keys 'time_step', 'duration', and 'integrator'. Raises: ValueError: If required parameters are missing or invalid. TypeError: If parameter types are incorrect. \"\"\" if sim_params is None : self . dt = 0.01 self . duration = 10.0 self . num_timesteps = int ( self . duration / self . dt ) self . integrator = 'RK4' self . verbose = True return self . verbose = sim_params . get ( 'verbose' , True ) required = [ 'time_step' , 'duration' , 'integrator' ] missing = [ key for key in required if key not in sim_params ] if missing : raise ValueError ( f \"Missing simulation parameters: { missing } \" ) time_step = sim_params [ 'time_step' ] duration = sim_params [ 'duration' ] integrator = sim_params [ 'integrator' ] if not isinstance ( time_step , ( float , int )) or time_step <= 0 : raise ValueError ( \"'time_step' must be a positive number.\" ) if not isinstance ( duration , ( float , int )) or duration <= 0 : raise ValueError ( \"'duration' must be a positive, nonzero number.\" ) if not isinstance ( integrator , str ): raise TypeError ( \"'integrator' must be a string.\" ) valid_integrators = { 'RK4' , 'Euler' , 'RK2' , 'RK45' } if integrator not in valid_integrators : raise ValueError ( f \"Unsupported integrator ' { integrator } '. Valid options: { valid_integrators } \" ) self . dt = float ( time_step ) self . duration = float ( duration ) self . num_timesteps = max ( 1 , int ( self . duration / self . dt )) self . integrator = integrator def load_from_config ( self , config ): \"\"\" Load simulation parameters, agent configuration, environment, and logging settings. Args: config (dict): YAML-style configuration dictionary. \"\"\" self . set_sim_params ( config . get ( 'simulation' , {})) self . add_agents ( config . get ( 'agents' , {})) self . env_params = config . get ( 'environment' , {}) self . logging_params = config . get ( 'logging' , {}) def add_agents ( self , agents ) -> None : \"\"\" Add one or more agents to the simulation. Args: agents (dict | tuple | dict): Dictionary of agents, (config, id) tuple, or a single config. Raises: TypeError: If format of input is not recognized. \"\"\" if isinstance ( agents , dict ): if all ( isinstance ( v , dict ) for v in agents . values ()): for agent_id , agent_config in agents . items (): self . _add_single_agent ( agent_config , agent_id ) else : self . _add_single_agent ( agents ) elif isinstance ( agents , tuple ): if not isinstance ( agents [ 0 ], dict ) or not isinstance ( agents [ 1 ], str ): raise TypeError ( \"Expected (agent_config: dict, agent_id: str)\" ) self . _add_single_agent ( agents [ 0 ], agents [ 1 ]) else : raise TypeError ( \"Expected one of: dict of agents, (config, id) tuple, or single agent config dict.\" ) def _add_single_agent ( self , agent_config : dict , agent_id : Optional [ str ] = None ): \"\"\" Add a single agent with the provided configuration and optional ID. Args: agent_config (dict): Configuration dictionary for the agent. agent_id (str, optional): Explicit ID for the agent. Auto-generated if None. Raises: ValueError: If required fields are missing or types are invalid. RuntimeError: If the agent fails to initialize. \"\"\" required_fields = [ 'type' , 'initial_state' , 'dynamics_model' , 'controller' ] missing = [ k for k in required_fields if k not in agent_config ] if missing : raise ValueError ( f \"Missing required fields in agent config: { missing } \" ) if not isinstance ( agent_config [ 'initial_state' ], dict ): raise TypeError ( \"initial_state must be a dictionary.\" ) if not isinstance ( agent_config [ 'controller' ], dict ): raise TypeError ( \"controller must be a dictionary.\" ) controller_block = agent_config [ 'controller' ] if not isinstance ( controller_block , dict ): raise TypeError ( \"Controller block must be a dictionary of control channels.\" ) for ctrl_name , ctrl_conf in controller_block . items (): if not isinstance ( ctrl_conf , dict ): raise TypeError ( f \"Controller for ' { ctrl_name } ' must be a dict.\" ) if \"type\" not in ctrl_conf : raise ValueError ( f \"Controller ' { ctrl_name } ' must include a 'type' field.\" ) if \"specs\" not in ctrl_conf : raise ValueError ( f \"Controller ' { ctrl_name } ' must include a 'specs' field.\" ) if not isinstance ( ctrl_conf [ \"specs\" ], list ): raise TypeError ( f \"Controller ' { ctrl_name } ' 'specs' must be a list.\" ) if agent_id is None : base = \"agent\" i = 1 while f \" { base } _ { i } \" in self . agent_ids : i += 1 agent_id = f \" { base } _ { i } \" if agent_id in self . agent_ids : raise ValueError ( f \"Agent ID ' { agent_id } ' already exists.\" ) agent_config [ 'id' ] = agent_id try : self . active_agents . append ( Agent ( agent_config , self . sim_time , self . dt )) except Exception as e : raise RuntimeError ( f \"Failed to initialize Agent ' { agent_id } ': { e } \" ) self . agent_ids . add ( agent_id ) if self . verbose : print ( f \"[Simulator] Agent ' { agent_id } ' added.\" ) def simulate ( self , on_step = None ) -> None : \"\"\" Run the simulation loop for all time steps. Args: on_step (Callable[[Simulator, int], None], optional): Callback executed before each step. \"\"\" start_time = time () iterator = tqdm ( range ( self . num_timesteps ), desc = \"Simulating\" , unit = \"step\" ) if self . verbose else range ( self . num_timesteps ) for step_idx in iterator : if on_step : on_step ( self , step_idx ) self . step () self . sim_time = time () - start_time self . inactive_agents . extend ( self . active_agents ) self . active_agents . clear () if self . logging_params . get ( \"enabled\" , True ): if self . logging_params . get ( \"format\" , \"hdf5\" ) == \"hdf5\" : self . logger . log_to_hdf5 () if self . verbose : print ( f \"Sim time: { self . sim_time : .4f } \" ) def step ( self ) -> None : \"\"\" Advance the simulation by one time step, updating agent states using control input. \"\"\" state_values = {} all_controls = [] control_dims = [] # 1. Gather state values and nominal control for each agent for idx , agent in enumerate ( self . active_agents ): state_values [ f \"x { idx } \" ] = agent . state [ \"position_x\" ] state_values [ f \"y { idx } \" ] = agent . state [ \"position_y\" ] control = agent . manual_control_input if agent . manual_control_input is not None else agent . compute_control ( self . sim_time ) all_controls . append ( control ) control_dims . append ( len ( control )) u_nom = np . concatenate ( all_controls ) # 2. Filter full control vector using CBF system if available if self . cbf_system is not None : u_filtered = self . cbf_system . filter_controls ( state_values , u_nom , mode = \"all\" ) else : u_filtered = u_nom # 3. Slice filtered controls back to each agent and step them idx = 0 for agent , dim in zip ( self . active_agents , control_dims ): agent_control = u_filtered [ idx : idx + dim ] agent . step ( self . sim_time , agent_control ) idx += dim def clear_manual_control ( self , agent_id : str ) -> None : \"\"\" Clear any manually assigned control input for a specific agent. Args: agent_id (str): ID of the agent to clear manual control for. \"\"\" for agent in self . active_agents : if agent . _id == agent_id : agent . manual_control_input = None return def set_manual_control ( self , agent_id : str , control : np . ndarray ) -> None : \"\"\" Manually assign a control input to a specific agent. Args: agent_id (str): ID of the agent. control (np.ndarray): Manual control input. Raises: ValueError: If the agent ID is not found. \"\"\" for agent in self . active_agents : if agent . _id == agent_id : agent . manual_control_input = control if self . verbose : print ( f \"[Simulator] Manual control set for agent ' { agent_id } '.\" ) return raise ValueError ( f \"Agent with ID ' { agent_id } ' not found.\" ) def remove_agent ( self , agent : Agent ) -> bool : \"\"\" Remove an agent from the active list and move to the inactive list. Args: agent (Agent): The agent to be removed. Returns: bool: True if removal was successful. Raises: ValueError: If the agent is not in the active list. \"\"\" if agent not in self . active_agents : raise ValueError ( f \"Agent { agent . id } is not an active Agent.\" ) self . inactive_agents . append ( self . active_agents . pop ( self . active_agents . index ( agent ))) return True __init__ ( config = None ) Initialize the simulation with optional configuration parameters. Parameters: config ( dict , default: None ) \u2013 Dictionary containing simulation, agent, and logging parameters. Source code in kamaji/simulation/simulator.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 def __init__ ( self , config = None ) -> None : \"\"\" Initialize the simulation with optional configuration parameters. Args: config (dict, optional): Dictionary containing simulation, agent, and logging parameters. \"\"\" self . _config = config self . _current_real_time = time () self . _elapsed_real_time = 0.0 self . sim_time = 0.0 self . active_agents = [] self . inactive_agents = [] self . agent_ids = set () self . verbose = True self . plot = SimulationPlotter ( self ) self . logging_params = config . get ( \"logging\" , {}) if config else {} self . logger = SimulationLogger ( self ) self . cbf_system = None # Will be set later, if needed if config is not None : self . load_from_config ( config ) else : if self . verbose : print ( \"No config provided, using default values.\" ) add_agents ( agents ) Add one or more agents to the simulation. Parameters: agents ( dict | tuple | dict ) \u2013 Dictionary of agents, (config, id) tuple, or a single config. Raises: TypeError \u2013 If format of input is not recognized. Source code in kamaji/simulation/simulator.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 def add_agents ( self , agents ) -> None : \"\"\" Add one or more agents to the simulation. Args: agents (dict | tuple | dict): Dictionary of agents, (config, id) tuple, or a single config. Raises: TypeError: If format of input is not recognized. \"\"\" if isinstance ( agents , dict ): if all ( isinstance ( v , dict ) for v in agents . values ()): for agent_id , agent_config in agents . items (): self . _add_single_agent ( agent_config , agent_id ) else : self . _add_single_agent ( agents ) elif isinstance ( agents , tuple ): if not isinstance ( agents [ 0 ], dict ) or not isinstance ( agents [ 1 ], str ): raise TypeError ( \"Expected (agent_config: dict, agent_id: str)\" ) self . _add_single_agent ( agents [ 0 ], agents [ 1 ]) else : raise TypeError ( \"Expected one of: dict of agents, (config, id) tuple, or single agent config dict.\" ) clear_manual_control ( agent_id ) Clear any manually assigned control input for a specific agent. Parameters: agent_id ( str ) \u2013 ID of the agent to clear manual control for. Source code in kamaji/simulation/simulator.py 258 259 260 261 262 263 264 265 266 267 268 def clear_manual_control ( self , agent_id : str ) -> None : \"\"\" Clear any manually assigned control input for a specific agent. Args: agent_id (str): ID of the agent to clear manual control for. \"\"\" for agent in self . active_agents : if agent . _id == agent_id : agent . manual_control_input = None return load_from_config ( config ) Load simulation parameters, agent configuration, environment, and logging settings. Parameters: config ( dict ) \u2013 YAML-style configuration dictionary. Source code in kamaji/simulation/simulator.py 106 107 108 109 110 111 112 113 114 115 116 def load_from_config ( self , config ): \"\"\" Load simulation parameters, agent configuration, environment, and logging settings. Args: config (dict): YAML-style configuration dictionary. \"\"\" self . set_sim_params ( config . get ( 'simulation' , {})) self . add_agents ( config . get ( 'agents' , {})) self . env_params = config . get ( 'environment' , {}) self . logging_params = config . get ( 'logging' , {}) remove_agent ( agent ) Remove an agent from the active list and move to the inactive list. Parameters: agent ( Agent ) \u2013 The agent to be removed. Returns: bool ( bool ) \u2013 True if removal was successful. Raises: ValueError \u2013 If the agent is not in the active list. Source code in kamaji/simulation/simulator.py 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 def remove_agent ( self , agent : Agent ) -> bool : \"\"\" Remove an agent from the active list and move to the inactive list. Args: agent (Agent): The agent to be removed. Returns: bool: True if removal was successful. Raises: ValueError: If the agent is not in the active list. \"\"\" if agent not in self . active_agents : raise ValueError ( f \"Agent { agent . id } is not an active Agent.\" ) self . inactive_agents . append ( self . active_agents . pop ( self . active_agents . index ( agent ))) return True set_cbf_system ( cbf_system ) Set an external CBF system to be used during simulation. Parameters: cbf_system ( CBFSystem ) \u2013 A configured CBFSystem instance. Source code in kamaji/simulation/simulator.py 52 53 54 55 56 57 58 59 def set_cbf_system ( self , cbf_system ): \"\"\" Set an external CBF system to be used during simulation. Args: cbf_system (CBFSystem): A configured CBFSystem instance. \"\"\" self . cbf_system = cbf_system set_manual_control ( agent_id , control ) Manually assign a control input to a specific agent. Parameters: agent_id ( str ) \u2013 ID of the agent. control ( ndarray ) \u2013 Manual control input. Raises: ValueError \u2013 If the agent ID is not found. Source code in kamaji/simulation/simulator.py 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 def set_manual_control ( self , agent_id : str , control : np . ndarray ) -> None : \"\"\" Manually assign a control input to a specific agent. Args: agent_id (str): ID of the agent. control (np.ndarray): Manual control input. Raises: ValueError: If the agent ID is not found. \"\"\" for agent in self . active_agents : if agent . _id == agent_id : agent . manual_control_input = control if self . verbose : print ( f \"[Simulator] Manual control set for agent ' { agent_id } '.\" ) return raise ValueError ( f \"Agent with ID ' { agent_id } ' not found.\" ) set_sim_params ( sim_params = None ) Set core simulation parameters such as timestep, duration, and integration method. Parameters: sim_params ( dict , default: None ) \u2013 Dictionary with keys 'time_step', 'duration', and 'integrator'. Raises: ValueError \u2013 If required parameters are missing or invalid. TypeError \u2013 If parameter types are incorrect. Source code in kamaji/simulation/simulator.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 def set_sim_params ( self , sim_params = None ): \"\"\" Set core simulation parameters such as timestep, duration, and integration method. Args: sim_params (dict, optional): Dictionary with keys 'time_step', 'duration', and 'integrator'. Raises: ValueError: If required parameters are missing or invalid. TypeError: If parameter types are incorrect. \"\"\" if sim_params is None : self . dt = 0.01 self . duration = 10.0 self . num_timesteps = int ( self . duration / self . dt ) self . integrator = 'RK4' self . verbose = True return self . verbose = sim_params . get ( 'verbose' , True ) required = [ 'time_step' , 'duration' , 'integrator' ] missing = [ key for key in required if key not in sim_params ] if missing : raise ValueError ( f \"Missing simulation parameters: { missing } \" ) time_step = sim_params [ 'time_step' ] duration = sim_params [ 'duration' ] integrator = sim_params [ 'integrator' ] if not isinstance ( time_step , ( float , int )) or time_step <= 0 : raise ValueError ( \"'time_step' must be a positive number.\" ) if not isinstance ( duration , ( float , int )) or duration <= 0 : raise ValueError ( \"'duration' must be a positive, nonzero number.\" ) if not isinstance ( integrator , str ): raise TypeError ( \"'integrator' must be a string.\" ) valid_integrators = { 'RK4' , 'Euler' , 'RK2' , 'RK45' } if integrator not in valid_integrators : raise ValueError ( f \"Unsupported integrator ' { integrator } '. Valid options: { valid_integrators } \" ) self . dt = float ( time_step ) self . duration = float ( duration ) self . num_timesteps = max ( 1 , int ( self . duration / self . dt )) self . integrator = integrator simulate ( on_step = None ) Run the simulation loop for all time steps. Parameters: on_step ( Callable [[ Simulator , int ], None] , default: None ) \u2013 Callback executed before each step. Source code in kamaji/simulation/simulator.py 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 def simulate ( self , on_step = None ) -> None : \"\"\" Run the simulation loop for all time steps. Args: on_step (Callable[[Simulator, int], None], optional): Callback executed before each step. \"\"\" start_time = time () iterator = tqdm ( range ( self . num_timesteps ), desc = \"Simulating\" , unit = \"step\" ) if self . verbose else range ( self . num_timesteps ) for step_idx in iterator : if on_step : on_step ( self , step_idx ) self . step () self . sim_time = time () - start_time self . inactive_agents . extend ( self . active_agents ) self . active_agents . clear () if self . logging_params . get ( \"enabled\" , True ): if self . logging_params . get ( \"format\" , \"hdf5\" ) == \"hdf5\" : self . logger . log_to_hdf5 () if self . verbose : print ( f \"Sim time: { self . sim_time : .4f } \" ) step () Advance the simulation by one time step, updating agent states using control input. Source code in kamaji/simulation/simulator.py 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 def step ( self ) -> None : \"\"\" Advance the simulation by one time step, updating agent states using control input. \"\"\" state_values = {} all_controls = [] control_dims = [] # 1. Gather state values and nominal control for each agent for idx , agent in enumerate ( self . active_agents ): state_values [ f \"x { idx } \" ] = agent . state [ \"position_x\" ] state_values [ f \"y { idx } \" ] = agent . state [ \"position_y\" ] control = agent . manual_control_input if agent . manual_control_input is not None else agent . compute_control ( self . sim_time ) all_controls . append ( control ) control_dims . append ( len ( control )) u_nom = np . concatenate ( all_controls ) # 2. Filter full control vector using CBF system if available if self . cbf_system is not None : u_filtered = self . cbf_system . filter_controls ( state_values , u_nom , mode = \"all\" ) else : u_filtered = u_nom # 3. Slice filtered controls back to each agent and step them idx = 0 for agent , dim in zip ( self . active_agents , control_dims ): agent_control = u_filtered [ idx : idx + dim ] agent . step ( self . sim_time , agent_control ) idx += dim View Auction class kamaji.auctions.resource.Auction Source code in kamaji/auctions/resource.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 class Auction : def __init__ ( self , agents , Gamma , bids , alpha = 0.99 , rho_bar = 2 , rho = 0.5 , epsilon = 1e-4 ): \"\"\" Initialize the Auction class for decentralized divisible resource allocation. Args: agents (List[Agent]): List of Agent objects with valuation functions. Gamma (float): Total amount of divisible resource to allocate. bids (List[Tuple[float, float]]): Initial bids for each agent, in (\u03b2, d) format. alpha (float): Smoothing parameter for computing constrained demand. rho_bar (float): Upper bound on dynamic response term for constrained demand. rho (float): Smoothing factor for current demand vs. allocation. epsilon (float): Convergence threshold for bid updates. \"\"\" self . agents = agents self . N = len ( agents ) self . Gamma = Gamma self . alpha = alpha self . rho_bar = rho_bar self . rho = rho self . epsilon = epsilon self . bids = bids self . history = [ self . bids . copy ()] # Log of all bids over time def valuation ( self , n , x ): \"\"\"Returns the valuation u_n(x) of agent n at allocation x.\"\"\" return self . agents [ n ] . valuation ( x ) def marginal_valuation ( self , n , x ): \"\"\"Returns the marginal valuation u_n'(x) of agent n at allocation x.\"\"\" return self . agents [ n ] . marginal_valuation ( x ) def allocation ( self , bids ): \"\"\" Computes allocation vector from current bids using descending sort of \u03b2 with random tie-breaking. Args: bids (List[Tuple[float, float]]): Bids as list of (\u03b2, d) pairs. Returns: np.ndarray: Allocated resource vector x for all agents. \"\"\" indexed_bids = [( i , b [ 0 ], b [ 1 ], random . random ()) for i , b in enumerate ( bids )] beta_sorted = sorted ( indexed_bids , key = lambda x : ( - x [ 1 ], x [ 3 ])) x = np . zeros ( self . N ) remaining = self . Gamma for i , beta , d , _ in beta_sorted : x [ i ] = min ( d , remaining ) remaining -= x [ i ] if remaining <= 0 : break return x def payment ( self , bids , n ): \"\"\" Computes VCG payment for agent n using Clarke pivot rule. Args: bids (List[Tuple[float, float]]): Current bids. n (int): Agent index. Returns: float: Payment \u03c4_n agent n must pay. \"\"\" b_without_n = bids . copy () b_without_n [ n ] = ( bids [ n ][ 0 ], 0.0 ) x_without = self . allocation ( b_without_n ) return sum ( bids [ m ][ 0 ] * ( x_without [ m ] - self . x [ m ]) for m in range ( self . N ) if m != n ) def payoff ( self , n , bids ): \"\"\" Computes payoff for agent n given current bids. Args: n (int): Agent index. bids (List[Tuple[float, float]]): Bid profile. Returns: float: Payoff for agent n. \"\"\" x = self . allocation ( bids ) \u03c4 = self . payment ( bids , n ) return self . valuation ( n , x [ n ]) - \u03c4 def constrained_demand ( self , n , bids ): \"\"\" Computes upper bound for agent n's demand based on dynamic constraints. Args: n (int): Agent index. bids (List[Tuple[float, float]]): Bid profile. Returns: float: Constrained upper bound on agent n's demand. \"\"\" \u0393c = max ( 0 , self . Gamma - sum ( d for _ , d in bids )) \u03b2n , dn = bids [ n ] m = self . find_m ( n , bids ) dm = bids [ m ][ 1 ] if m is not None else 0 \u03b2m = bids [ m ][ 0 ] if m is not None else 0 \u03a6 = max ( 0 , ( \u03b2n - \u03b2m + self . rho * ( dn - self . x [ n ]) + 0.5 * self . rho_bar * \u0393c )) / self . rho_bar upper_bound = self . x [ n ] + min ( dm + \u0393c , self . alpha * \u03a6 , ( 2 / self . rho_bar ) * \u03b2n ) return upper_bound def find_m ( self , n , bids ): \"\"\" Finds the lowest priced winning agent (other than agent n). Args: n (int): Agent index. bids (List[Tuple[float, float]]): Bid profile. Returns: int: Index of agent m, or None if none found. \"\"\" lowest = float ( 'inf' ) idx = None for i in range ( self . N ): if i == n or self . x [ i ] == 0 : continue \u03b2 = bids [ i ][ 0 ] if \u03b2 < lowest or ( \u03b2 == lowest and ( idx is None or i < idx )): lowest = \u03b2 idx = i return idx def best_response ( self , n , bids ): \"\"\" Computes agent n's best response by optimizing payoff w.r.t. demand. Args: n (int): Agent index. bids (List[Tuple[float, float]]): Current bids. Returns: Tuple[float, float]: New bid (\u03b2, d) for agent n. \"\"\" upper = self . constrained_demand ( n , bids ) lower = self . x [ n ] def neg_payoff ( d ): \u03b2 = self . marginal_valuation ( n , d ) # true_beta = self.marginal_valuation(n, d) # budget = self.agents[n].budget # if budget <= 0: # scaled_beta = 0.0 # else: # scaling = budget / (budget + 1e-3) # scaled_beta = scaling * true_beta # Scaling factor \u2014 adjust if you want soft capping # scaling = budget / (budget + 1e-6) # avoid divide-by-zero # In your budget-weighted bid scaling: # Instead of soft scaling, use aggressive squashing: # scaling = self.agents[n].budget / (self.agents[n].budget + 0.01) # scaled_beta = scaling * true_beta # effective_beta = scaling * true_beta temp_bids = bids . copy () temp_bids [ n ] = ( \u03b2 , d ) # temp_bids[n] = (scaled_beta, d) return - self . payoff ( n , temp_bids ) res = minimize_scalar ( neg_payoff , bounds = ( lower , upper ), method = 'bounded' ) best_d = res . x \u03b2_best = self . marginal_valuation ( n , best_d ) return ( \u03b2_best , best_d ) # def best_response(self, n, bids): # \"\"\" # Computes agent n's best response by optimizing payoff with respect to demand, # using budget-aware bid scaling. # Args: # n (int): Agent index. # bids (List[Tuple[float, float]]): Current bid profile. # Returns: # Tuple[float, float]: New bid (\u03b2, d) for agent n. # \"\"\" # upper = self.constrained_demand(n, bids) # lower = self.x[n] # budget = self.agents[n].budget # # If agent is broke, skip optimization and return (0, 0) # if budget <= 0: # return (0.0, 0.0) # def neg_payoff(d): # true_beta = self.marginal_valuation(n, d) # scaling = budget / (budget + 1e-3) # aggressive scaling # scaled_beta = scaling * true_beta # temp_bids = bids.copy() # temp_bids[n] = (scaled_beta, d) # return -self.payoff(n, temp_bids) # res = minimize_scalar(neg_payoff, bounds=(lower, upper), method='bounded') # best_d = res.x # # Recompute scaled bid for this d # true_beta = self.marginal_valuation(n, best_d) # scaling = budget / (budget + 1e-3) # scaled_beta = scaling * true_beta # return (scaled_beta, best_d) def compute_payments_from_delta ( self , S ): \"\"\" Computes VCG payments based on the avoidance effort (Delta) using each agent's actual valuation function. Args: S (float): Total safety correction required (i.e., safety deficit). Returns: List[float]: VCG payments based on Delta externality. \"\"\" # Step 1: Final credit allocation (after auction) c = np . array ([ bid [ 1 ] for bid in self . bids ]) Delta = ( 1 - c ) * S / np . sum ( 1 - c ) print ( f \"\u0394: { [ round ( d , 4 ) for d in Delta ] } \" ) print ( \"Valuations of others with agent present:\" , [ round ( agent . valuation ( d ), 4 ) for i , ( agent , d ) in enumerate ( zip ( self . agents , Delta )) if i != 0 ]) # Then repeat with agent 1 removed (\u0394_wo_1) N = self . N payments = [] for i in range ( N ): # Step 2: Recompute allocation with agent i set to full credit (no burden) c_mod = c . copy () c_mod [ i ] = 1.0 denom = np . sum ( 1 - c_mod ) if denom == 0 : Delta_wo_i = np . zeros ( N ) else : Delta_wo_i = ( 1 - c_mod ) * S / denom # Step 3: Use agent-provided valuation functions to compute disutility welfare_wo_i = sum ( - self . agents [ j ] . valuation ( Delta_wo_i [ j ]) for j in range ( N ) if j != i ) welfare_with_i = sum ( - self . agents [ j ] . valuation ( Delta [ j ]) for j in range ( N ) if j != i ) # Step 4: VCG payment is the externality agent i imposes tau_i = welfare_wo_i - welfare_with_i payments . append ( tau_i ) return payments def select_next_player ( self ): \"\"\" Selects the next agent to update their bid based on allocation status. Returns: int: Index of next player. \"\"\" for i in range ( self . N ): \u03b2 , d = self . bids [ i ] if self . x [ i ] < d and self . x [ i ] > 0 : return i for i in range ( self . N ): \u03b2 , d = self . bids [ i ] if self . x [ i ] == 0 and d > 0 : return i return max ( range ( self . N ), key = lambda i : self . bids [ i ][ 0 ]) def run ( self , max_steps = 10000 ): \"\"\" Runs the auction process until convergence or max iterations. Args: max_steps (int): Maximum allowed iterations. Returns: Tuple[List[Tuple[float, float]], np.ndarray]: Final bid profile and allocation. \"\"\" k = 0 update_log = [] while k < max_steps : bids_old = self . bids . copy () self . x = self . allocation ( self . bids ) n = self . select_next_player () self . bids [ n ] = self . best_response ( n , self . bids ) self . history . append ( self . bids . copy ()) update_log . append ( n ) if len ( update_log ) >= self . N : recent = update_log [ - self . N :] all_updated = set ( recent ) == set ( range ( self . N )) delta = sum ( abs ( self . bids [ i ][ 1 ] - bids_old [ i ][ 1 ]) + abs ( self . bids [ i ][ 0 ] - bids_old [ i ][ 0 ]) for i in range ( self . N )) if all_updated and delta < self . epsilon : break k += 1 return self . bids , self . allocation ( self . bids ) # def compute_payments(self): # \"\"\" # Computes VCG payments for each agent after auction ends. # Returns: # List[float]: Payment \u03c4_i for each agent. # \"\"\" # self.x = self.allocation(self.bids) # return [self.payment(self.bids, n) for n in range(self.N)] # def compute_payments(self): # self.x = self.allocation(self.bids) # payments = [] # for n in range(self.N): # bids_wo_n = self.bids.copy() # bids_wo_n[n] = (self.bids[n][0], 0.0) # x_wo_n = self.allocation(bids_wo_n) # print(f\"\\nAgent {n} removal:\") # for m in range(self.N): # if m != n: # print(f\" Agent {m}: x_with = {self.x[m]:.4f}, x_wo_n = {x_wo_n[m]:.4f}\") # payment = sum(self.bids[m][0] * (x_wo_n[m] - self.x[m]) for m in range(self.N) if m != n) # print(f\" Payment \u03c4_{n} = {payment:.4f}\") # payments.append(payment) # return payments def compute_payments ( self ): \"\"\" Computes VCG payments for each agent using Clarke pivot rule with full reallocation. Assumes agents will reoptimize demand if another agent exits, so all \u0393 is consumed. \"\"\" self . x = self . allocation ( self . bids ) payments = [] for n in range ( self . N ): # 1. Remove agent n from allocation bids_wo_n = self . bids . copy () bids_wo_n [ n ] = ( self . bids [ n ][ 0 ], 0.0 ) # 2. Redistribute \u0393 among remaining agents proportionally to their marginal value total_beta = sum ( b [ 0 ] for i , b in enumerate ( bids_wo_n ) if i != n ) if total_beta == 0 : # No one else wants anything \u2014 payment is 0 payments . append ( 0.0 ) continue # 3. New demand: distribute Gamma proportionally to \u03b2 new_bids = [] for i , ( beta , _ ) in enumerate ( bids_wo_n ): if i == n : new_bids . append (( beta , 0.0 )) else : new_demand = self . Gamma * ( beta / total_beta ) new_bids . append (( beta , new_demand )) # 4. Compute new allocation x_wo_n = self . allocation ( new_bids ) # 5. Compute externality (benefit to others) externality = sum ( self . bids [ m ][ 0 ] * ( x_wo_n [ m ] - self . x [ m ]) for m in range ( self . N ) if m != n ) payments . append ( externality ) return payments def compute_payments_vcg ( self ): \"\"\" Computes externality-based VCG-style payments by re-running auction without each agent. Returns: List[float]: Payments for each agent. \"\"\" self . x = self . allocation ( self . bids ) return [ sum ( self . bids [ j ][ 0 ] * ( self . run_without_agent ( i )[ j ] - self . x [ j ]) for j in range ( self . N ) if j != i ) for i in range ( self . N ) ] def reset ( self , agents , bids ): \"\"\" Resets the auction environment to a new configuration. Args: agents (List[Agent]): New agent list. bids (List[Tuple[float, float]]): New initial bids. \"\"\" self . agents = agents self . N = len ( agents ) self . bids = bids . copy () self . history = [ self . bids . copy ()] self . x = np . zeros ( self . N ) def run_without_agent ( self , remove_index ): \"\"\" Runs auction without a specific agent, used for computing VCG payments. Args: remove_index (int): Index of agent to exclude. Returns: np.ndarray: Full allocation vector with zero at excluded index. \"\"\" agents_wo = [ a for i , a in enumerate ( self . agents ) if i != remove_index ] init_bids = [( a . marginal_valuation ( 1.0 ), 1.0 ) for a in agents_wo ] auction_wo = Auction ( agents_wo , self . Gamma , init_bids ) _ , alloc_wo = auction_wo . run () full_alloc = np . zeros ( self . N ) j = 0 for i in range ( self . N ): if i == remove_index : continue full_alloc [ i ] = alloc_wo [ j ] j += 1 return full_alloc def plot_bid_demand_over_time ( self ): \"\"\"Plots demand bids over the course of the auction.\"\"\" for i in range ( self . N ): plt . plot ([ step [ i ][ 1 ] for step in self . history ], label = f 'Player { i + 1 } ' ) plt . title ( 'Bid Demand Over Iterations' ) plt . xlabel ( 'Iteration' ) plt . ylabel ( 'Demand (d)' ) plt . legend () plt . grid ( True ) plt . tight_layout () plt . show () def plot_bid_price_over_time ( self ): \"\"\"Plots price bids (\u03b2) over the course of the auction.\"\"\" for i in range ( self . N ): plt . plot ([ step [ i ][ 0 ] for step in self . history ], label = f 'Player { i + 1 } ' ) plt . title ( 'Bid Price Over Iterations' ) plt . xlabel ( 'Iteration' ) plt . ylabel ( 'Bid Price (\u03b2)' ) plt . legend () plt . grid ( True ) plt . tight_layout () plt . show () __init__ ( agents , Gamma , bids , alpha = 0.99 , rho_bar = 2 , rho = 0.5 , epsilon = 0.0001 ) Initialize the Auction class for decentralized divisible resource allocation. Parameters: agents ( List [ Agent ] ) \u2013 List of Agent objects with valuation functions. Gamma ( float ) \u2013 Total amount of divisible resource to allocate. bids ( List [ Tuple [ float , float ]] ) \u2013 Initial bids for each agent, in (\u03b2, d) format. alpha ( float , default: 0.99 ) \u2013 Smoothing parameter for computing constrained demand. rho_bar ( float , default: 2 ) \u2013 Upper bound on dynamic response term for constrained demand. rho ( float , default: 0.5 ) \u2013 Smoothing factor for current demand vs. allocation. epsilon ( float , default: 0.0001 ) \u2013 Convergence threshold for bid updates. Source code in kamaji/auctions/resource.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 def __init__ ( self , agents , Gamma , bids , alpha = 0.99 , rho_bar = 2 , rho = 0.5 , epsilon = 1e-4 ): \"\"\" Initialize the Auction class for decentralized divisible resource allocation. Args: agents (List[Agent]): List of Agent objects with valuation functions. Gamma (float): Total amount of divisible resource to allocate. bids (List[Tuple[float, float]]): Initial bids for each agent, in (\u03b2, d) format. alpha (float): Smoothing parameter for computing constrained demand. rho_bar (float): Upper bound on dynamic response term for constrained demand. rho (float): Smoothing factor for current demand vs. allocation. epsilon (float): Convergence threshold for bid updates. \"\"\" self . agents = agents self . N = len ( agents ) self . Gamma = Gamma self . alpha = alpha self . rho_bar = rho_bar self . rho = rho self . epsilon = epsilon self . bids = bids self . history = [ self . bids . copy ()] # Log of all bids over time allocation ( bids ) Computes allocation vector from current bids using descending sort of \u03b2 with random tie-breaking. Parameters: bids ( List [ Tuple [ float , float ]] ) \u2013 Bids as list of (\u03b2, d) pairs. Returns: \u2013 np.ndarray: Allocated resource vector x for all agents. Source code in kamaji/auctions/resource.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 def allocation ( self , bids ): \"\"\" Computes allocation vector from current bids using descending sort of \u03b2 with random tie-breaking. Args: bids (List[Tuple[float, float]]): Bids as list of (\u03b2, d) pairs. Returns: np.ndarray: Allocated resource vector x for all agents. \"\"\" indexed_bids = [( i , b [ 0 ], b [ 1 ], random . random ()) for i , b in enumerate ( bids )] beta_sorted = sorted ( indexed_bids , key = lambda x : ( - x [ 1 ], x [ 3 ])) x = np . zeros ( self . N ) remaining = self . Gamma for i , beta , d , _ in beta_sorted : x [ i ] = min ( d , remaining ) remaining -= x [ i ] if remaining <= 0 : break return x best_response ( n , bids ) Computes agent n's best response by optimizing payoff w.r.t. demand. Parameters: n ( int ) \u2013 Agent index. bids ( List [ Tuple [ float , float ]] ) \u2013 Current bids. Returns: \u2013 Tuple[float, float]: New bid (\u03b2, d) for agent n. Source code in kamaji/auctions/resource.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 def best_response ( self , n , bids ): \"\"\" Computes agent n's best response by optimizing payoff w.r.t. demand. Args: n (int): Agent index. bids (List[Tuple[float, float]]): Current bids. Returns: Tuple[float, float]: New bid (\u03b2, d) for agent n. \"\"\" upper = self . constrained_demand ( n , bids ) lower = self . x [ n ] def neg_payoff ( d ): \u03b2 = self . marginal_valuation ( n , d ) # true_beta = self.marginal_valuation(n, d) # budget = self.agents[n].budget # if budget <= 0: # scaled_beta = 0.0 # else: # scaling = budget / (budget + 1e-3) # scaled_beta = scaling * true_beta # Scaling factor \u2014 adjust if you want soft capping # scaling = budget / (budget + 1e-6) # avoid divide-by-zero # In your budget-weighted bid scaling: # Instead of soft scaling, use aggressive squashing: # scaling = self.agents[n].budget / (self.agents[n].budget + 0.01) # scaled_beta = scaling * true_beta # effective_beta = scaling * true_beta temp_bids = bids . copy () temp_bids [ n ] = ( \u03b2 , d ) # temp_bids[n] = (scaled_beta, d) return - self . payoff ( n , temp_bids ) res = minimize_scalar ( neg_payoff , bounds = ( lower , upper ), method = 'bounded' ) best_d = res . x \u03b2_best = self . marginal_valuation ( n , best_d ) return ( \u03b2_best , best_d ) compute_payments () Computes VCG payments for each agent using Clarke pivot rule with full reallocation. Assumes agents will reoptimize demand if another agent exits, so all \u0393 is consumed. Source code in kamaji/auctions/resource.py 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 def compute_payments ( self ): \"\"\" Computes VCG payments for each agent using Clarke pivot rule with full reallocation. Assumes agents will reoptimize demand if another agent exits, so all \u0393 is consumed. \"\"\" self . x = self . allocation ( self . bids ) payments = [] for n in range ( self . N ): # 1. Remove agent n from allocation bids_wo_n = self . bids . copy () bids_wo_n [ n ] = ( self . bids [ n ][ 0 ], 0.0 ) # 2. Redistribute \u0393 among remaining agents proportionally to their marginal value total_beta = sum ( b [ 0 ] for i , b in enumerate ( bids_wo_n ) if i != n ) if total_beta == 0 : # No one else wants anything \u2014 payment is 0 payments . append ( 0.0 ) continue # 3. New demand: distribute Gamma proportionally to \u03b2 new_bids = [] for i , ( beta , _ ) in enumerate ( bids_wo_n ): if i == n : new_bids . append (( beta , 0.0 )) else : new_demand = self . Gamma * ( beta / total_beta ) new_bids . append (( beta , new_demand )) # 4. Compute new allocation x_wo_n = self . allocation ( new_bids ) # 5. Compute externality (benefit to others) externality = sum ( self . bids [ m ][ 0 ] * ( x_wo_n [ m ] - self . x [ m ]) for m in range ( self . N ) if m != n ) payments . append ( externality ) return payments compute_payments_from_delta ( S ) Computes VCG payments based on the avoidance effort (Delta) using each agent's actual valuation function. Parameters: S ( float ) \u2013 Total safety correction required (i.e., safety deficit). Returns: \u2013 List[float]: VCG payments based on Delta externality. Source code in kamaji/auctions/resource.py 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 def compute_payments_from_delta ( self , S ): \"\"\" Computes VCG payments based on the avoidance effort (Delta) using each agent's actual valuation function. Args: S (float): Total safety correction required (i.e., safety deficit). Returns: List[float]: VCG payments based on Delta externality. \"\"\" # Step 1: Final credit allocation (after auction) c = np . array ([ bid [ 1 ] for bid in self . bids ]) Delta = ( 1 - c ) * S / np . sum ( 1 - c ) print ( f \"\u0394: { [ round ( d , 4 ) for d in Delta ] } \" ) print ( \"Valuations of others with agent present:\" , [ round ( agent . valuation ( d ), 4 ) for i , ( agent , d ) in enumerate ( zip ( self . agents , Delta )) if i != 0 ]) # Then repeat with agent 1 removed (\u0394_wo_1) N = self . N payments = [] for i in range ( N ): # Step 2: Recompute allocation with agent i set to full credit (no burden) c_mod = c . copy () c_mod [ i ] = 1.0 denom = np . sum ( 1 - c_mod ) if denom == 0 : Delta_wo_i = np . zeros ( N ) else : Delta_wo_i = ( 1 - c_mod ) * S / denom # Step 3: Use agent-provided valuation functions to compute disutility welfare_wo_i = sum ( - self . agents [ j ] . valuation ( Delta_wo_i [ j ]) for j in range ( N ) if j != i ) welfare_with_i = sum ( - self . agents [ j ] . valuation ( Delta [ j ]) for j in range ( N ) if j != i ) # Step 4: VCG payment is the externality agent i imposes tau_i = welfare_wo_i - welfare_with_i payments . append ( tau_i ) return payments compute_payments_vcg () Computes externality-based VCG-style payments by re-running auction without each agent. Returns: \u2013 List[float]: Payments for each agent. Source code in kamaji/auctions/resource.py 388 389 390 391 392 393 394 395 396 397 398 399 def compute_payments_vcg ( self ): \"\"\" Computes externality-based VCG-style payments by re-running auction without each agent. Returns: List[float]: Payments for each agent. \"\"\" self . x = self . allocation ( self . bids ) return [ sum ( self . bids [ j ][ 0 ] * ( self . run_without_agent ( i )[ j ] - self . x [ j ]) for j in range ( self . N ) if j != i ) for i in range ( self . N ) ] constrained_demand ( n , bids ) Computes upper bound for agent n's demand based on dynamic constraints. Parameters: n ( int ) \u2013 Agent index. bids ( List [ Tuple [ float , float ]] ) \u2013 Bid profile. Returns: float \u2013 Constrained upper bound on agent n's demand. Source code in kamaji/auctions/resource.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 def constrained_demand ( self , n , bids ): \"\"\" Computes upper bound for agent n's demand based on dynamic constraints. Args: n (int): Agent index. bids (List[Tuple[float, float]]): Bid profile. Returns: float: Constrained upper bound on agent n's demand. \"\"\" \u0393c = max ( 0 , self . Gamma - sum ( d for _ , d in bids )) \u03b2n , dn = bids [ n ] m = self . find_m ( n , bids ) dm = bids [ m ][ 1 ] if m is not None else 0 \u03b2m = bids [ m ][ 0 ] if m is not None else 0 \u03a6 = max ( 0 , ( \u03b2n - \u03b2m + self . rho * ( dn - self . x [ n ]) + 0.5 * self . rho_bar * \u0393c )) / self . rho_bar upper_bound = self . x [ n ] + min ( dm + \u0393c , self . alpha * \u03a6 , ( 2 / self . rho_bar ) * \u03b2n ) return upper_bound find_m ( n , bids ) Finds the lowest priced winning agent (other than agent n). Parameters: n ( int ) \u2013 Agent index. bids ( List [ Tuple [ float , float ]] ) \u2013 Bid profile. Returns: int \u2013 Index of agent m, or None if none found. Source code in kamaji/auctions/resource.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 def find_m ( self , n , bids ): \"\"\" Finds the lowest priced winning agent (other than agent n). Args: n (int): Agent index. bids (List[Tuple[float, float]]): Bid profile. Returns: int: Index of agent m, or None if none found. \"\"\" lowest = float ( 'inf' ) idx = None for i in range ( self . N ): if i == n or self . x [ i ] == 0 : continue \u03b2 = bids [ i ][ 0 ] if \u03b2 < lowest or ( \u03b2 == lowest and ( idx is None or i < idx )): lowest = \u03b2 idx = i return idx marginal_valuation ( n , x ) Returns the marginal valuation u_n'(x) of agent n at allocation x. Source code in kamaji/auctions/resource.py 34 35 36 def marginal_valuation ( self , n , x ): \"\"\"Returns the marginal valuation u_n'(x) of agent n at allocation x.\"\"\" return self . agents [ n ] . marginal_valuation ( x ) payment ( bids , n ) Computes VCG payment for agent n using Clarke pivot rule. Parameters: bids ( List [ Tuple [ float , float ]] ) \u2013 Current bids. n ( int ) \u2013 Agent index. Returns: float \u2013 Payment \u03c4_n agent n must pay. Source code in kamaji/auctions/resource.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def payment ( self , bids , n ): \"\"\" Computes VCG payment for agent n using Clarke pivot rule. Args: bids (List[Tuple[float, float]]): Current bids. n (int): Agent index. Returns: float: Payment \u03c4_n agent n must pay. \"\"\" b_without_n = bids . copy () b_without_n [ n ] = ( bids [ n ][ 0 ], 0.0 ) x_without = self . allocation ( b_without_n ) return sum ( bids [ m ][ 0 ] * ( x_without [ m ] - self . x [ m ]) for m in range ( self . N ) if m != n ) payoff ( n , bids ) Computes payoff for agent n given current bids. Parameters: n ( int ) \u2013 Agent index. bids ( List [ Tuple [ float , float ]] ) \u2013 Bid profile. Returns: float \u2013 Payoff for agent n. Source code in kamaji/auctions/resource.py 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def payoff ( self , n , bids ): \"\"\" Computes payoff for agent n given current bids. Args: n (int): Agent index. bids (List[Tuple[float, float]]): Bid profile. Returns: float: Payoff for agent n. \"\"\" x = self . allocation ( bids ) \u03c4 = self . payment ( bids , n ) return self . valuation ( n , x [ n ]) - \u03c4 plot_bid_demand_over_time () Plots demand bids over the course of the auction. Source code in kamaji/auctions/resource.py 439 440 441 442 443 444 445 446 447 448 449 def plot_bid_demand_over_time ( self ): \"\"\"Plots demand bids over the course of the auction.\"\"\" for i in range ( self . N ): plt . plot ([ step [ i ][ 1 ] for step in self . history ], label = f 'Player { i + 1 } ' ) plt . title ( 'Bid Demand Over Iterations' ) plt . xlabel ( 'Iteration' ) plt . ylabel ( 'Demand (d)' ) plt . legend () plt . grid ( True ) plt . tight_layout () plt . show () plot_bid_price_over_time () Plots price bids (\u03b2) over the course of the auction. Source code in kamaji/auctions/resource.py 451 452 453 454 455 456 457 458 459 460 461 def plot_bid_price_over_time ( self ): \"\"\"Plots price bids (\u03b2) over the course of the auction.\"\"\" for i in range ( self . N ): plt . plot ([ step [ i ][ 0 ] for step in self . history ], label = f 'Player { i + 1 } ' ) plt . title ( 'Bid Price Over Iterations' ) plt . xlabel ( 'Iteration' ) plt . ylabel ( 'Bid Price (\u03b2)' ) plt . legend () plt . grid ( True ) plt . tight_layout () plt . show () reset ( agents , bids ) Resets the auction environment to a new configuration. Parameters: agents ( List [ Agent ] ) \u2013 New agent list. bids ( List [ Tuple [ float , float ]] ) \u2013 New initial bids. Source code in kamaji/auctions/resource.py 401 402 403 404 405 406 407 408 409 410 411 412 413 def reset ( self , agents , bids ): \"\"\" Resets the auction environment to a new configuration. Args: agents (List[Agent]): New agent list. bids (List[Tuple[float, float]]): New initial bids. \"\"\" self . agents = agents self . N = len ( agents ) self . bids = bids . copy () self . history = [ self . bids . copy ()] self . x = np . zeros ( self . N ) run ( max_steps = 10000 ) Runs the auction process until convergence or max iterations. Parameters: max_steps ( int , default: 10000 ) \u2013 Maximum allowed iterations. Returns: \u2013 Tuple[List[Tuple[float, float]], np.ndarray]: Final bid profile and allocation. Source code in kamaji/auctions/resource.py 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 def run ( self , max_steps = 10000 ): \"\"\" Runs the auction process until convergence or max iterations. Args: max_steps (int): Maximum allowed iterations. Returns: Tuple[List[Tuple[float, float]], np.ndarray]: Final bid profile and allocation. \"\"\" k = 0 update_log = [] while k < max_steps : bids_old = self . bids . copy () self . x = self . allocation ( self . bids ) n = self . select_next_player () self . bids [ n ] = self . best_response ( n , self . bids ) self . history . append ( self . bids . copy ()) update_log . append ( n ) if len ( update_log ) >= self . N : recent = update_log [ - self . N :] all_updated = set ( recent ) == set ( range ( self . N )) delta = sum ( abs ( self . bids [ i ][ 1 ] - bids_old [ i ][ 1 ]) + abs ( self . bids [ i ][ 0 ] - bids_old [ i ][ 0 ]) for i in range ( self . N )) if all_updated and delta < self . epsilon : break k += 1 return self . bids , self . allocation ( self . bids ) run_without_agent ( remove_index ) Runs auction without a specific agent, used for computing VCG payments. Parameters: remove_index ( int ) \u2013 Index of agent to exclude. Returns: \u2013 np.ndarray: Full allocation vector with zero at excluded index. Source code in kamaji/auctions/resource.py 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 def run_without_agent ( self , remove_index ): \"\"\" Runs auction without a specific agent, used for computing VCG payments. Args: remove_index (int): Index of agent to exclude. Returns: np.ndarray: Full allocation vector with zero at excluded index. \"\"\" agents_wo = [ a for i , a in enumerate ( self . agents ) if i != remove_index ] init_bids = [( a . marginal_valuation ( 1.0 ), 1.0 ) for a in agents_wo ] auction_wo = Auction ( agents_wo , self . Gamma , init_bids ) _ , alloc_wo = auction_wo . run () full_alloc = np . zeros ( self . N ) j = 0 for i in range ( self . N ): if i == remove_index : continue full_alloc [ i ] = alloc_wo [ j ] j += 1 return full_alloc select_next_player () Selects the next agent to update their bid based on allocation status. Returns: int \u2013 Index of next player. Source code in kamaji/auctions/resource.py 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 def select_next_player ( self ): \"\"\" Selects the next agent to update their bid based on allocation status. Returns: int: Index of next player. \"\"\" for i in range ( self . N ): \u03b2 , d = self . bids [ i ] if self . x [ i ] < d and self . x [ i ] > 0 : return i for i in range ( self . N ): \u03b2 , d = self . bids [ i ] if self . x [ i ] == 0 and d > 0 : return i return max ( range ( self . N ), key = lambda i : self . bids [ i ][ 0 ]) valuation ( n , x ) Returns the valuation u_n(x) of agent n at allocation x. Source code in kamaji/auctions/resource.py 30 31 32 def valuation ( self , n , x ): \"\"\"Returns the valuation u_n(x) of agent n at allocation x.\"\"\" return self . agents [ n ] . valuation ( x )","title":"API Reference"},{"location":"api/#api-reference","text":"This section documents the main modules of the Kamaji simulation environment. View Agent class","title":"API Reference"},{"location":"api/#kamaji.agent.Agent","text":"Source code in kamaji/agent/agent.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 class Agent : def __init__ ( self , agent_config , t = 0.0 , dt = 0.01 , ** kwargs ): for key , value in kwargs . items (): setattr ( self , key , value ) self . budget = 1 self . _agent_config = agent_config self . manual_control_input = None self . _dt = dt self . _id = agent_config [ 'id' ] self . _state = agent_config [ 'initial_state' ] self . _state_list = list ( self . _state . keys ()) self . _state_history = pd . DataFrame ( columns = [ 'time' ] + self . _state_list ) self . _state_history . loc [ len ( self . _state_history )] = { 'time' : t } | self . _state self . assign_dynamics () self . assign_controller () self . _control_list = self . dynamics_model . control_variables () self . _control_history = pd . DataFrame ( columns = [ 'time' ] + self . _control_list ) # Validate control alignment required_controls = len ( self . _control_list ) if hasattr ( self , 'control_model' ) and isinstance ( self . control_model , dict ): provided = len ( self . control_model ) if required_controls != provided : raise ValueError ( f \"[Agent: { self . _id } ] Control mismatch: dynamics model expects { required_controls } controls \" f \"but controller provides { provided } .\" ) def assign_dynamics ( self ): model_map = { \"Unicycle\" : Unicycle , \"CruiseControl\" : CruiseControl , \"SingleIntegrator1DOF\" : SingleIntegrator1DOF , \"SingleIntegrator2DOF\" : SingleIntegrator2DOF , \"SingleIntegrator3DOF\" : SingleIntegrator3DOF , \"DoubleIntegrator1DOF\" : DoubleIntegrator1DOF , \"DoubleIntegrator2DOF\" : DoubleIntegrator2DOF , \"DoubleIntegrator3DOF\" : DoubleIntegrator3DOF , } model_name = self . _agent_config [ 'dynamics_model' ] if model_name not in model_map : raise NotImplementedError ( f \" { model_name } is not a valid dynamics model.\" ) self . dynamics_model = model_map [ model_name ]( self . _dt ) # def assign_controller(self): # controller_cfg = self._agent_config.get(\"controller\", {}) # if not isinstance(controller_cfg, dict): # raise ValueError(\"Controller must be a dictionary of control channels with 'type' fields.\") # self.control_model = {} # for ctrl_name, ctrl_data in controller_cfg.items(): # ctrl_type = ctrl_data[\"type\"] # if ctrl_type == \"Constant\": # val = ctrl_data[\"value\"] # self.control_model[ctrl_name] = lambda t, state, v=val: v # elif ctrl_type == \"PID\": # spec = ctrl_data.get(\"specs\", [])[0] # self.control_model[ctrl_name] = PID( # [spec[\"state\"]], # [spec[\"goal\"]], # [spec[\"kp\"]], # [spec[\"ki\"]], # [spec[\"kd\"]], # dt=self._dt # ) # else: # raise ValueError(f\"Unknown controller type '{ctrl_type}' for {ctrl_name}\") def assign_controller ( self ): controller_cfg = self . _agent_config . get ( \"controller\" , {}) if not isinstance ( controller_cfg , dict ): raise ValueError ( \"Controller must be a dictionary of control channels with 'type' and 'specs'.\" ) self . control_model = {} for ctrl_name , ctrl_data in controller_cfg . items (): ctrl_type = ctrl_data [ \"type\" ] specs = ctrl_data . get ( \"specs\" , []) if not isinstance ( specs , list ) or len ( specs ) != 1 : raise ValueError ( f \"[Agent: { self . _id } ] Controller ' { ctrl_name } ' must have a single-item specs list.\" ) spec = specs [ 0 ] if ctrl_type == \"Constant\" : if \"value\" not in spec : raise ValueError ( f \"Constant controller for ' { ctrl_name } ' must specify 'value'\" ) val = spec [ \"value\" ] self . control_model [ ctrl_name ] = lambda t , state , v = val : v elif ctrl_type == \"PID\" : required_keys = [ \"state\" , \"goal\" , \"kp\" , \"ki\" , \"kd\" ] if not all ( k in spec for k in required_keys ): raise ValueError ( f \"PID controller for ' { ctrl_name } ' must contain { required_keys } \" ) self . control_model [ ctrl_name ] = PID ( [ spec [ \"state\" ]], [ spec [ \"goal\" ]], [ spec [ \"kp\" ]], [ spec [ \"ki\" ]], [ spec [ \"kd\" ]], dt = self . _dt ) else : raise ValueError ( f \"Unknown controller type ' { ctrl_type } ' for { ctrl_name } \" ) def compute_control ( self , t ) -> np . ndarray : \"\"\" Compute the full control vector by combining per-channel control outputs. Args: t (float): Current simulation time. Returns: np.ndarray: Control vector of shape (n_controls,) \"\"\" current_state = self . _state # For backward compatibility, support legacy controller format if isinstance ( self . control_model , dict ): control_channels = sorted ( self . control_model . keys ()) control_vector = [] for channel in control_channels : controller = self . control_model [ channel ] val = controller . update ( t , current_state ) if hasattr ( controller , \"update\" ) else controller ( t , current_state ) if isinstance ( val , ( list , tuple , np . ndarray )): control_vector . extend ( np . asarray ( val ) . flatten ()) else : control_vector . append ( val ) return np . array ( control_vector ) else : # Fallback for legacy single controller return self . control_model . update ( t , current_state ) def compute_dynamics ( self , t , control_input : np . ndarray ) -> np . ndarray : return self . dynamics_model . dynamics ( t , self . _state , control_input ) def step ( self , t : float , control_input : np . ndarray ) -> None : self . _state_order = list ( self . _state . keys ()) state_vec = np . array ([ self . _state [ k ] for k in self . _state_order ]) def compute_dynamics ( t_local , y , u ): return self . dynamics_model . dynamics ( t_local , { k : y [ i ] for i , k in enumerate ( self . _state_order )}, u ) _ , new_state_vec = ode . rk4_step ( compute_dynamics , t , state_vec , control_input , self . _dt ) new_state_dict = { k : new_state_vec [ i ] for i , k in enumerate ( self . _state_order )} self . _state = new_state_dict self . _state_history . loc [ len ( self . _state_history )] = { 'time' : t } | self . _state control_row = { 'time' : t } control_row . update ({ name : control_input [ i ] for i , name in enumerate ( self . _control_list )}) self . _control_history . loc [ len ( self . _control_history )] = control_row def set_valuation ( self , fn : Callable ): self . valuation_fn = fn def set_marginal_valuation ( self , fn : Callable ): self . marginal_valuation_fn = fn def valuation ( self , x ): return self . valuation_fn ( x ) def marginal_valuation ( self , x ): return self . marginal_valuation_fn ( x ) @property def state ( self ): return self . _state @property def state_log ( self ): return self . _state_history @property def control_log ( self ): return self . _control_history","title":"Agent"},{"location":"api/#kamaji.agent.Agent.compute_control","text":"Compute the full control vector by combining per-channel control outputs. Parameters: t ( float ) \u2013 Current simulation time. Returns: ndarray \u2013 np.ndarray: Control vector of shape (n_controls,) Source code in kamaji/agent/agent.py 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def compute_control ( self , t ) -> np . ndarray : \"\"\" Compute the full control vector by combining per-channel control outputs. Args: t (float): Current simulation time. Returns: np.ndarray: Control vector of shape (n_controls,) \"\"\" current_state = self . _state # For backward compatibility, support legacy controller format if isinstance ( self . control_model , dict ): control_channels = sorted ( self . control_model . keys ()) control_vector = [] for channel in control_channels : controller = self . control_model [ channel ] val = controller . update ( t , current_state ) if hasattr ( controller , \"update\" ) else controller ( t , current_state ) if isinstance ( val , ( list , tuple , np . ndarray )): control_vector . extend ( np . asarray ( val ) . flatten ()) else : control_vector . append ( val ) return np . array ( control_vector ) else : # Fallback for legacy single controller return self . control_model . update ( t , current_state ) View Simulator class","title":"compute_control"},{"location":"api/#kamaji.simulation.simulator.Simulator","text":"A class to manage and run multi-agent simulations with configurable dynamics, control, and collision avoidance mechanisms. Includes support for agent tracking, control input updates, manual overrides, logging, and visualization. Attributes: sim_time ( float ) \u2013 Current simulation time. active_agents ( list ) \u2013 List of currently active agents. inactive_agents ( list ) \u2013 List of agents that have completed simulation. agent_ids ( set ) \u2013 Set of agent IDs in the simulation. verbose ( bool ) \u2013 Flag for printing debug/output information. plot ( SimulationPlotter ) \u2013 Visualization utility. logger ( SimulationLogger ) \u2013 Logging utility for simulation data. Source code in kamaji/simulation/simulator.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 class Simulator : \"\"\" A class to manage and run multi-agent simulations with configurable dynamics, control, and collision avoidance mechanisms. Includes support for agent tracking, control input updates, manual overrides, logging, and visualization. Attributes: sim_time (float): Current simulation time. active_agents (list): List of currently active agents. inactive_agents (list): List of agents that have completed simulation. agent_ids (set): Set of agent IDs in the simulation. verbose (bool): Flag for printing debug/output information. plot (SimulationPlotter): Visualization utility. logger (SimulationLogger): Logging utility for simulation data. \"\"\" def __init__ ( self , config = None ) -> None : \"\"\" Initialize the simulation with optional configuration parameters. Args: config (dict, optional): Dictionary containing simulation, agent, and logging parameters. \"\"\" self . _config = config self . _current_real_time = time () self . _elapsed_real_time = 0.0 self . sim_time = 0.0 self . active_agents = [] self . inactive_agents = [] self . agent_ids = set () self . verbose = True self . plot = SimulationPlotter ( self ) self . logging_params = config . get ( \"logging\" , {}) if config else {} self . logger = SimulationLogger ( self ) self . cbf_system = None # Will be set later, if needed if config is not None : self . load_from_config ( config ) else : if self . verbose : print ( \"No config provided, using default values.\" ) def set_cbf_system ( self , cbf_system ): \"\"\" Set an external CBF system to be used during simulation. Args: cbf_system (CBFSystem): A configured CBFSystem instance. \"\"\" self . cbf_system = cbf_system def set_sim_params ( self , sim_params = None ): \"\"\" Set core simulation parameters such as timestep, duration, and integration method. Args: sim_params (dict, optional): Dictionary with keys 'time_step', 'duration', and 'integrator'. Raises: ValueError: If required parameters are missing or invalid. TypeError: If parameter types are incorrect. \"\"\" if sim_params is None : self . dt = 0.01 self . duration = 10.0 self . num_timesteps = int ( self . duration / self . dt ) self . integrator = 'RK4' self . verbose = True return self . verbose = sim_params . get ( 'verbose' , True ) required = [ 'time_step' , 'duration' , 'integrator' ] missing = [ key for key in required if key not in sim_params ] if missing : raise ValueError ( f \"Missing simulation parameters: { missing } \" ) time_step = sim_params [ 'time_step' ] duration = sim_params [ 'duration' ] integrator = sim_params [ 'integrator' ] if not isinstance ( time_step , ( float , int )) or time_step <= 0 : raise ValueError ( \"'time_step' must be a positive number.\" ) if not isinstance ( duration , ( float , int )) or duration <= 0 : raise ValueError ( \"'duration' must be a positive, nonzero number.\" ) if not isinstance ( integrator , str ): raise TypeError ( \"'integrator' must be a string.\" ) valid_integrators = { 'RK4' , 'Euler' , 'RK2' , 'RK45' } if integrator not in valid_integrators : raise ValueError ( f \"Unsupported integrator ' { integrator } '. Valid options: { valid_integrators } \" ) self . dt = float ( time_step ) self . duration = float ( duration ) self . num_timesteps = max ( 1 , int ( self . duration / self . dt )) self . integrator = integrator def load_from_config ( self , config ): \"\"\" Load simulation parameters, agent configuration, environment, and logging settings. Args: config (dict): YAML-style configuration dictionary. \"\"\" self . set_sim_params ( config . get ( 'simulation' , {})) self . add_agents ( config . get ( 'agents' , {})) self . env_params = config . get ( 'environment' , {}) self . logging_params = config . get ( 'logging' , {}) def add_agents ( self , agents ) -> None : \"\"\" Add one or more agents to the simulation. Args: agents (dict | tuple | dict): Dictionary of agents, (config, id) tuple, or a single config. Raises: TypeError: If format of input is not recognized. \"\"\" if isinstance ( agents , dict ): if all ( isinstance ( v , dict ) for v in agents . values ()): for agent_id , agent_config in agents . items (): self . _add_single_agent ( agent_config , agent_id ) else : self . _add_single_agent ( agents ) elif isinstance ( agents , tuple ): if not isinstance ( agents [ 0 ], dict ) or not isinstance ( agents [ 1 ], str ): raise TypeError ( \"Expected (agent_config: dict, agent_id: str)\" ) self . _add_single_agent ( agents [ 0 ], agents [ 1 ]) else : raise TypeError ( \"Expected one of: dict of agents, (config, id) tuple, or single agent config dict.\" ) def _add_single_agent ( self , agent_config : dict , agent_id : Optional [ str ] = None ): \"\"\" Add a single agent with the provided configuration and optional ID. Args: agent_config (dict): Configuration dictionary for the agent. agent_id (str, optional): Explicit ID for the agent. Auto-generated if None. Raises: ValueError: If required fields are missing or types are invalid. RuntimeError: If the agent fails to initialize. \"\"\" required_fields = [ 'type' , 'initial_state' , 'dynamics_model' , 'controller' ] missing = [ k for k in required_fields if k not in agent_config ] if missing : raise ValueError ( f \"Missing required fields in agent config: { missing } \" ) if not isinstance ( agent_config [ 'initial_state' ], dict ): raise TypeError ( \"initial_state must be a dictionary.\" ) if not isinstance ( agent_config [ 'controller' ], dict ): raise TypeError ( \"controller must be a dictionary.\" ) controller_block = agent_config [ 'controller' ] if not isinstance ( controller_block , dict ): raise TypeError ( \"Controller block must be a dictionary of control channels.\" ) for ctrl_name , ctrl_conf in controller_block . items (): if not isinstance ( ctrl_conf , dict ): raise TypeError ( f \"Controller for ' { ctrl_name } ' must be a dict.\" ) if \"type\" not in ctrl_conf : raise ValueError ( f \"Controller ' { ctrl_name } ' must include a 'type' field.\" ) if \"specs\" not in ctrl_conf : raise ValueError ( f \"Controller ' { ctrl_name } ' must include a 'specs' field.\" ) if not isinstance ( ctrl_conf [ \"specs\" ], list ): raise TypeError ( f \"Controller ' { ctrl_name } ' 'specs' must be a list.\" ) if agent_id is None : base = \"agent\" i = 1 while f \" { base } _ { i } \" in self . agent_ids : i += 1 agent_id = f \" { base } _ { i } \" if agent_id in self . agent_ids : raise ValueError ( f \"Agent ID ' { agent_id } ' already exists.\" ) agent_config [ 'id' ] = agent_id try : self . active_agents . append ( Agent ( agent_config , self . sim_time , self . dt )) except Exception as e : raise RuntimeError ( f \"Failed to initialize Agent ' { agent_id } ': { e } \" ) self . agent_ids . add ( agent_id ) if self . verbose : print ( f \"[Simulator] Agent ' { agent_id } ' added.\" ) def simulate ( self , on_step = None ) -> None : \"\"\" Run the simulation loop for all time steps. Args: on_step (Callable[[Simulator, int], None], optional): Callback executed before each step. \"\"\" start_time = time () iterator = tqdm ( range ( self . num_timesteps ), desc = \"Simulating\" , unit = \"step\" ) if self . verbose else range ( self . num_timesteps ) for step_idx in iterator : if on_step : on_step ( self , step_idx ) self . step () self . sim_time = time () - start_time self . inactive_agents . extend ( self . active_agents ) self . active_agents . clear () if self . logging_params . get ( \"enabled\" , True ): if self . logging_params . get ( \"format\" , \"hdf5\" ) == \"hdf5\" : self . logger . log_to_hdf5 () if self . verbose : print ( f \"Sim time: { self . sim_time : .4f } \" ) def step ( self ) -> None : \"\"\" Advance the simulation by one time step, updating agent states using control input. \"\"\" state_values = {} all_controls = [] control_dims = [] # 1. Gather state values and nominal control for each agent for idx , agent in enumerate ( self . active_agents ): state_values [ f \"x { idx } \" ] = agent . state [ \"position_x\" ] state_values [ f \"y { idx } \" ] = agent . state [ \"position_y\" ] control = agent . manual_control_input if agent . manual_control_input is not None else agent . compute_control ( self . sim_time ) all_controls . append ( control ) control_dims . append ( len ( control )) u_nom = np . concatenate ( all_controls ) # 2. Filter full control vector using CBF system if available if self . cbf_system is not None : u_filtered = self . cbf_system . filter_controls ( state_values , u_nom , mode = \"all\" ) else : u_filtered = u_nom # 3. Slice filtered controls back to each agent and step them idx = 0 for agent , dim in zip ( self . active_agents , control_dims ): agent_control = u_filtered [ idx : idx + dim ] agent . step ( self . sim_time , agent_control ) idx += dim def clear_manual_control ( self , agent_id : str ) -> None : \"\"\" Clear any manually assigned control input for a specific agent. Args: agent_id (str): ID of the agent to clear manual control for. \"\"\" for agent in self . active_agents : if agent . _id == agent_id : agent . manual_control_input = None return def set_manual_control ( self , agent_id : str , control : np . ndarray ) -> None : \"\"\" Manually assign a control input to a specific agent. Args: agent_id (str): ID of the agent. control (np.ndarray): Manual control input. Raises: ValueError: If the agent ID is not found. \"\"\" for agent in self . active_agents : if agent . _id == agent_id : agent . manual_control_input = control if self . verbose : print ( f \"[Simulator] Manual control set for agent ' { agent_id } '.\" ) return raise ValueError ( f \"Agent with ID ' { agent_id } ' not found.\" ) def remove_agent ( self , agent : Agent ) -> bool : \"\"\" Remove an agent from the active list and move to the inactive list. Args: agent (Agent): The agent to be removed. Returns: bool: True if removal was successful. Raises: ValueError: If the agent is not in the active list. \"\"\" if agent not in self . active_agents : raise ValueError ( f \"Agent { agent . id } is not an active Agent.\" ) self . inactive_agents . append ( self . active_agents . pop ( self . active_agents . index ( agent ))) return True","title":"Simulator"},{"location":"api/#kamaji.simulation.simulator.Simulator.__init__","text":"Initialize the simulation with optional configuration parameters. Parameters: config ( dict , default: None ) \u2013 Dictionary containing simulation, agent, and logging parameters. Source code in kamaji/simulation/simulator.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 def __init__ ( self , config = None ) -> None : \"\"\" Initialize the simulation with optional configuration parameters. Args: config (dict, optional): Dictionary containing simulation, agent, and logging parameters. \"\"\" self . _config = config self . _current_real_time = time () self . _elapsed_real_time = 0.0 self . sim_time = 0.0 self . active_agents = [] self . inactive_agents = [] self . agent_ids = set () self . verbose = True self . plot = SimulationPlotter ( self ) self . logging_params = config . get ( \"logging\" , {}) if config else {} self . logger = SimulationLogger ( self ) self . cbf_system = None # Will be set later, if needed if config is not None : self . load_from_config ( config ) else : if self . verbose : print ( \"No config provided, using default values.\" )","title":"__init__"},{"location":"api/#kamaji.simulation.simulator.Simulator.add_agents","text":"Add one or more agents to the simulation. Parameters: agents ( dict | tuple | dict ) \u2013 Dictionary of agents, (config, id) tuple, or a single config. Raises: TypeError \u2013 If format of input is not recognized. Source code in kamaji/simulation/simulator.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 def add_agents ( self , agents ) -> None : \"\"\" Add one or more agents to the simulation. Args: agents (dict | tuple | dict): Dictionary of agents, (config, id) tuple, or a single config. Raises: TypeError: If format of input is not recognized. \"\"\" if isinstance ( agents , dict ): if all ( isinstance ( v , dict ) for v in agents . values ()): for agent_id , agent_config in agents . items (): self . _add_single_agent ( agent_config , agent_id ) else : self . _add_single_agent ( agents ) elif isinstance ( agents , tuple ): if not isinstance ( agents [ 0 ], dict ) or not isinstance ( agents [ 1 ], str ): raise TypeError ( \"Expected (agent_config: dict, agent_id: str)\" ) self . _add_single_agent ( agents [ 0 ], agents [ 1 ]) else : raise TypeError ( \"Expected one of: dict of agents, (config, id) tuple, or single agent config dict.\" )","title":"add_agents"},{"location":"api/#kamaji.simulation.simulator.Simulator.clear_manual_control","text":"Clear any manually assigned control input for a specific agent. Parameters: agent_id ( str ) \u2013 ID of the agent to clear manual control for. Source code in kamaji/simulation/simulator.py 258 259 260 261 262 263 264 265 266 267 268 def clear_manual_control ( self , agent_id : str ) -> None : \"\"\" Clear any manually assigned control input for a specific agent. Args: agent_id (str): ID of the agent to clear manual control for. \"\"\" for agent in self . active_agents : if agent . _id == agent_id : agent . manual_control_input = None return","title":"clear_manual_control"},{"location":"api/#kamaji.simulation.simulator.Simulator.load_from_config","text":"Load simulation parameters, agent configuration, environment, and logging settings. Parameters: config ( dict ) \u2013 YAML-style configuration dictionary. Source code in kamaji/simulation/simulator.py 106 107 108 109 110 111 112 113 114 115 116 def load_from_config ( self , config ): \"\"\" Load simulation parameters, agent configuration, environment, and logging settings. Args: config (dict): YAML-style configuration dictionary. \"\"\" self . set_sim_params ( config . get ( 'simulation' , {})) self . add_agents ( config . get ( 'agents' , {})) self . env_params = config . get ( 'environment' , {}) self . logging_params = config . get ( 'logging' , {})","title":"load_from_config"},{"location":"api/#kamaji.simulation.simulator.Simulator.remove_agent","text":"Remove an agent from the active list and move to the inactive list. Parameters: agent ( Agent ) \u2013 The agent to be removed. Returns: bool ( bool ) \u2013 True if removal was successful. Raises: ValueError \u2013 If the agent is not in the active list. Source code in kamaji/simulation/simulator.py 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 def remove_agent ( self , agent : Agent ) -> bool : \"\"\" Remove an agent from the active list and move to the inactive list. Args: agent (Agent): The agent to be removed. Returns: bool: True if removal was successful. Raises: ValueError: If the agent is not in the active list. \"\"\" if agent not in self . active_agents : raise ValueError ( f \"Agent { agent . id } is not an active Agent.\" ) self . inactive_agents . append ( self . active_agents . pop ( self . active_agents . index ( agent ))) return True","title":"remove_agent"},{"location":"api/#kamaji.simulation.simulator.Simulator.set_cbf_system","text":"Set an external CBF system to be used during simulation. Parameters: cbf_system ( CBFSystem ) \u2013 A configured CBFSystem instance. Source code in kamaji/simulation/simulator.py 52 53 54 55 56 57 58 59 def set_cbf_system ( self , cbf_system ): \"\"\" Set an external CBF system to be used during simulation. Args: cbf_system (CBFSystem): A configured CBFSystem instance. \"\"\" self . cbf_system = cbf_system","title":"set_cbf_system"},{"location":"api/#kamaji.simulation.simulator.Simulator.set_manual_control","text":"Manually assign a control input to a specific agent. Parameters: agent_id ( str ) \u2013 ID of the agent. control ( ndarray ) \u2013 Manual control input. Raises: ValueError \u2013 If the agent ID is not found. Source code in kamaji/simulation/simulator.py 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 def set_manual_control ( self , agent_id : str , control : np . ndarray ) -> None : \"\"\" Manually assign a control input to a specific agent. Args: agent_id (str): ID of the agent. control (np.ndarray): Manual control input. Raises: ValueError: If the agent ID is not found. \"\"\" for agent in self . active_agents : if agent . _id == agent_id : agent . manual_control_input = control if self . verbose : print ( f \"[Simulator] Manual control set for agent ' { agent_id } '.\" ) return raise ValueError ( f \"Agent with ID ' { agent_id } ' not found.\" )","title":"set_manual_control"},{"location":"api/#kamaji.simulation.simulator.Simulator.set_sim_params","text":"Set core simulation parameters such as timestep, duration, and integration method. Parameters: sim_params ( dict , default: None ) \u2013 Dictionary with keys 'time_step', 'duration', and 'integrator'. Raises: ValueError \u2013 If required parameters are missing or invalid. TypeError \u2013 If parameter types are incorrect. Source code in kamaji/simulation/simulator.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 def set_sim_params ( self , sim_params = None ): \"\"\" Set core simulation parameters such as timestep, duration, and integration method. Args: sim_params (dict, optional): Dictionary with keys 'time_step', 'duration', and 'integrator'. Raises: ValueError: If required parameters are missing or invalid. TypeError: If parameter types are incorrect. \"\"\" if sim_params is None : self . dt = 0.01 self . duration = 10.0 self . num_timesteps = int ( self . duration / self . dt ) self . integrator = 'RK4' self . verbose = True return self . verbose = sim_params . get ( 'verbose' , True ) required = [ 'time_step' , 'duration' , 'integrator' ] missing = [ key for key in required if key not in sim_params ] if missing : raise ValueError ( f \"Missing simulation parameters: { missing } \" ) time_step = sim_params [ 'time_step' ] duration = sim_params [ 'duration' ] integrator = sim_params [ 'integrator' ] if not isinstance ( time_step , ( float , int )) or time_step <= 0 : raise ValueError ( \"'time_step' must be a positive number.\" ) if not isinstance ( duration , ( float , int )) or duration <= 0 : raise ValueError ( \"'duration' must be a positive, nonzero number.\" ) if not isinstance ( integrator , str ): raise TypeError ( \"'integrator' must be a string.\" ) valid_integrators = { 'RK4' , 'Euler' , 'RK2' , 'RK45' } if integrator not in valid_integrators : raise ValueError ( f \"Unsupported integrator ' { integrator } '. Valid options: { valid_integrators } \" ) self . dt = float ( time_step ) self . duration = float ( duration ) self . num_timesteps = max ( 1 , int ( self . duration / self . dt )) self . integrator = integrator","title":"set_sim_params"},{"location":"api/#kamaji.simulation.simulator.Simulator.simulate","text":"Run the simulation loop for all time steps. Parameters: on_step ( Callable [[ Simulator , int ], None] , default: None ) \u2013 Callback executed before each step. Source code in kamaji/simulation/simulator.py 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 def simulate ( self , on_step = None ) -> None : \"\"\" Run the simulation loop for all time steps. Args: on_step (Callable[[Simulator, int], None], optional): Callback executed before each step. \"\"\" start_time = time () iterator = tqdm ( range ( self . num_timesteps ), desc = \"Simulating\" , unit = \"step\" ) if self . verbose else range ( self . num_timesteps ) for step_idx in iterator : if on_step : on_step ( self , step_idx ) self . step () self . sim_time = time () - start_time self . inactive_agents . extend ( self . active_agents ) self . active_agents . clear () if self . logging_params . get ( \"enabled\" , True ): if self . logging_params . get ( \"format\" , \"hdf5\" ) == \"hdf5\" : self . logger . log_to_hdf5 () if self . verbose : print ( f \"Sim time: { self . sim_time : .4f } \" )","title":"simulate"},{"location":"api/#kamaji.simulation.simulator.Simulator.step","text":"Advance the simulation by one time step, updating agent states using control input. Source code in kamaji/simulation/simulator.py 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 def step ( self ) -> None : \"\"\" Advance the simulation by one time step, updating agent states using control input. \"\"\" state_values = {} all_controls = [] control_dims = [] # 1. Gather state values and nominal control for each agent for idx , agent in enumerate ( self . active_agents ): state_values [ f \"x { idx } \" ] = agent . state [ \"position_x\" ] state_values [ f \"y { idx } \" ] = agent . state [ \"position_y\" ] control = agent . manual_control_input if agent . manual_control_input is not None else agent . compute_control ( self . sim_time ) all_controls . append ( control ) control_dims . append ( len ( control )) u_nom = np . concatenate ( all_controls ) # 2. Filter full control vector using CBF system if available if self . cbf_system is not None : u_filtered = self . cbf_system . filter_controls ( state_values , u_nom , mode = \"all\" ) else : u_filtered = u_nom # 3. Slice filtered controls back to each agent and step them idx = 0 for agent , dim in zip ( self . active_agents , control_dims ): agent_control = u_filtered [ idx : idx + dim ] agent . step ( self . sim_time , agent_control ) idx += dim View Auction class","title":"step"},{"location":"api/#kamaji.auctions.resource.Auction","text":"Source code in kamaji/auctions/resource.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 class Auction : def __init__ ( self , agents , Gamma , bids , alpha = 0.99 , rho_bar = 2 , rho = 0.5 , epsilon = 1e-4 ): \"\"\" Initialize the Auction class for decentralized divisible resource allocation. Args: agents (List[Agent]): List of Agent objects with valuation functions. Gamma (float): Total amount of divisible resource to allocate. bids (List[Tuple[float, float]]): Initial bids for each agent, in (\u03b2, d) format. alpha (float): Smoothing parameter for computing constrained demand. rho_bar (float): Upper bound on dynamic response term for constrained demand. rho (float): Smoothing factor for current demand vs. allocation. epsilon (float): Convergence threshold for bid updates. \"\"\" self . agents = agents self . N = len ( agents ) self . Gamma = Gamma self . alpha = alpha self . rho_bar = rho_bar self . rho = rho self . epsilon = epsilon self . bids = bids self . history = [ self . bids . copy ()] # Log of all bids over time def valuation ( self , n , x ): \"\"\"Returns the valuation u_n(x) of agent n at allocation x.\"\"\" return self . agents [ n ] . valuation ( x ) def marginal_valuation ( self , n , x ): \"\"\"Returns the marginal valuation u_n'(x) of agent n at allocation x.\"\"\" return self . agents [ n ] . marginal_valuation ( x ) def allocation ( self , bids ): \"\"\" Computes allocation vector from current bids using descending sort of \u03b2 with random tie-breaking. Args: bids (List[Tuple[float, float]]): Bids as list of (\u03b2, d) pairs. Returns: np.ndarray: Allocated resource vector x for all agents. \"\"\" indexed_bids = [( i , b [ 0 ], b [ 1 ], random . random ()) for i , b in enumerate ( bids )] beta_sorted = sorted ( indexed_bids , key = lambda x : ( - x [ 1 ], x [ 3 ])) x = np . zeros ( self . N ) remaining = self . Gamma for i , beta , d , _ in beta_sorted : x [ i ] = min ( d , remaining ) remaining -= x [ i ] if remaining <= 0 : break return x def payment ( self , bids , n ): \"\"\" Computes VCG payment for agent n using Clarke pivot rule. Args: bids (List[Tuple[float, float]]): Current bids. n (int): Agent index. Returns: float: Payment \u03c4_n agent n must pay. \"\"\" b_without_n = bids . copy () b_without_n [ n ] = ( bids [ n ][ 0 ], 0.0 ) x_without = self . allocation ( b_without_n ) return sum ( bids [ m ][ 0 ] * ( x_without [ m ] - self . x [ m ]) for m in range ( self . N ) if m != n ) def payoff ( self , n , bids ): \"\"\" Computes payoff for agent n given current bids. Args: n (int): Agent index. bids (List[Tuple[float, float]]): Bid profile. Returns: float: Payoff for agent n. \"\"\" x = self . allocation ( bids ) \u03c4 = self . payment ( bids , n ) return self . valuation ( n , x [ n ]) - \u03c4 def constrained_demand ( self , n , bids ): \"\"\" Computes upper bound for agent n's demand based on dynamic constraints. Args: n (int): Agent index. bids (List[Tuple[float, float]]): Bid profile. Returns: float: Constrained upper bound on agent n's demand. \"\"\" \u0393c = max ( 0 , self . Gamma - sum ( d for _ , d in bids )) \u03b2n , dn = bids [ n ] m = self . find_m ( n , bids ) dm = bids [ m ][ 1 ] if m is not None else 0 \u03b2m = bids [ m ][ 0 ] if m is not None else 0 \u03a6 = max ( 0 , ( \u03b2n - \u03b2m + self . rho * ( dn - self . x [ n ]) + 0.5 * self . rho_bar * \u0393c )) / self . rho_bar upper_bound = self . x [ n ] + min ( dm + \u0393c , self . alpha * \u03a6 , ( 2 / self . rho_bar ) * \u03b2n ) return upper_bound def find_m ( self , n , bids ): \"\"\" Finds the lowest priced winning agent (other than agent n). Args: n (int): Agent index. bids (List[Tuple[float, float]]): Bid profile. Returns: int: Index of agent m, or None if none found. \"\"\" lowest = float ( 'inf' ) idx = None for i in range ( self . N ): if i == n or self . x [ i ] == 0 : continue \u03b2 = bids [ i ][ 0 ] if \u03b2 < lowest or ( \u03b2 == lowest and ( idx is None or i < idx )): lowest = \u03b2 idx = i return idx def best_response ( self , n , bids ): \"\"\" Computes agent n's best response by optimizing payoff w.r.t. demand. Args: n (int): Agent index. bids (List[Tuple[float, float]]): Current bids. Returns: Tuple[float, float]: New bid (\u03b2, d) for agent n. \"\"\" upper = self . constrained_demand ( n , bids ) lower = self . x [ n ] def neg_payoff ( d ): \u03b2 = self . marginal_valuation ( n , d ) # true_beta = self.marginal_valuation(n, d) # budget = self.agents[n].budget # if budget <= 0: # scaled_beta = 0.0 # else: # scaling = budget / (budget + 1e-3) # scaled_beta = scaling * true_beta # Scaling factor \u2014 adjust if you want soft capping # scaling = budget / (budget + 1e-6) # avoid divide-by-zero # In your budget-weighted bid scaling: # Instead of soft scaling, use aggressive squashing: # scaling = self.agents[n].budget / (self.agents[n].budget + 0.01) # scaled_beta = scaling * true_beta # effective_beta = scaling * true_beta temp_bids = bids . copy () temp_bids [ n ] = ( \u03b2 , d ) # temp_bids[n] = (scaled_beta, d) return - self . payoff ( n , temp_bids ) res = minimize_scalar ( neg_payoff , bounds = ( lower , upper ), method = 'bounded' ) best_d = res . x \u03b2_best = self . marginal_valuation ( n , best_d ) return ( \u03b2_best , best_d ) # def best_response(self, n, bids): # \"\"\" # Computes agent n's best response by optimizing payoff with respect to demand, # using budget-aware bid scaling. # Args: # n (int): Agent index. # bids (List[Tuple[float, float]]): Current bid profile. # Returns: # Tuple[float, float]: New bid (\u03b2, d) for agent n. # \"\"\" # upper = self.constrained_demand(n, bids) # lower = self.x[n] # budget = self.agents[n].budget # # If agent is broke, skip optimization and return (0, 0) # if budget <= 0: # return (0.0, 0.0) # def neg_payoff(d): # true_beta = self.marginal_valuation(n, d) # scaling = budget / (budget + 1e-3) # aggressive scaling # scaled_beta = scaling * true_beta # temp_bids = bids.copy() # temp_bids[n] = (scaled_beta, d) # return -self.payoff(n, temp_bids) # res = minimize_scalar(neg_payoff, bounds=(lower, upper), method='bounded') # best_d = res.x # # Recompute scaled bid for this d # true_beta = self.marginal_valuation(n, best_d) # scaling = budget / (budget + 1e-3) # scaled_beta = scaling * true_beta # return (scaled_beta, best_d) def compute_payments_from_delta ( self , S ): \"\"\" Computes VCG payments based on the avoidance effort (Delta) using each agent's actual valuation function. Args: S (float): Total safety correction required (i.e., safety deficit). Returns: List[float]: VCG payments based on Delta externality. \"\"\" # Step 1: Final credit allocation (after auction) c = np . array ([ bid [ 1 ] for bid in self . bids ]) Delta = ( 1 - c ) * S / np . sum ( 1 - c ) print ( f \"\u0394: { [ round ( d , 4 ) for d in Delta ] } \" ) print ( \"Valuations of others with agent present:\" , [ round ( agent . valuation ( d ), 4 ) for i , ( agent , d ) in enumerate ( zip ( self . agents , Delta )) if i != 0 ]) # Then repeat with agent 1 removed (\u0394_wo_1) N = self . N payments = [] for i in range ( N ): # Step 2: Recompute allocation with agent i set to full credit (no burden) c_mod = c . copy () c_mod [ i ] = 1.0 denom = np . sum ( 1 - c_mod ) if denom == 0 : Delta_wo_i = np . zeros ( N ) else : Delta_wo_i = ( 1 - c_mod ) * S / denom # Step 3: Use agent-provided valuation functions to compute disutility welfare_wo_i = sum ( - self . agents [ j ] . valuation ( Delta_wo_i [ j ]) for j in range ( N ) if j != i ) welfare_with_i = sum ( - self . agents [ j ] . valuation ( Delta [ j ]) for j in range ( N ) if j != i ) # Step 4: VCG payment is the externality agent i imposes tau_i = welfare_wo_i - welfare_with_i payments . append ( tau_i ) return payments def select_next_player ( self ): \"\"\" Selects the next agent to update their bid based on allocation status. Returns: int: Index of next player. \"\"\" for i in range ( self . N ): \u03b2 , d = self . bids [ i ] if self . x [ i ] < d and self . x [ i ] > 0 : return i for i in range ( self . N ): \u03b2 , d = self . bids [ i ] if self . x [ i ] == 0 and d > 0 : return i return max ( range ( self . N ), key = lambda i : self . bids [ i ][ 0 ]) def run ( self , max_steps = 10000 ): \"\"\" Runs the auction process until convergence or max iterations. Args: max_steps (int): Maximum allowed iterations. Returns: Tuple[List[Tuple[float, float]], np.ndarray]: Final bid profile and allocation. \"\"\" k = 0 update_log = [] while k < max_steps : bids_old = self . bids . copy () self . x = self . allocation ( self . bids ) n = self . select_next_player () self . bids [ n ] = self . best_response ( n , self . bids ) self . history . append ( self . bids . copy ()) update_log . append ( n ) if len ( update_log ) >= self . N : recent = update_log [ - self . N :] all_updated = set ( recent ) == set ( range ( self . N )) delta = sum ( abs ( self . bids [ i ][ 1 ] - bids_old [ i ][ 1 ]) + abs ( self . bids [ i ][ 0 ] - bids_old [ i ][ 0 ]) for i in range ( self . N )) if all_updated and delta < self . epsilon : break k += 1 return self . bids , self . allocation ( self . bids ) # def compute_payments(self): # \"\"\" # Computes VCG payments for each agent after auction ends. # Returns: # List[float]: Payment \u03c4_i for each agent. # \"\"\" # self.x = self.allocation(self.bids) # return [self.payment(self.bids, n) for n in range(self.N)] # def compute_payments(self): # self.x = self.allocation(self.bids) # payments = [] # for n in range(self.N): # bids_wo_n = self.bids.copy() # bids_wo_n[n] = (self.bids[n][0], 0.0) # x_wo_n = self.allocation(bids_wo_n) # print(f\"\\nAgent {n} removal:\") # for m in range(self.N): # if m != n: # print(f\" Agent {m}: x_with = {self.x[m]:.4f}, x_wo_n = {x_wo_n[m]:.4f}\") # payment = sum(self.bids[m][0] * (x_wo_n[m] - self.x[m]) for m in range(self.N) if m != n) # print(f\" Payment \u03c4_{n} = {payment:.4f}\") # payments.append(payment) # return payments def compute_payments ( self ): \"\"\" Computes VCG payments for each agent using Clarke pivot rule with full reallocation. Assumes agents will reoptimize demand if another agent exits, so all \u0393 is consumed. \"\"\" self . x = self . allocation ( self . bids ) payments = [] for n in range ( self . N ): # 1. Remove agent n from allocation bids_wo_n = self . bids . copy () bids_wo_n [ n ] = ( self . bids [ n ][ 0 ], 0.0 ) # 2. Redistribute \u0393 among remaining agents proportionally to their marginal value total_beta = sum ( b [ 0 ] for i , b in enumerate ( bids_wo_n ) if i != n ) if total_beta == 0 : # No one else wants anything \u2014 payment is 0 payments . append ( 0.0 ) continue # 3. New demand: distribute Gamma proportionally to \u03b2 new_bids = [] for i , ( beta , _ ) in enumerate ( bids_wo_n ): if i == n : new_bids . append (( beta , 0.0 )) else : new_demand = self . Gamma * ( beta / total_beta ) new_bids . append (( beta , new_demand )) # 4. Compute new allocation x_wo_n = self . allocation ( new_bids ) # 5. Compute externality (benefit to others) externality = sum ( self . bids [ m ][ 0 ] * ( x_wo_n [ m ] - self . x [ m ]) for m in range ( self . N ) if m != n ) payments . append ( externality ) return payments def compute_payments_vcg ( self ): \"\"\" Computes externality-based VCG-style payments by re-running auction without each agent. Returns: List[float]: Payments for each agent. \"\"\" self . x = self . allocation ( self . bids ) return [ sum ( self . bids [ j ][ 0 ] * ( self . run_without_agent ( i )[ j ] - self . x [ j ]) for j in range ( self . N ) if j != i ) for i in range ( self . N ) ] def reset ( self , agents , bids ): \"\"\" Resets the auction environment to a new configuration. Args: agents (List[Agent]): New agent list. bids (List[Tuple[float, float]]): New initial bids. \"\"\" self . agents = agents self . N = len ( agents ) self . bids = bids . copy () self . history = [ self . bids . copy ()] self . x = np . zeros ( self . N ) def run_without_agent ( self , remove_index ): \"\"\" Runs auction without a specific agent, used for computing VCG payments. Args: remove_index (int): Index of agent to exclude. Returns: np.ndarray: Full allocation vector with zero at excluded index. \"\"\" agents_wo = [ a for i , a in enumerate ( self . agents ) if i != remove_index ] init_bids = [( a . marginal_valuation ( 1.0 ), 1.0 ) for a in agents_wo ] auction_wo = Auction ( agents_wo , self . Gamma , init_bids ) _ , alloc_wo = auction_wo . run () full_alloc = np . zeros ( self . N ) j = 0 for i in range ( self . N ): if i == remove_index : continue full_alloc [ i ] = alloc_wo [ j ] j += 1 return full_alloc def plot_bid_demand_over_time ( self ): \"\"\"Plots demand bids over the course of the auction.\"\"\" for i in range ( self . N ): plt . plot ([ step [ i ][ 1 ] for step in self . history ], label = f 'Player { i + 1 } ' ) plt . title ( 'Bid Demand Over Iterations' ) plt . xlabel ( 'Iteration' ) plt . ylabel ( 'Demand (d)' ) plt . legend () plt . grid ( True ) plt . tight_layout () plt . show () def plot_bid_price_over_time ( self ): \"\"\"Plots price bids (\u03b2) over the course of the auction.\"\"\" for i in range ( self . N ): plt . plot ([ step [ i ][ 0 ] for step in self . history ], label = f 'Player { i + 1 } ' ) plt . title ( 'Bid Price Over Iterations' ) plt . xlabel ( 'Iteration' ) plt . ylabel ( 'Bid Price (\u03b2)' ) plt . legend () plt . grid ( True ) plt . tight_layout () plt . show ()","title":"Auction"},{"location":"api/#kamaji.auctions.resource.Auction.__init__","text":"Initialize the Auction class for decentralized divisible resource allocation. Parameters: agents ( List [ Agent ] ) \u2013 List of Agent objects with valuation functions. Gamma ( float ) \u2013 Total amount of divisible resource to allocate. bids ( List [ Tuple [ float , float ]] ) \u2013 Initial bids for each agent, in (\u03b2, d) format. alpha ( float , default: 0.99 ) \u2013 Smoothing parameter for computing constrained demand. rho_bar ( float , default: 2 ) \u2013 Upper bound on dynamic response term for constrained demand. rho ( float , default: 0.5 ) \u2013 Smoothing factor for current demand vs. allocation. epsilon ( float , default: 0.0001 ) \u2013 Convergence threshold for bid updates. Source code in kamaji/auctions/resource.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 def __init__ ( self , agents , Gamma , bids , alpha = 0.99 , rho_bar = 2 , rho = 0.5 , epsilon = 1e-4 ): \"\"\" Initialize the Auction class for decentralized divisible resource allocation. Args: agents (List[Agent]): List of Agent objects with valuation functions. Gamma (float): Total amount of divisible resource to allocate. bids (List[Tuple[float, float]]): Initial bids for each agent, in (\u03b2, d) format. alpha (float): Smoothing parameter for computing constrained demand. rho_bar (float): Upper bound on dynamic response term for constrained demand. rho (float): Smoothing factor for current demand vs. allocation. epsilon (float): Convergence threshold for bid updates. \"\"\" self . agents = agents self . N = len ( agents ) self . Gamma = Gamma self . alpha = alpha self . rho_bar = rho_bar self . rho = rho self . epsilon = epsilon self . bids = bids self . history = [ self . bids . copy ()] # Log of all bids over time","title":"__init__"},{"location":"api/#kamaji.auctions.resource.Auction.allocation","text":"Computes allocation vector from current bids using descending sort of \u03b2 with random tie-breaking. Parameters: bids ( List [ Tuple [ float , float ]] ) \u2013 Bids as list of (\u03b2, d) pairs. Returns: \u2013 np.ndarray: Allocated resource vector x for all agents. Source code in kamaji/auctions/resource.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 def allocation ( self , bids ): \"\"\" Computes allocation vector from current bids using descending sort of \u03b2 with random tie-breaking. Args: bids (List[Tuple[float, float]]): Bids as list of (\u03b2, d) pairs. Returns: np.ndarray: Allocated resource vector x for all agents. \"\"\" indexed_bids = [( i , b [ 0 ], b [ 1 ], random . random ()) for i , b in enumerate ( bids )] beta_sorted = sorted ( indexed_bids , key = lambda x : ( - x [ 1 ], x [ 3 ])) x = np . zeros ( self . N ) remaining = self . Gamma for i , beta , d , _ in beta_sorted : x [ i ] = min ( d , remaining ) remaining -= x [ i ] if remaining <= 0 : break return x","title":"allocation"},{"location":"api/#kamaji.auctions.resource.Auction.best_response","text":"Computes agent n's best response by optimizing payoff w.r.t. demand. Parameters: n ( int ) \u2013 Agent index. bids ( List [ Tuple [ float , float ]] ) \u2013 Current bids. Returns: \u2013 Tuple[float, float]: New bid (\u03b2, d) for agent n. Source code in kamaji/auctions/resource.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 def best_response ( self , n , bids ): \"\"\" Computes agent n's best response by optimizing payoff w.r.t. demand. Args: n (int): Agent index. bids (List[Tuple[float, float]]): Current bids. Returns: Tuple[float, float]: New bid (\u03b2, d) for agent n. \"\"\" upper = self . constrained_demand ( n , bids ) lower = self . x [ n ] def neg_payoff ( d ): \u03b2 = self . marginal_valuation ( n , d ) # true_beta = self.marginal_valuation(n, d) # budget = self.agents[n].budget # if budget <= 0: # scaled_beta = 0.0 # else: # scaling = budget / (budget + 1e-3) # scaled_beta = scaling * true_beta # Scaling factor \u2014 adjust if you want soft capping # scaling = budget / (budget + 1e-6) # avoid divide-by-zero # In your budget-weighted bid scaling: # Instead of soft scaling, use aggressive squashing: # scaling = self.agents[n].budget / (self.agents[n].budget + 0.01) # scaled_beta = scaling * true_beta # effective_beta = scaling * true_beta temp_bids = bids . copy () temp_bids [ n ] = ( \u03b2 , d ) # temp_bids[n] = (scaled_beta, d) return - self . payoff ( n , temp_bids ) res = minimize_scalar ( neg_payoff , bounds = ( lower , upper ), method = 'bounded' ) best_d = res . x \u03b2_best = self . marginal_valuation ( n , best_d ) return ( \u03b2_best , best_d )","title":"best_response"},{"location":"api/#kamaji.auctions.resource.Auction.compute_payments","text":"Computes VCG payments for each agent using Clarke pivot rule with full reallocation. Assumes agents will reoptimize demand if another agent exits, so all \u0393 is consumed. Source code in kamaji/auctions/resource.py 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 def compute_payments ( self ): \"\"\" Computes VCG payments for each agent using Clarke pivot rule with full reallocation. Assumes agents will reoptimize demand if another agent exits, so all \u0393 is consumed. \"\"\" self . x = self . allocation ( self . bids ) payments = [] for n in range ( self . N ): # 1. Remove agent n from allocation bids_wo_n = self . bids . copy () bids_wo_n [ n ] = ( self . bids [ n ][ 0 ], 0.0 ) # 2. Redistribute \u0393 among remaining agents proportionally to their marginal value total_beta = sum ( b [ 0 ] for i , b in enumerate ( bids_wo_n ) if i != n ) if total_beta == 0 : # No one else wants anything \u2014 payment is 0 payments . append ( 0.0 ) continue # 3. New demand: distribute Gamma proportionally to \u03b2 new_bids = [] for i , ( beta , _ ) in enumerate ( bids_wo_n ): if i == n : new_bids . append (( beta , 0.0 )) else : new_demand = self . Gamma * ( beta / total_beta ) new_bids . append (( beta , new_demand )) # 4. Compute new allocation x_wo_n = self . allocation ( new_bids ) # 5. Compute externality (benefit to others) externality = sum ( self . bids [ m ][ 0 ] * ( x_wo_n [ m ] - self . x [ m ]) for m in range ( self . N ) if m != n ) payments . append ( externality ) return payments","title":"compute_payments"},{"location":"api/#kamaji.auctions.resource.Auction.compute_payments_from_delta","text":"Computes VCG payments based on the avoidance effort (Delta) using each agent's actual valuation function. Parameters: S ( float ) \u2013 Total safety correction required (i.e., safety deficit). Returns: \u2013 List[float]: VCG payments based on Delta externality. Source code in kamaji/auctions/resource.py 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 def compute_payments_from_delta ( self , S ): \"\"\" Computes VCG payments based on the avoidance effort (Delta) using each agent's actual valuation function. Args: S (float): Total safety correction required (i.e., safety deficit). Returns: List[float]: VCG payments based on Delta externality. \"\"\" # Step 1: Final credit allocation (after auction) c = np . array ([ bid [ 1 ] for bid in self . bids ]) Delta = ( 1 - c ) * S / np . sum ( 1 - c ) print ( f \"\u0394: { [ round ( d , 4 ) for d in Delta ] } \" ) print ( \"Valuations of others with agent present:\" , [ round ( agent . valuation ( d ), 4 ) for i , ( agent , d ) in enumerate ( zip ( self . agents , Delta )) if i != 0 ]) # Then repeat with agent 1 removed (\u0394_wo_1) N = self . N payments = [] for i in range ( N ): # Step 2: Recompute allocation with agent i set to full credit (no burden) c_mod = c . copy () c_mod [ i ] = 1.0 denom = np . sum ( 1 - c_mod ) if denom == 0 : Delta_wo_i = np . zeros ( N ) else : Delta_wo_i = ( 1 - c_mod ) * S / denom # Step 3: Use agent-provided valuation functions to compute disutility welfare_wo_i = sum ( - self . agents [ j ] . valuation ( Delta_wo_i [ j ]) for j in range ( N ) if j != i ) welfare_with_i = sum ( - self . agents [ j ] . valuation ( Delta [ j ]) for j in range ( N ) if j != i ) # Step 4: VCG payment is the externality agent i imposes tau_i = welfare_wo_i - welfare_with_i payments . append ( tau_i ) return payments","title":"compute_payments_from_delta"},{"location":"api/#kamaji.auctions.resource.Auction.compute_payments_vcg","text":"Computes externality-based VCG-style payments by re-running auction without each agent. Returns: \u2013 List[float]: Payments for each agent. Source code in kamaji/auctions/resource.py 388 389 390 391 392 393 394 395 396 397 398 399 def compute_payments_vcg ( self ): \"\"\" Computes externality-based VCG-style payments by re-running auction without each agent. Returns: List[float]: Payments for each agent. \"\"\" self . x = self . allocation ( self . bids ) return [ sum ( self . bids [ j ][ 0 ] * ( self . run_without_agent ( i )[ j ] - self . x [ j ]) for j in range ( self . N ) if j != i ) for i in range ( self . N ) ]","title":"compute_payments_vcg"},{"location":"api/#kamaji.auctions.resource.Auction.constrained_demand","text":"Computes upper bound for agent n's demand based on dynamic constraints. Parameters: n ( int ) \u2013 Agent index. bids ( List [ Tuple [ float , float ]] ) \u2013 Bid profile. Returns: float \u2013 Constrained upper bound on agent n's demand. Source code in kamaji/auctions/resource.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 def constrained_demand ( self , n , bids ): \"\"\" Computes upper bound for agent n's demand based on dynamic constraints. Args: n (int): Agent index. bids (List[Tuple[float, float]]): Bid profile. Returns: float: Constrained upper bound on agent n's demand. \"\"\" \u0393c = max ( 0 , self . Gamma - sum ( d for _ , d in bids )) \u03b2n , dn = bids [ n ] m = self . find_m ( n , bids ) dm = bids [ m ][ 1 ] if m is not None else 0 \u03b2m = bids [ m ][ 0 ] if m is not None else 0 \u03a6 = max ( 0 , ( \u03b2n - \u03b2m + self . rho * ( dn - self . x [ n ]) + 0.5 * self . rho_bar * \u0393c )) / self . rho_bar upper_bound = self . x [ n ] + min ( dm + \u0393c , self . alpha * \u03a6 , ( 2 / self . rho_bar ) * \u03b2n ) return upper_bound","title":"constrained_demand"},{"location":"api/#kamaji.auctions.resource.Auction.find_m","text":"Finds the lowest priced winning agent (other than agent n). Parameters: n ( int ) \u2013 Agent index. bids ( List [ Tuple [ float , float ]] ) \u2013 Bid profile. Returns: int \u2013 Index of agent m, or None if none found. Source code in kamaji/auctions/resource.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 def find_m ( self , n , bids ): \"\"\" Finds the lowest priced winning agent (other than agent n). Args: n (int): Agent index. bids (List[Tuple[float, float]]): Bid profile. Returns: int: Index of agent m, or None if none found. \"\"\" lowest = float ( 'inf' ) idx = None for i in range ( self . N ): if i == n or self . x [ i ] == 0 : continue \u03b2 = bids [ i ][ 0 ] if \u03b2 < lowest or ( \u03b2 == lowest and ( idx is None or i < idx )): lowest = \u03b2 idx = i return idx","title":"find_m"},{"location":"api/#kamaji.auctions.resource.Auction.marginal_valuation","text":"Returns the marginal valuation u_n'(x) of agent n at allocation x. Source code in kamaji/auctions/resource.py 34 35 36 def marginal_valuation ( self , n , x ): \"\"\"Returns the marginal valuation u_n'(x) of agent n at allocation x.\"\"\" return self . agents [ n ] . marginal_valuation ( x )","title":"marginal_valuation"},{"location":"api/#kamaji.auctions.resource.Auction.payment","text":"Computes VCG payment for agent n using Clarke pivot rule. Parameters: bids ( List [ Tuple [ float , float ]] ) \u2013 Current bids. n ( int ) \u2013 Agent index. Returns: float \u2013 Payment \u03c4_n agent n must pay. Source code in kamaji/auctions/resource.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def payment ( self , bids , n ): \"\"\" Computes VCG payment for agent n using Clarke pivot rule. Args: bids (List[Tuple[float, float]]): Current bids. n (int): Agent index. Returns: float: Payment \u03c4_n agent n must pay. \"\"\" b_without_n = bids . copy () b_without_n [ n ] = ( bids [ n ][ 0 ], 0.0 ) x_without = self . allocation ( b_without_n ) return sum ( bids [ m ][ 0 ] * ( x_without [ m ] - self . x [ m ]) for m in range ( self . N ) if m != n )","title":"payment"},{"location":"api/#kamaji.auctions.resource.Auction.payoff","text":"Computes payoff for agent n given current bids. Parameters: n ( int ) \u2013 Agent index. bids ( List [ Tuple [ float , float ]] ) \u2013 Bid profile. Returns: float \u2013 Payoff for agent n. Source code in kamaji/auctions/resource.py 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def payoff ( self , n , bids ): \"\"\" Computes payoff for agent n given current bids. Args: n (int): Agent index. bids (List[Tuple[float, float]]): Bid profile. Returns: float: Payoff for agent n. \"\"\" x = self . allocation ( bids ) \u03c4 = self . payment ( bids , n ) return self . valuation ( n , x [ n ]) - \u03c4","title":"payoff"},{"location":"api/#kamaji.auctions.resource.Auction.plot_bid_demand_over_time","text":"Plots demand bids over the course of the auction. Source code in kamaji/auctions/resource.py 439 440 441 442 443 444 445 446 447 448 449 def plot_bid_demand_over_time ( self ): \"\"\"Plots demand bids over the course of the auction.\"\"\" for i in range ( self . N ): plt . plot ([ step [ i ][ 1 ] for step in self . history ], label = f 'Player { i + 1 } ' ) plt . title ( 'Bid Demand Over Iterations' ) plt . xlabel ( 'Iteration' ) plt . ylabel ( 'Demand (d)' ) plt . legend () plt . grid ( True ) plt . tight_layout () plt . show ()","title":"plot_bid_demand_over_time"},{"location":"api/#kamaji.auctions.resource.Auction.plot_bid_price_over_time","text":"Plots price bids (\u03b2) over the course of the auction. Source code in kamaji/auctions/resource.py 451 452 453 454 455 456 457 458 459 460 461 def plot_bid_price_over_time ( self ): \"\"\"Plots price bids (\u03b2) over the course of the auction.\"\"\" for i in range ( self . N ): plt . plot ([ step [ i ][ 0 ] for step in self . history ], label = f 'Player { i + 1 } ' ) plt . title ( 'Bid Price Over Iterations' ) plt . xlabel ( 'Iteration' ) plt . ylabel ( 'Bid Price (\u03b2)' ) plt . legend () plt . grid ( True ) plt . tight_layout () plt . show ()","title":"plot_bid_price_over_time"},{"location":"api/#kamaji.auctions.resource.Auction.reset","text":"Resets the auction environment to a new configuration. Parameters: agents ( List [ Agent ] ) \u2013 New agent list. bids ( List [ Tuple [ float , float ]] ) \u2013 New initial bids. Source code in kamaji/auctions/resource.py 401 402 403 404 405 406 407 408 409 410 411 412 413 def reset ( self , agents , bids ): \"\"\" Resets the auction environment to a new configuration. Args: agents (List[Agent]): New agent list. bids (List[Tuple[float, float]]): New initial bids. \"\"\" self . agents = agents self . N = len ( agents ) self . bids = bids . copy () self . history = [ self . bids . copy ()] self . x = np . zeros ( self . N )","title":"reset"},{"location":"api/#kamaji.auctions.resource.Auction.run","text":"Runs the auction process until convergence or max iterations. Parameters: max_steps ( int , default: 10000 ) \u2013 Maximum allowed iterations. Returns: \u2013 Tuple[List[Tuple[float, float]], np.ndarray]: Final bid profile and allocation. Source code in kamaji/auctions/resource.py 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 def run ( self , max_steps = 10000 ): \"\"\" Runs the auction process until convergence or max iterations. Args: max_steps (int): Maximum allowed iterations. Returns: Tuple[List[Tuple[float, float]], np.ndarray]: Final bid profile and allocation. \"\"\" k = 0 update_log = [] while k < max_steps : bids_old = self . bids . copy () self . x = self . allocation ( self . bids ) n = self . select_next_player () self . bids [ n ] = self . best_response ( n , self . bids ) self . history . append ( self . bids . copy ()) update_log . append ( n ) if len ( update_log ) >= self . N : recent = update_log [ - self . N :] all_updated = set ( recent ) == set ( range ( self . N )) delta = sum ( abs ( self . bids [ i ][ 1 ] - bids_old [ i ][ 1 ]) + abs ( self . bids [ i ][ 0 ] - bids_old [ i ][ 0 ]) for i in range ( self . N )) if all_updated and delta < self . epsilon : break k += 1 return self . bids , self . allocation ( self . bids )","title":"run"},{"location":"api/#kamaji.auctions.resource.Auction.run_without_agent","text":"Runs auction without a specific agent, used for computing VCG payments. Parameters: remove_index ( int ) \u2013 Index of agent to exclude. Returns: \u2013 np.ndarray: Full allocation vector with zero at excluded index. Source code in kamaji/auctions/resource.py 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 def run_without_agent ( self , remove_index ): \"\"\" Runs auction without a specific agent, used for computing VCG payments. Args: remove_index (int): Index of agent to exclude. Returns: np.ndarray: Full allocation vector with zero at excluded index. \"\"\" agents_wo = [ a for i , a in enumerate ( self . agents ) if i != remove_index ] init_bids = [( a . marginal_valuation ( 1.0 ), 1.0 ) for a in agents_wo ] auction_wo = Auction ( agents_wo , self . Gamma , init_bids ) _ , alloc_wo = auction_wo . run () full_alloc = np . zeros ( self . N ) j = 0 for i in range ( self . N ): if i == remove_index : continue full_alloc [ i ] = alloc_wo [ j ] j += 1 return full_alloc","title":"run_without_agent"},{"location":"api/#kamaji.auctions.resource.Auction.select_next_player","text":"Selects the next agent to update their bid based on allocation status. Returns: int \u2013 Index of next player. Source code in kamaji/auctions/resource.py 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 def select_next_player ( self ): \"\"\" Selects the next agent to update their bid based on allocation status. Returns: int: Index of next player. \"\"\" for i in range ( self . N ): \u03b2 , d = self . bids [ i ] if self . x [ i ] < d and self . x [ i ] > 0 : return i for i in range ( self . N ): \u03b2 , d = self . bids [ i ] if self . x [ i ] == 0 and d > 0 : return i return max ( range ( self . N ), key = lambda i : self . bids [ i ][ 0 ])","title":"select_next_player"},{"location":"api/#kamaji.auctions.resource.Auction.valuation","text":"Returns the valuation u_n(x) of agent n at allocation x. Source code in kamaji/auctions/resource.py 30 31 32 def valuation ( self , n , x ): \"\"\"Returns the valuation u_n(x) of agent n at allocation x.\"\"\" return self . agents [ n ] . valuation ( x )","title":"valuation"},{"location":"license/","text":"License Kamaji is released under the MIT License. You are free to use, modify, and distribute this software in accordance with the terms outlined in the LICENSE file.","title":"License"},{"location":"license/#license","text":"Kamaji is released under the MIT License. You are free to use, modify, and distribute this software in accordance with the terms outlined in the LICENSE file.","title":"License"},{"location":"methods/","text":"Methods Kamaji supports research in safety-critical multi-agent systems using modern control techniques, including: \ud83d\udee1 Control Barrier Functions (CBFs) Kamaji uses Zeroing Control Barrier Functions to enforce safety constraints: Pairwise agent safety is encoded with functions h_ij(x) A global barrier function H(x) is formed via log-sum-exp When Au\u0302 < b , agents cooperatively adjust control inputs Auction-Based Fairness Agents bid to reduce their safety burden using an internal credit mechanism: Agents submit bids for avoidance credit The credit determines their control effort contribution ( \u2206i ) A VCG-style payment scheme encourages truthful bidding Nominal Control & Correction Each agent has: - A nominal controller (e.g., PID, geometric) - A correction mechanism (e.g., CBF via auction or QP) Correction only activates if safety constraints are violated. Applications Urban Air Mobility (UAM) Formation control Distributed collision avoidance Multi-agent negotiation and fairness","title":"Methods"},{"location":"methods/#methods","text":"Kamaji supports research in safety-critical multi-agent systems using modern control techniques, including:","title":"Methods"},{"location":"methods/#control-barrier-functions-cbfs","text":"Kamaji uses Zeroing Control Barrier Functions to enforce safety constraints: Pairwise agent safety is encoded with functions h_ij(x) A global barrier function H(x) is formed via log-sum-exp When Au\u0302 < b , agents cooperatively adjust control inputs","title":"\ud83d\udee1 Control Barrier Functions (CBFs)"},{"location":"methods/#auction-based-fairness","text":"Agents bid to reduce their safety burden using an internal credit mechanism: Agents submit bids for avoidance credit The credit determines their control effort contribution ( \u2206i ) A VCG-style payment scheme encourages truthful bidding","title":"Auction-Based Fairness"},{"location":"methods/#nominal-control-correction","text":"Each agent has: - A nominal controller (e.g., PID, geometric) - A correction mechanism (e.g., CBF via auction or QP) Correction only activates if safety constraints are violated.","title":"Nominal Control &amp; Correction"},{"location":"methods/#applications","text":"Urban Air Mobility (UAM) Formation control Distributed collision avoidance Multi-agent negotiation and fairness","title":"Applications"},{"location":"api/agent/","text":"View Agent class kamaji.agent.Agent Source code in kamaji/agent/agent.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 class Agent : def __init__ ( self , agent_config , t = 0.0 , dt = 0.01 , ** kwargs ): for key , value in kwargs . items (): setattr ( self , key , value ) self . budget = 1 self . _agent_config = agent_config self . manual_control_input = None self . _dt = dt self . _id = agent_config [ 'id' ] self . _state = agent_config [ 'initial_state' ] self . _state_list = list ( self . _state . keys ()) self . _state_history = pd . DataFrame ( columns = [ 'time' ] + self . _state_list ) self . _state_history . loc [ len ( self . _state_history )] = { 'time' : t } | self . _state self . assign_dynamics () self . assign_controller () self . _control_list = self . dynamics_model . control_variables () self . _control_history = pd . DataFrame ( columns = [ 'time' ] + self . _control_list ) # Validate control alignment required_controls = len ( self . _control_list ) if hasattr ( self , 'control_model' ) and isinstance ( self . control_model , dict ): provided = len ( self . control_model ) if required_controls != provided : raise ValueError ( f \"[Agent: { self . _id } ] Control mismatch: dynamics model expects { required_controls } controls \" f \"but controller provides { provided } .\" ) def assign_dynamics ( self ): model_map = { \"Unicycle\" : Unicycle , \"CruiseControl\" : CruiseControl , \"SingleIntegrator1DOF\" : SingleIntegrator1DOF , \"SingleIntegrator2DOF\" : SingleIntegrator2DOF , \"SingleIntegrator3DOF\" : SingleIntegrator3DOF , \"DoubleIntegrator1DOF\" : DoubleIntegrator1DOF , \"DoubleIntegrator2DOF\" : DoubleIntegrator2DOF , \"DoubleIntegrator3DOF\" : DoubleIntegrator3DOF , } model_name = self . _agent_config [ 'dynamics_model' ] if model_name not in model_map : raise NotImplementedError ( f \" { model_name } is not a valid dynamics model.\" ) self . dynamics_model = model_map [ model_name ]( self . _dt ) # def assign_controller(self): # controller_cfg = self._agent_config.get(\"controller\", {}) # if not isinstance(controller_cfg, dict): # raise ValueError(\"Controller must be a dictionary of control channels with 'type' fields.\") # self.control_model = {} # for ctrl_name, ctrl_data in controller_cfg.items(): # ctrl_type = ctrl_data[\"type\"] # if ctrl_type == \"Constant\": # val = ctrl_data[\"value\"] # self.control_model[ctrl_name] = lambda t, state, v=val: v # elif ctrl_type == \"PID\": # spec = ctrl_data.get(\"specs\", [])[0] # self.control_model[ctrl_name] = PID( # [spec[\"state\"]], # [spec[\"goal\"]], # [spec[\"kp\"]], # [spec[\"ki\"]], # [spec[\"kd\"]], # dt=self._dt # ) # else: # raise ValueError(f\"Unknown controller type '{ctrl_type}' for {ctrl_name}\") def assign_controller ( self ): controller_cfg = self . _agent_config . get ( \"controller\" , {}) if not isinstance ( controller_cfg , dict ): raise ValueError ( \"Controller must be a dictionary of control channels with 'type' and 'specs'.\" ) self . control_model = {} for ctrl_name , ctrl_data in controller_cfg . items (): ctrl_type = ctrl_data [ \"type\" ] specs = ctrl_data . get ( \"specs\" , []) if not isinstance ( specs , list ) or len ( specs ) != 1 : raise ValueError ( f \"[Agent: { self . _id } ] Controller ' { ctrl_name } ' must have a single-item specs list.\" ) spec = specs [ 0 ] if ctrl_type == \"Constant\" : if \"value\" not in spec : raise ValueError ( f \"Constant controller for ' { ctrl_name } ' must specify 'value'\" ) val = spec [ \"value\" ] self . control_model [ ctrl_name ] = lambda t , state , v = val : v elif ctrl_type == \"PID\" : required_keys = [ \"state\" , \"goal\" , \"kp\" , \"ki\" , \"kd\" ] if not all ( k in spec for k in required_keys ): raise ValueError ( f \"PID controller for ' { ctrl_name } ' must contain { required_keys } \" ) self . control_model [ ctrl_name ] = PID ( [ spec [ \"state\" ]], [ spec [ \"goal\" ]], [ spec [ \"kp\" ]], [ spec [ \"ki\" ]], [ spec [ \"kd\" ]], dt = self . _dt ) else : raise ValueError ( f \"Unknown controller type ' { ctrl_type } ' for { ctrl_name } \" ) def compute_control ( self , t ) -> np . ndarray : \"\"\" Compute the full control vector by combining per-channel control outputs. Args: t (float): Current simulation time. Returns: np.ndarray: Control vector of shape (n_controls,) \"\"\" current_state = self . _state # For backward compatibility, support legacy controller format if isinstance ( self . control_model , dict ): control_channels = sorted ( self . control_model . keys ()) control_vector = [] for channel in control_channels : controller = self . control_model [ channel ] val = controller . update ( t , current_state ) if hasattr ( controller , \"update\" ) else controller ( t , current_state ) if isinstance ( val , ( list , tuple , np . ndarray )): control_vector . extend ( np . asarray ( val ) . flatten ()) else : control_vector . append ( val ) return np . array ( control_vector ) else : # Fallback for legacy single controller return self . control_model . update ( t , current_state ) def compute_dynamics ( self , t , control_input : np . ndarray ) -> np . ndarray : return self . dynamics_model . dynamics ( t , self . _state , control_input ) def step ( self , t : float , control_input : np . ndarray ) -> None : self . _state_order = list ( self . _state . keys ()) state_vec = np . array ([ self . _state [ k ] for k in self . _state_order ]) def compute_dynamics ( t_local , y , u ): return self . dynamics_model . dynamics ( t_local , { k : y [ i ] for i , k in enumerate ( self . _state_order )}, u ) _ , new_state_vec = ode . rk4_step ( compute_dynamics , t , state_vec , control_input , self . _dt ) new_state_dict = { k : new_state_vec [ i ] for i , k in enumerate ( self . _state_order )} self . _state = new_state_dict self . _state_history . loc [ len ( self . _state_history )] = { 'time' : t } | self . _state control_row = { 'time' : t } control_row . update ({ name : control_input [ i ] for i , name in enumerate ( self . _control_list )}) self . _control_history . loc [ len ( self . _control_history )] = control_row def set_valuation ( self , fn : Callable ): self . valuation_fn = fn def set_marginal_valuation ( self , fn : Callable ): self . marginal_valuation_fn = fn def valuation ( self , x ): return self . valuation_fn ( x ) def marginal_valuation ( self , x ): return self . marginal_valuation_fn ( x ) @property def state ( self ): return self . _state @property def state_log ( self ): return self . _state_history @property def control_log ( self ): return self . _control_history compute_control ( t ) Compute the full control vector by combining per-channel control outputs. Parameters: t ( float ) \u2013 Current simulation time. Returns: ndarray \u2013 np.ndarray: Control vector of shape (n_controls,) Source code in kamaji/agent/agent.py 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def compute_control ( self , t ) -> np . ndarray : \"\"\" Compute the full control vector by combining per-channel control outputs. Args: t (float): Current simulation time. Returns: np.ndarray: Control vector of shape (n_controls,) \"\"\" current_state = self . _state # For backward compatibility, support legacy controller format if isinstance ( self . control_model , dict ): control_channels = sorted ( self . control_model . keys ()) control_vector = [] for channel in control_channels : controller = self . control_model [ channel ] val = controller . update ( t , current_state ) if hasattr ( controller , \"update\" ) else controller ( t , current_state ) if isinstance ( val , ( list , tuple , np . ndarray )): control_vector . extend ( np . asarray ( val ) . flatten ()) else : control_vector . append ( val ) return np . array ( control_vector ) else : # Fallback for legacy single controller return self . control_model . update ( t , current_state )","title":"Agent"},{"location":"api/agent/#kamaji.agent.Agent","text":"Source code in kamaji/agent/agent.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 class Agent : def __init__ ( self , agent_config , t = 0.0 , dt = 0.01 , ** kwargs ): for key , value in kwargs . items (): setattr ( self , key , value ) self . budget = 1 self . _agent_config = agent_config self . manual_control_input = None self . _dt = dt self . _id = agent_config [ 'id' ] self . _state = agent_config [ 'initial_state' ] self . _state_list = list ( self . _state . keys ()) self . _state_history = pd . DataFrame ( columns = [ 'time' ] + self . _state_list ) self . _state_history . loc [ len ( self . _state_history )] = { 'time' : t } | self . _state self . assign_dynamics () self . assign_controller () self . _control_list = self . dynamics_model . control_variables () self . _control_history = pd . DataFrame ( columns = [ 'time' ] + self . _control_list ) # Validate control alignment required_controls = len ( self . _control_list ) if hasattr ( self , 'control_model' ) and isinstance ( self . control_model , dict ): provided = len ( self . control_model ) if required_controls != provided : raise ValueError ( f \"[Agent: { self . _id } ] Control mismatch: dynamics model expects { required_controls } controls \" f \"but controller provides { provided } .\" ) def assign_dynamics ( self ): model_map = { \"Unicycle\" : Unicycle , \"CruiseControl\" : CruiseControl , \"SingleIntegrator1DOF\" : SingleIntegrator1DOF , \"SingleIntegrator2DOF\" : SingleIntegrator2DOF , \"SingleIntegrator3DOF\" : SingleIntegrator3DOF , \"DoubleIntegrator1DOF\" : DoubleIntegrator1DOF , \"DoubleIntegrator2DOF\" : DoubleIntegrator2DOF , \"DoubleIntegrator3DOF\" : DoubleIntegrator3DOF , } model_name = self . _agent_config [ 'dynamics_model' ] if model_name not in model_map : raise NotImplementedError ( f \" { model_name } is not a valid dynamics model.\" ) self . dynamics_model = model_map [ model_name ]( self . _dt ) # def assign_controller(self): # controller_cfg = self._agent_config.get(\"controller\", {}) # if not isinstance(controller_cfg, dict): # raise ValueError(\"Controller must be a dictionary of control channels with 'type' fields.\") # self.control_model = {} # for ctrl_name, ctrl_data in controller_cfg.items(): # ctrl_type = ctrl_data[\"type\"] # if ctrl_type == \"Constant\": # val = ctrl_data[\"value\"] # self.control_model[ctrl_name] = lambda t, state, v=val: v # elif ctrl_type == \"PID\": # spec = ctrl_data.get(\"specs\", [])[0] # self.control_model[ctrl_name] = PID( # [spec[\"state\"]], # [spec[\"goal\"]], # [spec[\"kp\"]], # [spec[\"ki\"]], # [spec[\"kd\"]], # dt=self._dt # ) # else: # raise ValueError(f\"Unknown controller type '{ctrl_type}' for {ctrl_name}\") def assign_controller ( self ): controller_cfg = self . _agent_config . get ( \"controller\" , {}) if not isinstance ( controller_cfg , dict ): raise ValueError ( \"Controller must be a dictionary of control channels with 'type' and 'specs'.\" ) self . control_model = {} for ctrl_name , ctrl_data in controller_cfg . items (): ctrl_type = ctrl_data [ \"type\" ] specs = ctrl_data . get ( \"specs\" , []) if not isinstance ( specs , list ) or len ( specs ) != 1 : raise ValueError ( f \"[Agent: { self . _id } ] Controller ' { ctrl_name } ' must have a single-item specs list.\" ) spec = specs [ 0 ] if ctrl_type == \"Constant\" : if \"value\" not in spec : raise ValueError ( f \"Constant controller for ' { ctrl_name } ' must specify 'value'\" ) val = spec [ \"value\" ] self . control_model [ ctrl_name ] = lambda t , state , v = val : v elif ctrl_type == \"PID\" : required_keys = [ \"state\" , \"goal\" , \"kp\" , \"ki\" , \"kd\" ] if not all ( k in spec for k in required_keys ): raise ValueError ( f \"PID controller for ' { ctrl_name } ' must contain { required_keys } \" ) self . control_model [ ctrl_name ] = PID ( [ spec [ \"state\" ]], [ spec [ \"goal\" ]], [ spec [ \"kp\" ]], [ spec [ \"ki\" ]], [ spec [ \"kd\" ]], dt = self . _dt ) else : raise ValueError ( f \"Unknown controller type ' { ctrl_type } ' for { ctrl_name } \" ) def compute_control ( self , t ) -> np . ndarray : \"\"\" Compute the full control vector by combining per-channel control outputs. Args: t (float): Current simulation time. Returns: np.ndarray: Control vector of shape (n_controls,) \"\"\" current_state = self . _state # For backward compatibility, support legacy controller format if isinstance ( self . control_model , dict ): control_channels = sorted ( self . control_model . keys ()) control_vector = [] for channel in control_channels : controller = self . control_model [ channel ] val = controller . update ( t , current_state ) if hasattr ( controller , \"update\" ) else controller ( t , current_state ) if isinstance ( val , ( list , tuple , np . ndarray )): control_vector . extend ( np . asarray ( val ) . flatten ()) else : control_vector . append ( val ) return np . array ( control_vector ) else : # Fallback for legacy single controller return self . control_model . update ( t , current_state ) def compute_dynamics ( self , t , control_input : np . ndarray ) -> np . ndarray : return self . dynamics_model . dynamics ( t , self . _state , control_input ) def step ( self , t : float , control_input : np . ndarray ) -> None : self . _state_order = list ( self . _state . keys ()) state_vec = np . array ([ self . _state [ k ] for k in self . _state_order ]) def compute_dynamics ( t_local , y , u ): return self . dynamics_model . dynamics ( t_local , { k : y [ i ] for i , k in enumerate ( self . _state_order )}, u ) _ , new_state_vec = ode . rk4_step ( compute_dynamics , t , state_vec , control_input , self . _dt ) new_state_dict = { k : new_state_vec [ i ] for i , k in enumerate ( self . _state_order )} self . _state = new_state_dict self . _state_history . loc [ len ( self . _state_history )] = { 'time' : t } | self . _state control_row = { 'time' : t } control_row . update ({ name : control_input [ i ] for i , name in enumerate ( self . _control_list )}) self . _control_history . loc [ len ( self . _control_history )] = control_row def set_valuation ( self , fn : Callable ): self . valuation_fn = fn def set_marginal_valuation ( self , fn : Callable ): self . marginal_valuation_fn = fn def valuation ( self , x ): return self . valuation_fn ( x ) def marginal_valuation ( self , x ): return self . marginal_valuation_fn ( x ) @property def state ( self ): return self . _state @property def state_log ( self ): return self . _state_history @property def control_log ( self ): return self . _control_history","title":"Agent"},{"location":"api/agent/#kamaji.agent.Agent.compute_control","text":"Compute the full control vector by combining per-channel control outputs. Parameters: t ( float ) \u2013 Current simulation time. Returns: ndarray \u2013 np.ndarray: Control vector of shape (n_controls,) Source code in kamaji/agent/agent.py 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def compute_control ( self , t ) -> np . ndarray : \"\"\" Compute the full control vector by combining per-channel control outputs. Args: t (float): Current simulation time. Returns: np.ndarray: Control vector of shape (n_controls,) \"\"\" current_state = self . _state # For backward compatibility, support legacy controller format if isinstance ( self . control_model , dict ): control_channels = sorted ( self . control_model . keys ()) control_vector = [] for channel in control_channels : controller = self . control_model [ channel ] val = controller . update ( t , current_state ) if hasattr ( controller , \"update\" ) else controller ( t , current_state ) if isinstance ( val , ( list , tuple , np . ndarray )): control_vector . extend ( np . asarray ( val ) . flatten ()) else : control_vector . append ( val ) return np . array ( control_vector ) else : # Fallback for legacy single controller return self . control_model . update ( t , current_state )","title":"compute_control"},{"location":"api/auction/","text":"View Auction class kamaji.auctions.resource.Auction Source code in kamaji/auctions/resource.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 class Auction : def __init__ ( self , agents , Gamma , bids , alpha = 0.99 , rho_bar = 2 , rho = 0.5 , epsilon = 1e-4 ): \"\"\" Initialize the Auction class for decentralized divisible resource allocation. Args: agents (List[Agent]): List of Agent objects with valuation functions. Gamma (float): Total amount of divisible resource to allocate. bids (List[Tuple[float, float]]): Initial bids for each agent, in (\u03b2, d) format. alpha (float): Smoothing parameter for computing constrained demand. rho_bar (float): Upper bound on dynamic response term for constrained demand. rho (float): Smoothing factor for current demand vs. allocation. epsilon (float): Convergence threshold for bid updates. \"\"\" self . agents = agents self . N = len ( agents ) self . Gamma = Gamma self . alpha = alpha self . rho_bar = rho_bar self . rho = rho self . epsilon = epsilon self . bids = bids self . history = [ self . bids . copy ()] # Log of all bids over time def valuation ( self , n , x ): \"\"\"Returns the valuation u_n(x) of agent n at allocation x.\"\"\" return self . agents [ n ] . valuation ( x ) def marginal_valuation ( self , n , x ): \"\"\"Returns the marginal valuation u_n'(x) of agent n at allocation x.\"\"\" return self . agents [ n ] . marginal_valuation ( x ) def allocation ( self , bids ): \"\"\" Computes allocation vector from current bids using descending sort of \u03b2 with random tie-breaking. Args: bids (List[Tuple[float, float]]): Bids as list of (\u03b2, d) pairs. Returns: np.ndarray: Allocated resource vector x for all agents. \"\"\" indexed_bids = [( i , b [ 0 ], b [ 1 ], random . random ()) for i , b in enumerate ( bids )] beta_sorted = sorted ( indexed_bids , key = lambda x : ( - x [ 1 ], x [ 3 ])) x = np . zeros ( self . N ) remaining = self . Gamma for i , beta , d , _ in beta_sorted : x [ i ] = min ( d , remaining ) remaining -= x [ i ] if remaining <= 0 : break return x def payment ( self , bids , n ): \"\"\" Computes VCG payment for agent n using Clarke pivot rule. Args: bids (List[Tuple[float, float]]): Current bids. n (int): Agent index. Returns: float: Payment \u03c4_n agent n must pay. \"\"\" b_without_n = bids . copy () b_without_n [ n ] = ( bids [ n ][ 0 ], 0.0 ) x_without = self . allocation ( b_without_n ) return sum ( bids [ m ][ 0 ] * ( x_without [ m ] - self . x [ m ]) for m in range ( self . N ) if m != n ) def payoff ( self , n , bids ): \"\"\" Computes payoff for agent n given current bids. Args: n (int): Agent index. bids (List[Tuple[float, float]]): Bid profile. Returns: float: Payoff for agent n. \"\"\" x = self . allocation ( bids ) \u03c4 = self . payment ( bids , n ) return self . valuation ( n , x [ n ]) - \u03c4 def constrained_demand ( self , n , bids ): \"\"\" Computes upper bound for agent n's demand based on dynamic constraints. Args: n (int): Agent index. bids (List[Tuple[float, float]]): Bid profile. Returns: float: Constrained upper bound on agent n's demand. \"\"\" \u0393c = max ( 0 , self . Gamma - sum ( d for _ , d in bids )) \u03b2n , dn = bids [ n ] m = self . find_m ( n , bids ) dm = bids [ m ][ 1 ] if m is not None else 0 \u03b2m = bids [ m ][ 0 ] if m is not None else 0 \u03a6 = max ( 0 , ( \u03b2n - \u03b2m + self . rho * ( dn - self . x [ n ]) + 0.5 * self . rho_bar * \u0393c )) / self . rho_bar upper_bound = self . x [ n ] + min ( dm + \u0393c , self . alpha * \u03a6 , ( 2 / self . rho_bar ) * \u03b2n ) return upper_bound def find_m ( self , n , bids ): \"\"\" Finds the lowest priced winning agent (other than agent n). Args: n (int): Agent index. bids (List[Tuple[float, float]]): Bid profile. Returns: int: Index of agent m, or None if none found. \"\"\" lowest = float ( 'inf' ) idx = None for i in range ( self . N ): if i == n or self . x [ i ] == 0 : continue \u03b2 = bids [ i ][ 0 ] if \u03b2 < lowest or ( \u03b2 == lowest and ( idx is None or i < idx )): lowest = \u03b2 idx = i return idx def best_response ( self , n , bids ): \"\"\" Computes agent n's best response by optimizing payoff w.r.t. demand. Args: n (int): Agent index. bids (List[Tuple[float, float]]): Current bids. Returns: Tuple[float, float]: New bid (\u03b2, d) for agent n. \"\"\" upper = self . constrained_demand ( n , bids ) lower = self . x [ n ] def neg_payoff ( d ): \u03b2 = self . marginal_valuation ( n , d ) # true_beta = self.marginal_valuation(n, d) # budget = self.agents[n].budget # if budget <= 0: # scaled_beta = 0.0 # else: # scaling = budget / (budget + 1e-3) # scaled_beta = scaling * true_beta # Scaling factor \u2014 adjust if you want soft capping # scaling = budget / (budget + 1e-6) # avoid divide-by-zero # In your budget-weighted bid scaling: # Instead of soft scaling, use aggressive squashing: # scaling = self.agents[n].budget / (self.agents[n].budget + 0.01) # scaled_beta = scaling * true_beta # effective_beta = scaling * true_beta temp_bids = bids . copy () temp_bids [ n ] = ( \u03b2 , d ) # temp_bids[n] = (scaled_beta, d) return - self . payoff ( n , temp_bids ) res = minimize_scalar ( neg_payoff , bounds = ( lower , upper ), method = 'bounded' ) best_d = res . x \u03b2_best = self . marginal_valuation ( n , best_d ) return ( \u03b2_best , best_d ) # def best_response(self, n, bids): # \"\"\" # Computes agent n's best response by optimizing payoff with respect to demand, # using budget-aware bid scaling. # Args: # n (int): Agent index. # bids (List[Tuple[float, float]]): Current bid profile. # Returns: # Tuple[float, float]: New bid (\u03b2, d) for agent n. # \"\"\" # upper = self.constrained_demand(n, bids) # lower = self.x[n] # budget = self.agents[n].budget # # If agent is broke, skip optimization and return (0, 0) # if budget <= 0: # return (0.0, 0.0) # def neg_payoff(d): # true_beta = self.marginal_valuation(n, d) # scaling = budget / (budget + 1e-3) # aggressive scaling # scaled_beta = scaling * true_beta # temp_bids = bids.copy() # temp_bids[n] = (scaled_beta, d) # return -self.payoff(n, temp_bids) # res = minimize_scalar(neg_payoff, bounds=(lower, upper), method='bounded') # best_d = res.x # # Recompute scaled bid for this d # true_beta = self.marginal_valuation(n, best_d) # scaling = budget / (budget + 1e-3) # scaled_beta = scaling * true_beta # return (scaled_beta, best_d) def compute_payments_from_delta ( self , S ): \"\"\" Computes VCG payments based on the avoidance effort (Delta) using each agent's actual valuation function. Args: S (float): Total safety correction required (i.e., safety deficit). Returns: List[float]: VCG payments based on Delta externality. \"\"\" # Step 1: Final credit allocation (after auction) c = np . array ([ bid [ 1 ] for bid in self . bids ]) Delta = ( 1 - c ) * S / np . sum ( 1 - c ) print ( f \"\u0394: { [ round ( d , 4 ) for d in Delta ] } \" ) print ( \"Valuations of others with agent present:\" , [ round ( agent . valuation ( d ), 4 ) for i , ( agent , d ) in enumerate ( zip ( self . agents , Delta )) if i != 0 ]) # Then repeat with agent 1 removed (\u0394_wo_1) N = self . N payments = [] for i in range ( N ): # Step 2: Recompute allocation with agent i set to full credit (no burden) c_mod = c . copy () c_mod [ i ] = 1.0 denom = np . sum ( 1 - c_mod ) if denom == 0 : Delta_wo_i = np . zeros ( N ) else : Delta_wo_i = ( 1 - c_mod ) * S / denom # Step 3: Use agent-provided valuation functions to compute disutility welfare_wo_i = sum ( - self . agents [ j ] . valuation ( Delta_wo_i [ j ]) for j in range ( N ) if j != i ) welfare_with_i = sum ( - self . agents [ j ] . valuation ( Delta [ j ]) for j in range ( N ) if j != i ) # Step 4: VCG payment is the externality agent i imposes tau_i = welfare_wo_i - welfare_with_i payments . append ( tau_i ) return payments def select_next_player ( self ): \"\"\" Selects the next agent to update their bid based on allocation status. Returns: int: Index of next player. \"\"\" for i in range ( self . N ): \u03b2 , d = self . bids [ i ] if self . x [ i ] < d and self . x [ i ] > 0 : return i for i in range ( self . N ): \u03b2 , d = self . bids [ i ] if self . x [ i ] == 0 and d > 0 : return i return max ( range ( self . N ), key = lambda i : self . bids [ i ][ 0 ]) def run ( self , max_steps = 10000 ): \"\"\" Runs the auction process until convergence or max iterations. Args: max_steps (int): Maximum allowed iterations. Returns: Tuple[List[Tuple[float, float]], np.ndarray]: Final bid profile and allocation. \"\"\" k = 0 update_log = [] while k < max_steps : bids_old = self . bids . copy () self . x = self . allocation ( self . bids ) n = self . select_next_player () self . bids [ n ] = self . best_response ( n , self . bids ) self . history . append ( self . bids . copy ()) update_log . append ( n ) if len ( update_log ) >= self . N : recent = update_log [ - self . N :] all_updated = set ( recent ) == set ( range ( self . N )) delta = sum ( abs ( self . bids [ i ][ 1 ] - bids_old [ i ][ 1 ]) + abs ( self . bids [ i ][ 0 ] - bids_old [ i ][ 0 ]) for i in range ( self . N )) if all_updated and delta < self . epsilon : break k += 1 return self . bids , self . allocation ( self . bids ) # def compute_payments(self): # \"\"\" # Computes VCG payments for each agent after auction ends. # Returns: # List[float]: Payment \u03c4_i for each agent. # \"\"\" # self.x = self.allocation(self.bids) # return [self.payment(self.bids, n) for n in range(self.N)] # def compute_payments(self): # self.x = self.allocation(self.bids) # payments = [] # for n in range(self.N): # bids_wo_n = self.bids.copy() # bids_wo_n[n] = (self.bids[n][0], 0.0) # x_wo_n = self.allocation(bids_wo_n) # print(f\"\\nAgent {n} removal:\") # for m in range(self.N): # if m != n: # print(f\" Agent {m}: x_with = {self.x[m]:.4f}, x_wo_n = {x_wo_n[m]:.4f}\") # payment = sum(self.bids[m][0] * (x_wo_n[m] - self.x[m]) for m in range(self.N) if m != n) # print(f\" Payment \u03c4_{n} = {payment:.4f}\") # payments.append(payment) # return payments def compute_payments ( self ): \"\"\" Computes VCG payments for each agent using Clarke pivot rule with full reallocation. Assumes agents will reoptimize demand if another agent exits, so all \u0393 is consumed. \"\"\" self . x = self . allocation ( self . bids ) payments = [] for n in range ( self . N ): # 1. Remove agent n from allocation bids_wo_n = self . bids . copy () bids_wo_n [ n ] = ( self . bids [ n ][ 0 ], 0.0 ) # 2. Redistribute \u0393 among remaining agents proportionally to their marginal value total_beta = sum ( b [ 0 ] for i , b in enumerate ( bids_wo_n ) if i != n ) if total_beta == 0 : # No one else wants anything \u2014 payment is 0 payments . append ( 0.0 ) continue # 3. New demand: distribute Gamma proportionally to \u03b2 new_bids = [] for i , ( beta , _ ) in enumerate ( bids_wo_n ): if i == n : new_bids . append (( beta , 0.0 )) else : new_demand = self . Gamma * ( beta / total_beta ) new_bids . append (( beta , new_demand )) # 4. Compute new allocation x_wo_n = self . allocation ( new_bids ) # 5. Compute externality (benefit to others) externality = sum ( self . bids [ m ][ 0 ] * ( x_wo_n [ m ] - self . x [ m ]) for m in range ( self . N ) if m != n ) payments . append ( externality ) return payments def compute_payments_vcg ( self ): \"\"\" Computes externality-based VCG-style payments by re-running auction without each agent. Returns: List[float]: Payments for each agent. \"\"\" self . x = self . allocation ( self . bids ) return [ sum ( self . bids [ j ][ 0 ] * ( self . run_without_agent ( i )[ j ] - self . x [ j ]) for j in range ( self . N ) if j != i ) for i in range ( self . N ) ] def reset ( self , agents , bids ): \"\"\" Resets the auction environment to a new configuration. Args: agents (List[Agent]): New agent list. bids (List[Tuple[float, float]]): New initial bids. \"\"\" self . agents = agents self . N = len ( agents ) self . bids = bids . copy () self . history = [ self . bids . copy ()] self . x = np . zeros ( self . N ) def run_without_agent ( self , remove_index ): \"\"\" Runs auction without a specific agent, used for computing VCG payments. Args: remove_index (int): Index of agent to exclude. Returns: np.ndarray: Full allocation vector with zero at excluded index. \"\"\" agents_wo = [ a for i , a in enumerate ( self . agents ) if i != remove_index ] init_bids = [( a . marginal_valuation ( 1.0 ), 1.0 ) for a in agents_wo ] auction_wo = Auction ( agents_wo , self . Gamma , init_bids ) _ , alloc_wo = auction_wo . run () full_alloc = np . zeros ( self . N ) j = 0 for i in range ( self . N ): if i == remove_index : continue full_alloc [ i ] = alloc_wo [ j ] j += 1 return full_alloc def plot_bid_demand_over_time ( self ): \"\"\"Plots demand bids over the course of the auction.\"\"\" for i in range ( self . N ): plt . plot ([ step [ i ][ 1 ] for step in self . history ], label = f 'Player { i + 1 } ' ) plt . title ( 'Bid Demand Over Iterations' ) plt . xlabel ( 'Iteration' ) plt . ylabel ( 'Demand (d)' ) plt . legend () plt . grid ( True ) plt . tight_layout () plt . show () def plot_bid_price_over_time ( self ): \"\"\"Plots price bids (\u03b2) over the course of the auction.\"\"\" for i in range ( self . N ): plt . plot ([ step [ i ][ 0 ] for step in self . history ], label = f 'Player { i + 1 } ' ) plt . title ( 'Bid Price Over Iterations' ) plt . xlabel ( 'Iteration' ) plt . ylabel ( 'Bid Price (\u03b2)' ) plt . legend () plt . grid ( True ) plt . tight_layout () plt . show () __init__ ( agents , Gamma , bids , alpha = 0.99 , rho_bar = 2 , rho = 0.5 , epsilon = 0.0001 ) Initialize the Auction class for decentralized divisible resource allocation. Parameters: agents ( List [ Agent ] ) \u2013 List of Agent objects with valuation functions. Gamma ( float ) \u2013 Total amount of divisible resource to allocate. bids ( List [ Tuple [ float , float ]] ) \u2013 Initial bids for each agent, in (\u03b2, d) format. alpha ( float , default: 0.99 ) \u2013 Smoothing parameter for computing constrained demand. rho_bar ( float , default: 2 ) \u2013 Upper bound on dynamic response term for constrained demand. rho ( float , default: 0.5 ) \u2013 Smoothing factor for current demand vs. allocation. epsilon ( float , default: 0.0001 ) \u2013 Convergence threshold for bid updates. Source code in kamaji/auctions/resource.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 def __init__ ( self , agents , Gamma , bids , alpha = 0.99 , rho_bar = 2 , rho = 0.5 , epsilon = 1e-4 ): \"\"\" Initialize the Auction class for decentralized divisible resource allocation. Args: agents (List[Agent]): List of Agent objects with valuation functions. Gamma (float): Total amount of divisible resource to allocate. bids (List[Tuple[float, float]]): Initial bids for each agent, in (\u03b2, d) format. alpha (float): Smoothing parameter for computing constrained demand. rho_bar (float): Upper bound on dynamic response term for constrained demand. rho (float): Smoothing factor for current demand vs. allocation. epsilon (float): Convergence threshold for bid updates. \"\"\" self . agents = agents self . N = len ( agents ) self . Gamma = Gamma self . alpha = alpha self . rho_bar = rho_bar self . rho = rho self . epsilon = epsilon self . bids = bids self . history = [ self . bids . copy ()] # Log of all bids over time allocation ( bids ) Computes allocation vector from current bids using descending sort of \u03b2 with random tie-breaking. Parameters: bids ( List [ Tuple [ float , float ]] ) \u2013 Bids as list of (\u03b2, d) pairs. Returns: \u2013 np.ndarray: Allocated resource vector x for all agents. Source code in kamaji/auctions/resource.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 def allocation ( self , bids ): \"\"\" Computes allocation vector from current bids using descending sort of \u03b2 with random tie-breaking. Args: bids (List[Tuple[float, float]]): Bids as list of (\u03b2, d) pairs. Returns: np.ndarray: Allocated resource vector x for all agents. \"\"\" indexed_bids = [( i , b [ 0 ], b [ 1 ], random . random ()) for i , b in enumerate ( bids )] beta_sorted = sorted ( indexed_bids , key = lambda x : ( - x [ 1 ], x [ 3 ])) x = np . zeros ( self . N ) remaining = self . Gamma for i , beta , d , _ in beta_sorted : x [ i ] = min ( d , remaining ) remaining -= x [ i ] if remaining <= 0 : break return x best_response ( n , bids ) Computes agent n's best response by optimizing payoff w.r.t. demand. Parameters: n ( int ) \u2013 Agent index. bids ( List [ Tuple [ float , float ]] ) \u2013 Current bids. Returns: \u2013 Tuple[float, float]: New bid (\u03b2, d) for agent n. Source code in kamaji/auctions/resource.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 def best_response ( self , n , bids ): \"\"\" Computes agent n's best response by optimizing payoff w.r.t. demand. Args: n (int): Agent index. bids (List[Tuple[float, float]]): Current bids. Returns: Tuple[float, float]: New bid (\u03b2, d) for agent n. \"\"\" upper = self . constrained_demand ( n , bids ) lower = self . x [ n ] def neg_payoff ( d ): \u03b2 = self . marginal_valuation ( n , d ) # true_beta = self.marginal_valuation(n, d) # budget = self.agents[n].budget # if budget <= 0: # scaled_beta = 0.0 # else: # scaling = budget / (budget + 1e-3) # scaled_beta = scaling * true_beta # Scaling factor \u2014 adjust if you want soft capping # scaling = budget / (budget + 1e-6) # avoid divide-by-zero # In your budget-weighted bid scaling: # Instead of soft scaling, use aggressive squashing: # scaling = self.agents[n].budget / (self.agents[n].budget + 0.01) # scaled_beta = scaling * true_beta # effective_beta = scaling * true_beta temp_bids = bids . copy () temp_bids [ n ] = ( \u03b2 , d ) # temp_bids[n] = (scaled_beta, d) return - self . payoff ( n , temp_bids ) res = minimize_scalar ( neg_payoff , bounds = ( lower , upper ), method = 'bounded' ) best_d = res . x \u03b2_best = self . marginal_valuation ( n , best_d ) return ( \u03b2_best , best_d ) compute_payments () Computes VCG payments for each agent using Clarke pivot rule with full reallocation. Assumes agents will reoptimize demand if another agent exits, so all \u0393 is consumed. Source code in kamaji/auctions/resource.py 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 def compute_payments ( self ): \"\"\" Computes VCG payments for each agent using Clarke pivot rule with full reallocation. Assumes agents will reoptimize demand if another agent exits, so all \u0393 is consumed. \"\"\" self . x = self . allocation ( self . bids ) payments = [] for n in range ( self . N ): # 1. Remove agent n from allocation bids_wo_n = self . bids . copy () bids_wo_n [ n ] = ( self . bids [ n ][ 0 ], 0.0 ) # 2. Redistribute \u0393 among remaining agents proportionally to their marginal value total_beta = sum ( b [ 0 ] for i , b in enumerate ( bids_wo_n ) if i != n ) if total_beta == 0 : # No one else wants anything \u2014 payment is 0 payments . append ( 0.0 ) continue # 3. New demand: distribute Gamma proportionally to \u03b2 new_bids = [] for i , ( beta , _ ) in enumerate ( bids_wo_n ): if i == n : new_bids . append (( beta , 0.0 )) else : new_demand = self . Gamma * ( beta / total_beta ) new_bids . append (( beta , new_demand )) # 4. Compute new allocation x_wo_n = self . allocation ( new_bids ) # 5. Compute externality (benefit to others) externality = sum ( self . bids [ m ][ 0 ] * ( x_wo_n [ m ] - self . x [ m ]) for m in range ( self . N ) if m != n ) payments . append ( externality ) return payments compute_payments_from_delta ( S ) Computes VCG payments based on the avoidance effort (Delta) using each agent's actual valuation function. Parameters: S ( float ) \u2013 Total safety correction required (i.e., safety deficit). Returns: \u2013 List[float]: VCG payments based on Delta externality. Source code in kamaji/auctions/resource.py 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 def compute_payments_from_delta ( self , S ): \"\"\" Computes VCG payments based on the avoidance effort (Delta) using each agent's actual valuation function. Args: S (float): Total safety correction required (i.e., safety deficit). Returns: List[float]: VCG payments based on Delta externality. \"\"\" # Step 1: Final credit allocation (after auction) c = np . array ([ bid [ 1 ] for bid in self . bids ]) Delta = ( 1 - c ) * S / np . sum ( 1 - c ) print ( f \"\u0394: { [ round ( d , 4 ) for d in Delta ] } \" ) print ( \"Valuations of others with agent present:\" , [ round ( agent . valuation ( d ), 4 ) for i , ( agent , d ) in enumerate ( zip ( self . agents , Delta )) if i != 0 ]) # Then repeat with agent 1 removed (\u0394_wo_1) N = self . N payments = [] for i in range ( N ): # Step 2: Recompute allocation with agent i set to full credit (no burden) c_mod = c . copy () c_mod [ i ] = 1.0 denom = np . sum ( 1 - c_mod ) if denom == 0 : Delta_wo_i = np . zeros ( N ) else : Delta_wo_i = ( 1 - c_mod ) * S / denom # Step 3: Use agent-provided valuation functions to compute disutility welfare_wo_i = sum ( - self . agents [ j ] . valuation ( Delta_wo_i [ j ]) for j in range ( N ) if j != i ) welfare_with_i = sum ( - self . agents [ j ] . valuation ( Delta [ j ]) for j in range ( N ) if j != i ) # Step 4: VCG payment is the externality agent i imposes tau_i = welfare_wo_i - welfare_with_i payments . append ( tau_i ) return payments compute_payments_vcg () Computes externality-based VCG-style payments by re-running auction without each agent. Returns: \u2013 List[float]: Payments for each agent. Source code in kamaji/auctions/resource.py 388 389 390 391 392 393 394 395 396 397 398 399 def compute_payments_vcg ( self ): \"\"\" Computes externality-based VCG-style payments by re-running auction without each agent. Returns: List[float]: Payments for each agent. \"\"\" self . x = self . allocation ( self . bids ) return [ sum ( self . bids [ j ][ 0 ] * ( self . run_without_agent ( i )[ j ] - self . x [ j ]) for j in range ( self . N ) if j != i ) for i in range ( self . N ) ] constrained_demand ( n , bids ) Computes upper bound for agent n's demand based on dynamic constraints. Parameters: n ( int ) \u2013 Agent index. bids ( List [ Tuple [ float , float ]] ) \u2013 Bid profile. Returns: float \u2013 Constrained upper bound on agent n's demand. Source code in kamaji/auctions/resource.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 def constrained_demand ( self , n , bids ): \"\"\" Computes upper bound for agent n's demand based on dynamic constraints. Args: n (int): Agent index. bids (List[Tuple[float, float]]): Bid profile. Returns: float: Constrained upper bound on agent n's demand. \"\"\" \u0393c = max ( 0 , self . Gamma - sum ( d for _ , d in bids )) \u03b2n , dn = bids [ n ] m = self . find_m ( n , bids ) dm = bids [ m ][ 1 ] if m is not None else 0 \u03b2m = bids [ m ][ 0 ] if m is not None else 0 \u03a6 = max ( 0 , ( \u03b2n - \u03b2m + self . rho * ( dn - self . x [ n ]) + 0.5 * self . rho_bar * \u0393c )) / self . rho_bar upper_bound = self . x [ n ] + min ( dm + \u0393c , self . alpha * \u03a6 , ( 2 / self . rho_bar ) * \u03b2n ) return upper_bound find_m ( n , bids ) Finds the lowest priced winning agent (other than agent n). Parameters: n ( int ) \u2013 Agent index. bids ( List [ Tuple [ float , float ]] ) \u2013 Bid profile. Returns: int \u2013 Index of agent m, or None if none found. Source code in kamaji/auctions/resource.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 def find_m ( self , n , bids ): \"\"\" Finds the lowest priced winning agent (other than agent n). Args: n (int): Agent index. bids (List[Tuple[float, float]]): Bid profile. Returns: int: Index of agent m, or None if none found. \"\"\" lowest = float ( 'inf' ) idx = None for i in range ( self . N ): if i == n or self . x [ i ] == 0 : continue \u03b2 = bids [ i ][ 0 ] if \u03b2 < lowest or ( \u03b2 == lowest and ( idx is None or i < idx )): lowest = \u03b2 idx = i return idx marginal_valuation ( n , x ) Returns the marginal valuation u_n'(x) of agent n at allocation x. Source code in kamaji/auctions/resource.py 34 35 36 def marginal_valuation ( self , n , x ): \"\"\"Returns the marginal valuation u_n'(x) of agent n at allocation x.\"\"\" return self . agents [ n ] . marginal_valuation ( x ) payment ( bids , n ) Computes VCG payment for agent n using Clarke pivot rule. Parameters: bids ( List [ Tuple [ float , float ]] ) \u2013 Current bids. n ( int ) \u2013 Agent index. Returns: float \u2013 Payment \u03c4_n agent n must pay. Source code in kamaji/auctions/resource.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def payment ( self , bids , n ): \"\"\" Computes VCG payment for agent n using Clarke pivot rule. Args: bids (List[Tuple[float, float]]): Current bids. n (int): Agent index. Returns: float: Payment \u03c4_n agent n must pay. \"\"\" b_without_n = bids . copy () b_without_n [ n ] = ( bids [ n ][ 0 ], 0.0 ) x_without = self . allocation ( b_without_n ) return sum ( bids [ m ][ 0 ] * ( x_without [ m ] - self . x [ m ]) for m in range ( self . N ) if m != n ) payoff ( n , bids ) Computes payoff for agent n given current bids. Parameters: n ( int ) \u2013 Agent index. bids ( List [ Tuple [ float , float ]] ) \u2013 Bid profile. Returns: float \u2013 Payoff for agent n. Source code in kamaji/auctions/resource.py 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def payoff ( self , n , bids ): \"\"\" Computes payoff for agent n given current bids. Args: n (int): Agent index. bids (List[Tuple[float, float]]): Bid profile. Returns: float: Payoff for agent n. \"\"\" x = self . allocation ( bids ) \u03c4 = self . payment ( bids , n ) return self . valuation ( n , x [ n ]) - \u03c4 plot_bid_demand_over_time () Plots demand bids over the course of the auction. Source code in kamaji/auctions/resource.py 439 440 441 442 443 444 445 446 447 448 449 def plot_bid_demand_over_time ( self ): \"\"\"Plots demand bids over the course of the auction.\"\"\" for i in range ( self . N ): plt . plot ([ step [ i ][ 1 ] for step in self . history ], label = f 'Player { i + 1 } ' ) plt . title ( 'Bid Demand Over Iterations' ) plt . xlabel ( 'Iteration' ) plt . ylabel ( 'Demand (d)' ) plt . legend () plt . grid ( True ) plt . tight_layout () plt . show () plot_bid_price_over_time () Plots price bids (\u03b2) over the course of the auction. Source code in kamaji/auctions/resource.py 451 452 453 454 455 456 457 458 459 460 461 def plot_bid_price_over_time ( self ): \"\"\"Plots price bids (\u03b2) over the course of the auction.\"\"\" for i in range ( self . N ): plt . plot ([ step [ i ][ 0 ] for step in self . history ], label = f 'Player { i + 1 } ' ) plt . title ( 'Bid Price Over Iterations' ) plt . xlabel ( 'Iteration' ) plt . ylabel ( 'Bid Price (\u03b2)' ) plt . legend () plt . grid ( True ) plt . tight_layout () plt . show () reset ( agents , bids ) Resets the auction environment to a new configuration. Parameters: agents ( List [ Agent ] ) \u2013 New agent list. bids ( List [ Tuple [ float , float ]] ) \u2013 New initial bids. Source code in kamaji/auctions/resource.py 401 402 403 404 405 406 407 408 409 410 411 412 413 def reset ( self , agents , bids ): \"\"\" Resets the auction environment to a new configuration. Args: agents (List[Agent]): New agent list. bids (List[Tuple[float, float]]): New initial bids. \"\"\" self . agents = agents self . N = len ( agents ) self . bids = bids . copy () self . history = [ self . bids . copy ()] self . x = np . zeros ( self . N ) run ( max_steps = 10000 ) Runs the auction process until convergence or max iterations. Parameters: max_steps ( int , default: 10000 ) \u2013 Maximum allowed iterations. Returns: \u2013 Tuple[List[Tuple[float, float]], np.ndarray]: Final bid profile and allocation. Source code in kamaji/auctions/resource.py 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 def run ( self , max_steps = 10000 ): \"\"\" Runs the auction process until convergence or max iterations. Args: max_steps (int): Maximum allowed iterations. Returns: Tuple[List[Tuple[float, float]], np.ndarray]: Final bid profile and allocation. \"\"\" k = 0 update_log = [] while k < max_steps : bids_old = self . bids . copy () self . x = self . allocation ( self . bids ) n = self . select_next_player () self . bids [ n ] = self . best_response ( n , self . bids ) self . history . append ( self . bids . copy ()) update_log . append ( n ) if len ( update_log ) >= self . N : recent = update_log [ - self . N :] all_updated = set ( recent ) == set ( range ( self . N )) delta = sum ( abs ( self . bids [ i ][ 1 ] - bids_old [ i ][ 1 ]) + abs ( self . bids [ i ][ 0 ] - bids_old [ i ][ 0 ]) for i in range ( self . N )) if all_updated and delta < self . epsilon : break k += 1 return self . bids , self . allocation ( self . bids ) run_without_agent ( remove_index ) Runs auction without a specific agent, used for computing VCG payments. Parameters: remove_index ( int ) \u2013 Index of agent to exclude. Returns: \u2013 np.ndarray: Full allocation vector with zero at excluded index. Source code in kamaji/auctions/resource.py 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 def run_without_agent ( self , remove_index ): \"\"\" Runs auction without a specific agent, used for computing VCG payments. Args: remove_index (int): Index of agent to exclude. Returns: np.ndarray: Full allocation vector with zero at excluded index. \"\"\" agents_wo = [ a for i , a in enumerate ( self . agents ) if i != remove_index ] init_bids = [( a . marginal_valuation ( 1.0 ), 1.0 ) for a in agents_wo ] auction_wo = Auction ( agents_wo , self . Gamma , init_bids ) _ , alloc_wo = auction_wo . run () full_alloc = np . zeros ( self . N ) j = 0 for i in range ( self . N ): if i == remove_index : continue full_alloc [ i ] = alloc_wo [ j ] j += 1 return full_alloc select_next_player () Selects the next agent to update their bid based on allocation status. Returns: int \u2013 Index of next player. Source code in kamaji/auctions/resource.py 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 def select_next_player ( self ): \"\"\" Selects the next agent to update their bid based on allocation status. Returns: int: Index of next player. \"\"\" for i in range ( self . N ): \u03b2 , d = self . bids [ i ] if self . x [ i ] < d and self . x [ i ] > 0 : return i for i in range ( self . N ): \u03b2 , d = self . bids [ i ] if self . x [ i ] == 0 and d > 0 : return i return max ( range ( self . N ), key = lambda i : self . bids [ i ][ 0 ]) valuation ( n , x ) Returns the valuation u_n(x) of agent n at allocation x. Source code in kamaji/auctions/resource.py 30 31 32 def valuation ( self , n , x ): \"\"\"Returns the valuation u_n(x) of agent n at allocation x.\"\"\" return self . agents [ n ] . valuation ( x )","title":"Auction"},{"location":"api/auction/#kamaji.auctions.resource.Auction","text":"Source code in kamaji/auctions/resource.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 class Auction : def __init__ ( self , agents , Gamma , bids , alpha = 0.99 , rho_bar = 2 , rho = 0.5 , epsilon = 1e-4 ): \"\"\" Initialize the Auction class for decentralized divisible resource allocation. Args: agents (List[Agent]): List of Agent objects with valuation functions. Gamma (float): Total amount of divisible resource to allocate. bids (List[Tuple[float, float]]): Initial bids for each agent, in (\u03b2, d) format. alpha (float): Smoothing parameter for computing constrained demand. rho_bar (float): Upper bound on dynamic response term for constrained demand. rho (float): Smoothing factor for current demand vs. allocation. epsilon (float): Convergence threshold for bid updates. \"\"\" self . agents = agents self . N = len ( agents ) self . Gamma = Gamma self . alpha = alpha self . rho_bar = rho_bar self . rho = rho self . epsilon = epsilon self . bids = bids self . history = [ self . bids . copy ()] # Log of all bids over time def valuation ( self , n , x ): \"\"\"Returns the valuation u_n(x) of agent n at allocation x.\"\"\" return self . agents [ n ] . valuation ( x ) def marginal_valuation ( self , n , x ): \"\"\"Returns the marginal valuation u_n'(x) of agent n at allocation x.\"\"\" return self . agents [ n ] . marginal_valuation ( x ) def allocation ( self , bids ): \"\"\" Computes allocation vector from current bids using descending sort of \u03b2 with random tie-breaking. Args: bids (List[Tuple[float, float]]): Bids as list of (\u03b2, d) pairs. Returns: np.ndarray: Allocated resource vector x for all agents. \"\"\" indexed_bids = [( i , b [ 0 ], b [ 1 ], random . random ()) for i , b in enumerate ( bids )] beta_sorted = sorted ( indexed_bids , key = lambda x : ( - x [ 1 ], x [ 3 ])) x = np . zeros ( self . N ) remaining = self . Gamma for i , beta , d , _ in beta_sorted : x [ i ] = min ( d , remaining ) remaining -= x [ i ] if remaining <= 0 : break return x def payment ( self , bids , n ): \"\"\" Computes VCG payment for agent n using Clarke pivot rule. Args: bids (List[Tuple[float, float]]): Current bids. n (int): Agent index. Returns: float: Payment \u03c4_n agent n must pay. \"\"\" b_without_n = bids . copy () b_without_n [ n ] = ( bids [ n ][ 0 ], 0.0 ) x_without = self . allocation ( b_without_n ) return sum ( bids [ m ][ 0 ] * ( x_without [ m ] - self . x [ m ]) for m in range ( self . N ) if m != n ) def payoff ( self , n , bids ): \"\"\" Computes payoff for agent n given current bids. Args: n (int): Agent index. bids (List[Tuple[float, float]]): Bid profile. Returns: float: Payoff for agent n. \"\"\" x = self . allocation ( bids ) \u03c4 = self . payment ( bids , n ) return self . valuation ( n , x [ n ]) - \u03c4 def constrained_demand ( self , n , bids ): \"\"\" Computes upper bound for agent n's demand based on dynamic constraints. Args: n (int): Agent index. bids (List[Tuple[float, float]]): Bid profile. Returns: float: Constrained upper bound on agent n's demand. \"\"\" \u0393c = max ( 0 , self . Gamma - sum ( d for _ , d in bids )) \u03b2n , dn = bids [ n ] m = self . find_m ( n , bids ) dm = bids [ m ][ 1 ] if m is not None else 0 \u03b2m = bids [ m ][ 0 ] if m is not None else 0 \u03a6 = max ( 0 , ( \u03b2n - \u03b2m + self . rho * ( dn - self . x [ n ]) + 0.5 * self . rho_bar * \u0393c )) / self . rho_bar upper_bound = self . x [ n ] + min ( dm + \u0393c , self . alpha * \u03a6 , ( 2 / self . rho_bar ) * \u03b2n ) return upper_bound def find_m ( self , n , bids ): \"\"\" Finds the lowest priced winning agent (other than agent n). Args: n (int): Agent index. bids (List[Tuple[float, float]]): Bid profile. Returns: int: Index of agent m, or None if none found. \"\"\" lowest = float ( 'inf' ) idx = None for i in range ( self . N ): if i == n or self . x [ i ] == 0 : continue \u03b2 = bids [ i ][ 0 ] if \u03b2 < lowest or ( \u03b2 == lowest and ( idx is None or i < idx )): lowest = \u03b2 idx = i return idx def best_response ( self , n , bids ): \"\"\" Computes agent n's best response by optimizing payoff w.r.t. demand. Args: n (int): Agent index. bids (List[Tuple[float, float]]): Current bids. Returns: Tuple[float, float]: New bid (\u03b2, d) for agent n. \"\"\" upper = self . constrained_demand ( n , bids ) lower = self . x [ n ] def neg_payoff ( d ): \u03b2 = self . marginal_valuation ( n , d ) # true_beta = self.marginal_valuation(n, d) # budget = self.agents[n].budget # if budget <= 0: # scaled_beta = 0.0 # else: # scaling = budget / (budget + 1e-3) # scaled_beta = scaling * true_beta # Scaling factor \u2014 adjust if you want soft capping # scaling = budget / (budget + 1e-6) # avoid divide-by-zero # In your budget-weighted bid scaling: # Instead of soft scaling, use aggressive squashing: # scaling = self.agents[n].budget / (self.agents[n].budget + 0.01) # scaled_beta = scaling * true_beta # effective_beta = scaling * true_beta temp_bids = bids . copy () temp_bids [ n ] = ( \u03b2 , d ) # temp_bids[n] = (scaled_beta, d) return - self . payoff ( n , temp_bids ) res = minimize_scalar ( neg_payoff , bounds = ( lower , upper ), method = 'bounded' ) best_d = res . x \u03b2_best = self . marginal_valuation ( n , best_d ) return ( \u03b2_best , best_d ) # def best_response(self, n, bids): # \"\"\" # Computes agent n's best response by optimizing payoff with respect to demand, # using budget-aware bid scaling. # Args: # n (int): Agent index. # bids (List[Tuple[float, float]]): Current bid profile. # Returns: # Tuple[float, float]: New bid (\u03b2, d) for agent n. # \"\"\" # upper = self.constrained_demand(n, bids) # lower = self.x[n] # budget = self.agents[n].budget # # If agent is broke, skip optimization and return (0, 0) # if budget <= 0: # return (0.0, 0.0) # def neg_payoff(d): # true_beta = self.marginal_valuation(n, d) # scaling = budget / (budget + 1e-3) # aggressive scaling # scaled_beta = scaling * true_beta # temp_bids = bids.copy() # temp_bids[n] = (scaled_beta, d) # return -self.payoff(n, temp_bids) # res = minimize_scalar(neg_payoff, bounds=(lower, upper), method='bounded') # best_d = res.x # # Recompute scaled bid for this d # true_beta = self.marginal_valuation(n, best_d) # scaling = budget / (budget + 1e-3) # scaled_beta = scaling * true_beta # return (scaled_beta, best_d) def compute_payments_from_delta ( self , S ): \"\"\" Computes VCG payments based on the avoidance effort (Delta) using each agent's actual valuation function. Args: S (float): Total safety correction required (i.e., safety deficit). Returns: List[float]: VCG payments based on Delta externality. \"\"\" # Step 1: Final credit allocation (after auction) c = np . array ([ bid [ 1 ] for bid in self . bids ]) Delta = ( 1 - c ) * S / np . sum ( 1 - c ) print ( f \"\u0394: { [ round ( d , 4 ) for d in Delta ] } \" ) print ( \"Valuations of others with agent present:\" , [ round ( agent . valuation ( d ), 4 ) for i , ( agent , d ) in enumerate ( zip ( self . agents , Delta )) if i != 0 ]) # Then repeat with agent 1 removed (\u0394_wo_1) N = self . N payments = [] for i in range ( N ): # Step 2: Recompute allocation with agent i set to full credit (no burden) c_mod = c . copy () c_mod [ i ] = 1.0 denom = np . sum ( 1 - c_mod ) if denom == 0 : Delta_wo_i = np . zeros ( N ) else : Delta_wo_i = ( 1 - c_mod ) * S / denom # Step 3: Use agent-provided valuation functions to compute disutility welfare_wo_i = sum ( - self . agents [ j ] . valuation ( Delta_wo_i [ j ]) for j in range ( N ) if j != i ) welfare_with_i = sum ( - self . agents [ j ] . valuation ( Delta [ j ]) for j in range ( N ) if j != i ) # Step 4: VCG payment is the externality agent i imposes tau_i = welfare_wo_i - welfare_with_i payments . append ( tau_i ) return payments def select_next_player ( self ): \"\"\" Selects the next agent to update their bid based on allocation status. Returns: int: Index of next player. \"\"\" for i in range ( self . N ): \u03b2 , d = self . bids [ i ] if self . x [ i ] < d and self . x [ i ] > 0 : return i for i in range ( self . N ): \u03b2 , d = self . bids [ i ] if self . x [ i ] == 0 and d > 0 : return i return max ( range ( self . N ), key = lambda i : self . bids [ i ][ 0 ]) def run ( self , max_steps = 10000 ): \"\"\" Runs the auction process until convergence or max iterations. Args: max_steps (int): Maximum allowed iterations. Returns: Tuple[List[Tuple[float, float]], np.ndarray]: Final bid profile and allocation. \"\"\" k = 0 update_log = [] while k < max_steps : bids_old = self . bids . copy () self . x = self . allocation ( self . bids ) n = self . select_next_player () self . bids [ n ] = self . best_response ( n , self . bids ) self . history . append ( self . bids . copy ()) update_log . append ( n ) if len ( update_log ) >= self . N : recent = update_log [ - self . N :] all_updated = set ( recent ) == set ( range ( self . N )) delta = sum ( abs ( self . bids [ i ][ 1 ] - bids_old [ i ][ 1 ]) + abs ( self . bids [ i ][ 0 ] - bids_old [ i ][ 0 ]) for i in range ( self . N )) if all_updated and delta < self . epsilon : break k += 1 return self . bids , self . allocation ( self . bids ) # def compute_payments(self): # \"\"\" # Computes VCG payments for each agent after auction ends. # Returns: # List[float]: Payment \u03c4_i for each agent. # \"\"\" # self.x = self.allocation(self.bids) # return [self.payment(self.bids, n) for n in range(self.N)] # def compute_payments(self): # self.x = self.allocation(self.bids) # payments = [] # for n in range(self.N): # bids_wo_n = self.bids.copy() # bids_wo_n[n] = (self.bids[n][0], 0.0) # x_wo_n = self.allocation(bids_wo_n) # print(f\"\\nAgent {n} removal:\") # for m in range(self.N): # if m != n: # print(f\" Agent {m}: x_with = {self.x[m]:.4f}, x_wo_n = {x_wo_n[m]:.4f}\") # payment = sum(self.bids[m][0] * (x_wo_n[m] - self.x[m]) for m in range(self.N) if m != n) # print(f\" Payment \u03c4_{n} = {payment:.4f}\") # payments.append(payment) # return payments def compute_payments ( self ): \"\"\" Computes VCG payments for each agent using Clarke pivot rule with full reallocation. Assumes agents will reoptimize demand if another agent exits, so all \u0393 is consumed. \"\"\" self . x = self . allocation ( self . bids ) payments = [] for n in range ( self . N ): # 1. Remove agent n from allocation bids_wo_n = self . bids . copy () bids_wo_n [ n ] = ( self . bids [ n ][ 0 ], 0.0 ) # 2. Redistribute \u0393 among remaining agents proportionally to their marginal value total_beta = sum ( b [ 0 ] for i , b in enumerate ( bids_wo_n ) if i != n ) if total_beta == 0 : # No one else wants anything \u2014 payment is 0 payments . append ( 0.0 ) continue # 3. New demand: distribute Gamma proportionally to \u03b2 new_bids = [] for i , ( beta , _ ) in enumerate ( bids_wo_n ): if i == n : new_bids . append (( beta , 0.0 )) else : new_demand = self . Gamma * ( beta / total_beta ) new_bids . append (( beta , new_demand )) # 4. Compute new allocation x_wo_n = self . allocation ( new_bids ) # 5. Compute externality (benefit to others) externality = sum ( self . bids [ m ][ 0 ] * ( x_wo_n [ m ] - self . x [ m ]) for m in range ( self . N ) if m != n ) payments . append ( externality ) return payments def compute_payments_vcg ( self ): \"\"\" Computes externality-based VCG-style payments by re-running auction without each agent. Returns: List[float]: Payments for each agent. \"\"\" self . x = self . allocation ( self . bids ) return [ sum ( self . bids [ j ][ 0 ] * ( self . run_without_agent ( i )[ j ] - self . x [ j ]) for j in range ( self . N ) if j != i ) for i in range ( self . N ) ] def reset ( self , agents , bids ): \"\"\" Resets the auction environment to a new configuration. Args: agents (List[Agent]): New agent list. bids (List[Tuple[float, float]]): New initial bids. \"\"\" self . agents = agents self . N = len ( agents ) self . bids = bids . copy () self . history = [ self . bids . copy ()] self . x = np . zeros ( self . N ) def run_without_agent ( self , remove_index ): \"\"\" Runs auction without a specific agent, used for computing VCG payments. Args: remove_index (int): Index of agent to exclude. Returns: np.ndarray: Full allocation vector with zero at excluded index. \"\"\" agents_wo = [ a for i , a in enumerate ( self . agents ) if i != remove_index ] init_bids = [( a . marginal_valuation ( 1.0 ), 1.0 ) for a in agents_wo ] auction_wo = Auction ( agents_wo , self . Gamma , init_bids ) _ , alloc_wo = auction_wo . run () full_alloc = np . zeros ( self . N ) j = 0 for i in range ( self . N ): if i == remove_index : continue full_alloc [ i ] = alloc_wo [ j ] j += 1 return full_alloc def plot_bid_demand_over_time ( self ): \"\"\"Plots demand bids over the course of the auction.\"\"\" for i in range ( self . N ): plt . plot ([ step [ i ][ 1 ] for step in self . history ], label = f 'Player { i + 1 } ' ) plt . title ( 'Bid Demand Over Iterations' ) plt . xlabel ( 'Iteration' ) plt . ylabel ( 'Demand (d)' ) plt . legend () plt . grid ( True ) plt . tight_layout () plt . show () def plot_bid_price_over_time ( self ): \"\"\"Plots price bids (\u03b2) over the course of the auction.\"\"\" for i in range ( self . N ): plt . plot ([ step [ i ][ 0 ] for step in self . history ], label = f 'Player { i + 1 } ' ) plt . title ( 'Bid Price Over Iterations' ) plt . xlabel ( 'Iteration' ) plt . ylabel ( 'Bid Price (\u03b2)' ) plt . legend () plt . grid ( True ) plt . tight_layout () plt . show ()","title":"Auction"},{"location":"api/auction/#kamaji.auctions.resource.Auction.__init__","text":"Initialize the Auction class for decentralized divisible resource allocation. Parameters: agents ( List [ Agent ] ) \u2013 List of Agent objects with valuation functions. Gamma ( float ) \u2013 Total amount of divisible resource to allocate. bids ( List [ Tuple [ float , float ]] ) \u2013 Initial bids for each agent, in (\u03b2, d) format. alpha ( float , default: 0.99 ) \u2013 Smoothing parameter for computing constrained demand. rho_bar ( float , default: 2 ) \u2013 Upper bound on dynamic response term for constrained demand. rho ( float , default: 0.5 ) \u2013 Smoothing factor for current demand vs. allocation. epsilon ( float , default: 0.0001 ) \u2013 Convergence threshold for bid updates. Source code in kamaji/auctions/resource.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 def __init__ ( self , agents , Gamma , bids , alpha = 0.99 , rho_bar = 2 , rho = 0.5 , epsilon = 1e-4 ): \"\"\" Initialize the Auction class for decentralized divisible resource allocation. Args: agents (List[Agent]): List of Agent objects with valuation functions. Gamma (float): Total amount of divisible resource to allocate. bids (List[Tuple[float, float]]): Initial bids for each agent, in (\u03b2, d) format. alpha (float): Smoothing parameter for computing constrained demand. rho_bar (float): Upper bound on dynamic response term for constrained demand. rho (float): Smoothing factor for current demand vs. allocation. epsilon (float): Convergence threshold for bid updates. \"\"\" self . agents = agents self . N = len ( agents ) self . Gamma = Gamma self . alpha = alpha self . rho_bar = rho_bar self . rho = rho self . epsilon = epsilon self . bids = bids self . history = [ self . bids . copy ()] # Log of all bids over time","title":"__init__"},{"location":"api/auction/#kamaji.auctions.resource.Auction.allocation","text":"Computes allocation vector from current bids using descending sort of \u03b2 with random tie-breaking. Parameters: bids ( List [ Tuple [ float , float ]] ) \u2013 Bids as list of (\u03b2, d) pairs. Returns: \u2013 np.ndarray: Allocated resource vector x for all agents. Source code in kamaji/auctions/resource.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 def allocation ( self , bids ): \"\"\" Computes allocation vector from current bids using descending sort of \u03b2 with random tie-breaking. Args: bids (List[Tuple[float, float]]): Bids as list of (\u03b2, d) pairs. Returns: np.ndarray: Allocated resource vector x for all agents. \"\"\" indexed_bids = [( i , b [ 0 ], b [ 1 ], random . random ()) for i , b in enumerate ( bids )] beta_sorted = sorted ( indexed_bids , key = lambda x : ( - x [ 1 ], x [ 3 ])) x = np . zeros ( self . N ) remaining = self . Gamma for i , beta , d , _ in beta_sorted : x [ i ] = min ( d , remaining ) remaining -= x [ i ] if remaining <= 0 : break return x","title":"allocation"},{"location":"api/auction/#kamaji.auctions.resource.Auction.best_response","text":"Computes agent n's best response by optimizing payoff w.r.t. demand. Parameters: n ( int ) \u2013 Agent index. bids ( List [ Tuple [ float , float ]] ) \u2013 Current bids. Returns: \u2013 Tuple[float, float]: New bid (\u03b2, d) for agent n. Source code in kamaji/auctions/resource.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 def best_response ( self , n , bids ): \"\"\" Computes agent n's best response by optimizing payoff w.r.t. demand. Args: n (int): Agent index. bids (List[Tuple[float, float]]): Current bids. Returns: Tuple[float, float]: New bid (\u03b2, d) for agent n. \"\"\" upper = self . constrained_demand ( n , bids ) lower = self . x [ n ] def neg_payoff ( d ): \u03b2 = self . marginal_valuation ( n , d ) # true_beta = self.marginal_valuation(n, d) # budget = self.agents[n].budget # if budget <= 0: # scaled_beta = 0.0 # else: # scaling = budget / (budget + 1e-3) # scaled_beta = scaling * true_beta # Scaling factor \u2014 adjust if you want soft capping # scaling = budget / (budget + 1e-6) # avoid divide-by-zero # In your budget-weighted bid scaling: # Instead of soft scaling, use aggressive squashing: # scaling = self.agents[n].budget / (self.agents[n].budget + 0.01) # scaled_beta = scaling * true_beta # effective_beta = scaling * true_beta temp_bids = bids . copy () temp_bids [ n ] = ( \u03b2 , d ) # temp_bids[n] = (scaled_beta, d) return - self . payoff ( n , temp_bids ) res = minimize_scalar ( neg_payoff , bounds = ( lower , upper ), method = 'bounded' ) best_d = res . x \u03b2_best = self . marginal_valuation ( n , best_d ) return ( \u03b2_best , best_d )","title":"best_response"},{"location":"api/auction/#kamaji.auctions.resource.Auction.compute_payments","text":"Computes VCG payments for each agent using Clarke pivot rule with full reallocation. Assumes agents will reoptimize demand if another agent exits, so all \u0393 is consumed. Source code in kamaji/auctions/resource.py 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 def compute_payments ( self ): \"\"\" Computes VCG payments for each agent using Clarke pivot rule with full reallocation. Assumes agents will reoptimize demand if another agent exits, so all \u0393 is consumed. \"\"\" self . x = self . allocation ( self . bids ) payments = [] for n in range ( self . N ): # 1. Remove agent n from allocation bids_wo_n = self . bids . copy () bids_wo_n [ n ] = ( self . bids [ n ][ 0 ], 0.0 ) # 2. Redistribute \u0393 among remaining agents proportionally to their marginal value total_beta = sum ( b [ 0 ] for i , b in enumerate ( bids_wo_n ) if i != n ) if total_beta == 0 : # No one else wants anything \u2014 payment is 0 payments . append ( 0.0 ) continue # 3. New demand: distribute Gamma proportionally to \u03b2 new_bids = [] for i , ( beta , _ ) in enumerate ( bids_wo_n ): if i == n : new_bids . append (( beta , 0.0 )) else : new_demand = self . Gamma * ( beta / total_beta ) new_bids . append (( beta , new_demand )) # 4. Compute new allocation x_wo_n = self . allocation ( new_bids ) # 5. Compute externality (benefit to others) externality = sum ( self . bids [ m ][ 0 ] * ( x_wo_n [ m ] - self . x [ m ]) for m in range ( self . N ) if m != n ) payments . append ( externality ) return payments","title":"compute_payments"},{"location":"api/auction/#kamaji.auctions.resource.Auction.compute_payments_from_delta","text":"Computes VCG payments based on the avoidance effort (Delta) using each agent's actual valuation function. Parameters: S ( float ) \u2013 Total safety correction required (i.e., safety deficit). Returns: \u2013 List[float]: VCG payments based on Delta externality. Source code in kamaji/auctions/resource.py 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 def compute_payments_from_delta ( self , S ): \"\"\" Computes VCG payments based on the avoidance effort (Delta) using each agent's actual valuation function. Args: S (float): Total safety correction required (i.e., safety deficit). Returns: List[float]: VCG payments based on Delta externality. \"\"\" # Step 1: Final credit allocation (after auction) c = np . array ([ bid [ 1 ] for bid in self . bids ]) Delta = ( 1 - c ) * S / np . sum ( 1 - c ) print ( f \"\u0394: { [ round ( d , 4 ) for d in Delta ] } \" ) print ( \"Valuations of others with agent present:\" , [ round ( agent . valuation ( d ), 4 ) for i , ( agent , d ) in enumerate ( zip ( self . agents , Delta )) if i != 0 ]) # Then repeat with agent 1 removed (\u0394_wo_1) N = self . N payments = [] for i in range ( N ): # Step 2: Recompute allocation with agent i set to full credit (no burden) c_mod = c . copy () c_mod [ i ] = 1.0 denom = np . sum ( 1 - c_mod ) if denom == 0 : Delta_wo_i = np . zeros ( N ) else : Delta_wo_i = ( 1 - c_mod ) * S / denom # Step 3: Use agent-provided valuation functions to compute disutility welfare_wo_i = sum ( - self . agents [ j ] . valuation ( Delta_wo_i [ j ]) for j in range ( N ) if j != i ) welfare_with_i = sum ( - self . agents [ j ] . valuation ( Delta [ j ]) for j in range ( N ) if j != i ) # Step 4: VCG payment is the externality agent i imposes tau_i = welfare_wo_i - welfare_with_i payments . append ( tau_i ) return payments","title":"compute_payments_from_delta"},{"location":"api/auction/#kamaji.auctions.resource.Auction.compute_payments_vcg","text":"Computes externality-based VCG-style payments by re-running auction without each agent. Returns: \u2013 List[float]: Payments for each agent. Source code in kamaji/auctions/resource.py 388 389 390 391 392 393 394 395 396 397 398 399 def compute_payments_vcg ( self ): \"\"\" Computes externality-based VCG-style payments by re-running auction without each agent. Returns: List[float]: Payments for each agent. \"\"\" self . x = self . allocation ( self . bids ) return [ sum ( self . bids [ j ][ 0 ] * ( self . run_without_agent ( i )[ j ] - self . x [ j ]) for j in range ( self . N ) if j != i ) for i in range ( self . N ) ]","title":"compute_payments_vcg"},{"location":"api/auction/#kamaji.auctions.resource.Auction.constrained_demand","text":"Computes upper bound for agent n's demand based on dynamic constraints. Parameters: n ( int ) \u2013 Agent index. bids ( List [ Tuple [ float , float ]] ) \u2013 Bid profile. Returns: float \u2013 Constrained upper bound on agent n's demand. Source code in kamaji/auctions/resource.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 def constrained_demand ( self , n , bids ): \"\"\" Computes upper bound for agent n's demand based on dynamic constraints. Args: n (int): Agent index. bids (List[Tuple[float, float]]): Bid profile. Returns: float: Constrained upper bound on agent n's demand. \"\"\" \u0393c = max ( 0 , self . Gamma - sum ( d for _ , d in bids )) \u03b2n , dn = bids [ n ] m = self . find_m ( n , bids ) dm = bids [ m ][ 1 ] if m is not None else 0 \u03b2m = bids [ m ][ 0 ] if m is not None else 0 \u03a6 = max ( 0 , ( \u03b2n - \u03b2m + self . rho * ( dn - self . x [ n ]) + 0.5 * self . rho_bar * \u0393c )) / self . rho_bar upper_bound = self . x [ n ] + min ( dm + \u0393c , self . alpha * \u03a6 , ( 2 / self . rho_bar ) * \u03b2n ) return upper_bound","title":"constrained_demand"},{"location":"api/auction/#kamaji.auctions.resource.Auction.find_m","text":"Finds the lowest priced winning agent (other than agent n). Parameters: n ( int ) \u2013 Agent index. bids ( List [ Tuple [ float , float ]] ) \u2013 Bid profile. Returns: int \u2013 Index of agent m, or None if none found. Source code in kamaji/auctions/resource.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 def find_m ( self , n , bids ): \"\"\" Finds the lowest priced winning agent (other than agent n). Args: n (int): Agent index. bids (List[Tuple[float, float]]): Bid profile. Returns: int: Index of agent m, or None if none found. \"\"\" lowest = float ( 'inf' ) idx = None for i in range ( self . N ): if i == n or self . x [ i ] == 0 : continue \u03b2 = bids [ i ][ 0 ] if \u03b2 < lowest or ( \u03b2 == lowest and ( idx is None or i < idx )): lowest = \u03b2 idx = i return idx","title":"find_m"},{"location":"api/auction/#kamaji.auctions.resource.Auction.marginal_valuation","text":"Returns the marginal valuation u_n'(x) of agent n at allocation x. Source code in kamaji/auctions/resource.py 34 35 36 def marginal_valuation ( self , n , x ): \"\"\"Returns the marginal valuation u_n'(x) of agent n at allocation x.\"\"\" return self . agents [ n ] . marginal_valuation ( x )","title":"marginal_valuation"},{"location":"api/auction/#kamaji.auctions.resource.Auction.payment","text":"Computes VCG payment for agent n using Clarke pivot rule. Parameters: bids ( List [ Tuple [ float , float ]] ) \u2013 Current bids. n ( int ) \u2013 Agent index. Returns: float \u2013 Payment \u03c4_n agent n must pay. Source code in kamaji/auctions/resource.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def payment ( self , bids , n ): \"\"\" Computes VCG payment for agent n using Clarke pivot rule. Args: bids (List[Tuple[float, float]]): Current bids. n (int): Agent index. Returns: float: Payment \u03c4_n agent n must pay. \"\"\" b_without_n = bids . copy () b_without_n [ n ] = ( bids [ n ][ 0 ], 0.0 ) x_without = self . allocation ( b_without_n ) return sum ( bids [ m ][ 0 ] * ( x_without [ m ] - self . x [ m ]) for m in range ( self . N ) if m != n )","title":"payment"},{"location":"api/auction/#kamaji.auctions.resource.Auction.payoff","text":"Computes payoff for agent n given current bids. Parameters: n ( int ) \u2013 Agent index. bids ( List [ Tuple [ float , float ]] ) \u2013 Bid profile. Returns: float \u2013 Payoff for agent n. Source code in kamaji/auctions/resource.py 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def payoff ( self , n , bids ): \"\"\" Computes payoff for agent n given current bids. Args: n (int): Agent index. bids (List[Tuple[float, float]]): Bid profile. Returns: float: Payoff for agent n. \"\"\" x = self . allocation ( bids ) \u03c4 = self . payment ( bids , n ) return self . valuation ( n , x [ n ]) - \u03c4","title":"payoff"},{"location":"api/auction/#kamaji.auctions.resource.Auction.plot_bid_demand_over_time","text":"Plots demand bids over the course of the auction. Source code in kamaji/auctions/resource.py 439 440 441 442 443 444 445 446 447 448 449 def plot_bid_demand_over_time ( self ): \"\"\"Plots demand bids over the course of the auction.\"\"\" for i in range ( self . N ): plt . plot ([ step [ i ][ 1 ] for step in self . history ], label = f 'Player { i + 1 } ' ) plt . title ( 'Bid Demand Over Iterations' ) plt . xlabel ( 'Iteration' ) plt . ylabel ( 'Demand (d)' ) plt . legend () plt . grid ( True ) plt . tight_layout () plt . show ()","title":"plot_bid_demand_over_time"},{"location":"api/auction/#kamaji.auctions.resource.Auction.plot_bid_price_over_time","text":"Plots price bids (\u03b2) over the course of the auction. Source code in kamaji/auctions/resource.py 451 452 453 454 455 456 457 458 459 460 461 def plot_bid_price_over_time ( self ): \"\"\"Plots price bids (\u03b2) over the course of the auction.\"\"\" for i in range ( self . N ): plt . plot ([ step [ i ][ 0 ] for step in self . history ], label = f 'Player { i + 1 } ' ) plt . title ( 'Bid Price Over Iterations' ) plt . xlabel ( 'Iteration' ) plt . ylabel ( 'Bid Price (\u03b2)' ) plt . legend () plt . grid ( True ) plt . tight_layout () plt . show ()","title":"plot_bid_price_over_time"},{"location":"api/auction/#kamaji.auctions.resource.Auction.reset","text":"Resets the auction environment to a new configuration. Parameters: agents ( List [ Agent ] ) \u2013 New agent list. bids ( List [ Tuple [ float , float ]] ) \u2013 New initial bids. Source code in kamaji/auctions/resource.py 401 402 403 404 405 406 407 408 409 410 411 412 413 def reset ( self , agents , bids ): \"\"\" Resets the auction environment to a new configuration. Args: agents (List[Agent]): New agent list. bids (List[Tuple[float, float]]): New initial bids. \"\"\" self . agents = agents self . N = len ( agents ) self . bids = bids . copy () self . history = [ self . bids . copy ()] self . x = np . zeros ( self . N )","title":"reset"},{"location":"api/auction/#kamaji.auctions.resource.Auction.run","text":"Runs the auction process until convergence or max iterations. Parameters: max_steps ( int , default: 10000 ) \u2013 Maximum allowed iterations. Returns: \u2013 Tuple[List[Tuple[float, float]], np.ndarray]: Final bid profile and allocation. Source code in kamaji/auctions/resource.py 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 def run ( self , max_steps = 10000 ): \"\"\" Runs the auction process until convergence or max iterations. Args: max_steps (int): Maximum allowed iterations. Returns: Tuple[List[Tuple[float, float]], np.ndarray]: Final bid profile and allocation. \"\"\" k = 0 update_log = [] while k < max_steps : bids_old = self . bids . copy () self . x = self . allocation ( self . bids ) n = self . select_next_player () self . bids [ n ] = self . best_response ( n , self . bids ) self . history . append ( self . bids . copy ()) update_log . append ( n ) if len ( update_log ) >= self . N : recent = update_log [ - self . N :] all_updated = set ( recent ) == set ( range ( self . N )) delta = sum ( abs ( self . bids [ i ][ 1 ] - bids_old [ i ][ 1 ]) + abs ( self . bids [ i ][ 0 ] - bids_old [ i ][ 0 ]) for i in range ( self . N )) if all_updated and delta < self . epsilon : break k += 1 return self . bids , self . allocation ( self . bids )","title":"run"},{"location":"api/auction/#kamaji.auctions.resource.Auction.run_without_agent","text":"Runs auction without a specific agent, used for computing VCG payments. Parameters: remove_index ( int ) \u2013 Index of agent to exclude. Returns: \u2013 np.ndarray: Full allocation vector with zero at excluded index. Source code in kamaji/auctions/resource.py 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 def run_without_agent ( self , remove_index ): \"\"\" Runs auction without a specific agent, used for computing VCG payments. Args: remove_index (int): Index of agent to exclude. Returns: np.ndarray: Full allocation vector with zero at excluded index. \"\"\" agents_wo = [ a for i , a in enumerate ( self . agents ) if i != remove_index ] init_bids = [( a . marginal_valuation ( 1.0 ), 1.0 ) for a in agents_wo ] auction_wo = Auction ( agents_wo , self . Gamma , init_bids ) _ , alloc_wo = auction_wo . run () full_alloc = np . zeros ( self . N ) j = 0 for i in range ( self . N ): if i == remove_index : continue full_alloc [ i ] = alloc_wo [ j ] j += 1 return full_alloc","title":"run_without_agent"},{"location":"api/auction/#kamaji.auctions.resource.Auction.select_next_player","text":"Selects the next agent to update their bid based on allocation status. Returns: int \u2013 Index of next player. Source code in kamaji/auctions/resource.py 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 def select_next_player ( self ): \"\"\" Selects the next agent to update their bid based on allocation status. Returns: int: Index of next player. \"\"\" for i in range ( self . N ): \u03b2 , d = self . bids [ i ] if self . x [ i ] < d and self . x [ i ] > 0 : return i for i in range ( self . N ): \u03b2 , d = self . bids [ i ] if self . x [ i ] == 0 and d > 0 : return i return max ( range ( self . N ), key = lambda i : self . bids [ i ][ 0 ])","title":"select_next_player"},{"location":"api/auction/#kamaji.auctions.resource.Auction.valuation","text":"Returns the valuation u_n(x) of agent n at allocation x. Source code in kamaji/auctions/resource.py 30 31 32 def valuation ( self , n , x ): \"\"\"Returns the valuation u_n(x) of agent n at allocation x.\"\"\" return self . agents [ n ] . valuation ( x )","title":"valuation"},{"location":"api/simulator/","text":"View Simulator class kamaji.simulation.simulator.Simulator A class to manage and run multi-agent simulations with configurable dynamics, control, and collision avoidance mechanisms. Includes support for agent tracking, control input updates, manual overrides, logging, and visualization. Attributes: sim_time ( float ) \u2013 Current simulation time. active_agents ( list ) \u2013 List of currently active agents. inactive_agents ( list ) \u2013 List of agents that have completed simulation. agent_ids ( set ) \u2013 Set of agent IDs in the simulation. verbose ( bool ) \u2013 Flag for printing debug/output information. plot ( SimulationPlotter ) \u2013 Visualization utility. logger ( SimulationLogger ) \u2013 Logging utility for simulation data. Source code in kamaji/simulation/simulator.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 class Simulator : \"\"\" A class to manage and run multi-agent simulations with configurable dynamics, control, and collision avoidance mechanisms. Includes support for agent tracking, control input updates, manual overrides, logging, and visualization. Attributes: sim_time (float): Current simulation time. active_agents (list): List of currently active agents. inactive_agents (list): List of agents that have completed simulation. agent_ids (set): Set of agent IDs in the simulation. verbose (bool): Flag for printing debug/output information. plot (SimulationPlotter): Visualization utility. logger (SimulationLogger): Logging utility for simulation data. \"\"\" def __init__ ( self , config = None ) -> None : \"\"\" Initialize the simulation with optional configuration parameters. Args: config (dict, optional): Dictionary containing simulation, agent, and logging parameters. \"\"\" self . _config = config self . _current_real_time = time () self . _elapsed_real_time = 0.0 self . sim_time = 0.0 self . active_agents = [] self . inactive_agents = [] self . agent_ids = set () self . verbose = True self . plot = SimulationPlotter ( self ) self . logging_params = config . get ( \"logging\" , {}) if config else {} self . logger = SimulationLogger ( self ) self . cbf_system = None # Will be set later, if needed if config is not None : self . load_from_config ( config ) else : if self . verbose : print ( \"No config provided, using default values.\" ) def set_cbf_system ( self , cbf_system ): \"\"\" Set an external CBF system to be used during simulation. Args: cbf_system (CBFSystem): A configured CBFSystem instance. \"\"\" self . cbf_system = cbf_system def set_sim_params ( self , sim_params = None ): \"\"\" Set core simulation parameters such as timestep, duration, and integration method. Args: sim_params (dict, optional): Dictionary with keys 'time_step', 'duration', and 'integrator'. Raises: ValueError: If required parameters are missing or invalid. TypeError: If parameter types are incorrect. \"\"\" if sim_params is None : self . dt = 0.01 self . duration = 10.0 self . num_timesteps = int ( self . duration / self . dt ) self . integrator = 'RK4' self . verbose = True return self . verbose = sim_params . get ( 'verbose' , True ) required = [ 'time_step' , 'duration' , 'integrator' ] missing = [ key for key in required if key not in sim_params ] if missing : raise ValueError ( f \"Missing simulation parameters: { missing } \" ) time_step = sim_params [ 'time_step' ] duration = sim_params [ 'duration' ] integrator = sim_params [ 'integrator' ] if not isinstance ( time_step , ( float , int )) or time_step <= 0 : raise ValueError ( \"'time_step' must be a positive number.\" ) if not isinstance ( duration , ( float , int )) or duration <= 0 : raise ValueError ( \"'duration' must be a positive, nonzero number.\" ) if not isinstance ( integrator , str ): raise TypeError ( \"'integrator' must be a string.\" ) valid_integrators = { 'RK4' , 'Euler' , 'RK2' , 'RK45' } if integrator not in valid_integrators : raise ValueError ( f \"Unsupported integrator ' { integrator } '. Valid options: { valid_integrators } \" ) self . dt = float ( time_step ) self . duration = float ( duration ) self . num_timesteps = max ( 1 , int ( self . duration / self . dt )) self . integrator = integrator def load_from_config ( self , config ): \"\"\" Load simulation parameters, agent configuration, environment, and logging settings. Args: config (dict): YAML-style configuration dictionary. \"\"\" self . set_sim_params ( config . get ( 'simulation' , {})) self . add_agents ( config . get ( 'agents' , {})) self . env_params = config . get ( 'environment' , {}) self . logging_params = config . get ( 'logging' , {}) def add_agents ( self , agents ) -> None : \"\"\" Add one or more agents to the simulation. Args: agents (dict | tuple | dict): Dictionary of agents, (config, id) tuple, or a single config. Raises: TypeError: If format of input is not recognized. \"\"\" if isinstance ( agents , dict ): if all ( isinstance ( v , dict ) for v in agents . values ()): for agent_id , agent_config in agents . items (): self . _add_single_agent ( agent_config , agent_id ) else : self . _add_single_agent ( agents ) elif isinstance ( agents , tuple ): if not isinstance ( agents [ 0 ], dict ) or not isinstance ( agents [ 1 ], str ): raise TypeError ( \"Expected (agent_config: dict, agent_id: str)\" ) self . _add_single_agent ( agents [ 0 ], agents [ 1 ]) else : raise TypeError ( \"Expected one of: dict of agents, (config, id) tuple, or single agent config dict.\" ) def _add_single_agent ( self , agent_config : dict , agent_id : Optional [ str ] = None ): \"\"\" Add a single agent with the provided configuration and optional ID. Args: agent_config (dict): Configuration dictionary for the agent. agent_id (str, optional): Explicit ID for the agent. Auto-generated if None. Raises: ValueError: If required fields are missing or types are invalid. RuntimeError: If the agent fails to initialize. \"\"\" required_fields = [ 'type' , 'initial_state' , 'dynamics_model' , 'controller' ] missing = [ k for k in required_fields if k not in agent_config ] if missing : raise ValueError ( f \"Missing required fields in agent config: { missing } \" ) if not isinstance ( agent_config [ 'initial_state' ], dict ): raise TypeError ( \"initial_state must be a dictionary.\" ) if not isinstance ( agent_config [ 'controller' ], dict ): raise TypeError ( \"controller must be a dictionary.\" ) controller_block = agent_config [ 'controller' ] if not isinstance ( controller_block , dict ): raise TypeError ( \"Controller block must be a dictionary of control channels.\" ) for ctrl_name , ctrl_conf in controller_block . items (): if not isinstance ( ctrl_conf , dict ): raise TypeError ( f \"Controller for ' { ctrl_name } ' must be a dict.\" ) if \"type\" not in ctrl_conf : raise ValueError ( f \"Controller ' { ctrl_name } ' must include a 'type' field.\" ) if \"specs\" not in ctrl_conf : raise ValueError ( f \"Controller ' { ctrl_name } ' must include a 'specs' field.\" ) if not isinstance ( ctrl_conf [ \"specs\" ], list ): raise TypeError ( f \"Controller ' { ctrl_name } ' 'specs' must be a list.\" ) if agent_id is None : base = \"agent\" i = 1 while f \" { base } _ { i } \" in self . agent_ids : i += 1 agent_id = f \" { base } _ { i } \" if agent_id in self . agent_ids : raise ValueError ( f \"Agent ID ' { agent_id } ' already exists.\" ) agent_config [ 'id' ] = agent_id try : self . active_agents . append ( Agent ( agent_config , self . sim_time , self . dt )) except Exception as e : raise RuntimeError ( f \"Failed to initialize Agent ' { agent_id } ': { e } \" ) self . agent_ids . add ( agent_id ) if self . verbose : print ( f \"[Simulator] Agent ' { agent_id } ' added.\" ) def simulate ( self , on_step = None ) -> None : \"\"\" Run the simulation loop for all time steps. Args: on_step (Callable[[Simulator, int], None], optional): Callback executed before each step. \"\"\" start_time = time () iterator = tqdm ( range ( self . num_timesteps ), desc = \"Simulating\" , unit = \"step\" ) if self . verbose else range ( self . num_timesteps ) for step_idx in iterator : if on_step : on_step ( self , step_idx ) self . step () self . sim_time = time () - start_time self . inactive_agents . extend ( self . active_agents ) self . active_agents . clear () if self . logging_params . get ( \"enabled\" , True ): if self . logging_params . get ( \"format\" , \"hdf5\" ) == \"hdf5\" : self . logger . log_to_hdf5 () if self . verbose : print ( f \"Sim time: { self . sim_time : .4f } \" ) def step ( self ) -> None : \"\"\" Advance the simulation by one time step, updating agent states using control input. \"\"\" state_values = {} all_controls = [] control_dims = [] # 1. Gather state values and nominal control for each agent for idx , agent in enumerate ( self . active_agents ): state_values [ f \"x { idx } \" ] = agent . state [ \"position_x\" ] state_values [ f \"y { idx } \" ] = agent . state [ \"position_y\" ] control = agent . manual_control_input if agent . manual_control_input is not None else agent . compute_control ( self . sim_time ) all_controls . append ( control ) control_dims . append ( len ( control )) u_nom = np . concatenate ( all_controls ) # 2. Filter full control vector using CBF system if available if self . cbf_system is not None : u_filtered = self . cbf_system . filter_controls ( state_values , u_nom , mode = \"all\" ) else : u_filtered = u_nom # 3. Slice filtered controls back to each agent and step them idx = 0 for agent , dim in zip ( self . active_agents , control_dims ): agent_control = u_filtered [ idx : idx + dim ] agent . step ( self . sim_time , agent_control ) idx += dim def clear_manual_control ( self , agent_id : str ) -> None : \"\"\" Clear any manually assigned control input for a specific agent. Args: agent_id (str): ID of the agent to clear manual control for. \"\"\" for agent in self . active_agents : if agent . _id == agent_id : agent . manual_control_input = None return def set_manual_control ( self , agent_id : str , control : np . ndarray ) -> None : \"\"\" Manually assign a control input to a specific agent. Args: agent_id (str): ID of the agent. control (np.ndarray): Manual control input. Raises: ValueError: If the agent ID is not found. \"\"\" for agent in self . active_agents : if agent . _id == agent_id : agent . manual_control_input = control if self . verbose : print ( f \"[Simulator] Manual control set for agent ' { agent_id } '.\" ) return raise ValueError ( f \"Agent with ID ' { agent_id } ' not found.\" ) def remove_agent ( self , agent : Agent ) -> bool : \"\"\" Remove an agent from the active list and move to the inactive list. Args: agent (Agent): The agent to be removed. Returns: bool: True if removal was successful. Raises: ValueError: If the agent is not in the active list. \"\"\" if agent not in self . active_agents : raise ValueError ( f \"Agent { agent . id } is not an active Agent.\" ) self . inactive_agents . append ( self . active_agents . pop ( self . active_agents . index ( agent ))) return True __init__ ( config = None ) Initialize the simulation with optional configuration parameters. Parameters: config ( dict , default: None ) \u2013 Dictionary containing simulation, agent, and logging parameters. Source code in kamaji/simulation/simulator.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 def __init__ ( self , config = None ) -> None : \"\"\" Initialize the simulation with optional configuration parameters. Args: config (dict, optional): Dictionary containing simulation, agent, and logging parameters. \"\"\" self . _config = config self . _current_real_time = time () self . _elapsed_real_time = 0.0 self . sim_time = 0.0 self . active_agents = [] self . inactive_agents = [] self . agent_ids = set () self . verbose = True self . plot = SimulationPlotter ( self ) self . logging_params = config . get ( \"logging\" , {}) if config else {} self . logger = SimulationLogger ( self ) self . cbf_system = None # Will be set later, if needed if config is not None : self . load_from_config ( config ) else : if self . verbose : print ( \"No config provided, using default values.\" ) add_agents ( agents ) Add one or more agents to the simulation. Parameters: agents ( dict | tuple | dict ) \u2013 Dictionary of agents, (config, id) tuple, or a single config. Raises: TypeError \u2013 If format of input is not recognized. Source code in kamaji/simulation/simulator.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 def add_agents ( self , agents ) -> None : \"\"\" Add one or more agents to the simulation. Args: agents (dict | tuple | dict): Dictionary of agents, (config, id) tuple, or a single config. Raises: TypeError: If format of input is not recognized. \"\"\" if isinstance ( agents , dict ): if all ( isinstance ( v , dict ) for v in agents . values ()): for agent_id , agent_config in agents . items (): self . _add_single_agent ( agent_config , agent_id ) else : self . _add_single_agent ( agents ) elif isinstance ( agents , tuple ): if not isinstance ( agents [ 0 ], dict ) or not isinstance ( agents [ 1 ], str ): raise TypeError ( \"Expected (agent_config: dict, agent_id: str)\" ) self . _add_single_agent ( agents [ 0 ], agents [ 1 ]) else : raise TypeError ( \"Expected one of: dict of agents, (config, id) tuple, or single agent config dict.\" ) clear_manual_control ( agent_id ) Clear any manually assigned control input for a specific agent. Parameters: agent_id ( str ) \u2013 ID of the agent to clear manual control for. Source code in kamaji/simulation/simulator.py 258 259 260 261 262 263 264 265 266 267 268 def clear_manual_control ( self , agent_id : str ) -> None : \"\"\" Clear any manually assigned control input for a specific agent. Args: agent_id (str): ID of the agent to clear manual control for. \"\"\" for agent in self . active_agents : if agent . _id == agent_id : agent . manual_control_input = None return load_from_config ( config ) Load simulation parameters, agent configuration, environment, and logging settings. Parameters: config ( dict ) \u2013 YAML-style configuration dictionary. Source code in kamaji/simulation/simulator.py 106 107 108 109 110 111 112 113 114 115 116 def load_from_config ( self , config ): \"\"\" Load simulation parameters, agent configuration, environment, and logging settings. Args: config (dict): YAML-style configuration dictionary. \"\"\" self . set_sim_params ( config . get ( 'simulation' , {})) self . add_agents ( config . get ( 'agents' , {})) self . env_params = config . get ( 'environment' , {}) self . logging_params = config . get ( 'logging' , {}) remove_agent ( agent ) Remove an agent from the active list and move to the inactive list. Parameters: agent ( Agent ) \u2013 The agent to be removed. Returns: bool ( bool ) \u2013 True if removal was successful. Raises: ValueError \u2013 If the agent is not in the active list. Source code in kamaji/simulation/simulator.py 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 def remove_agent ( self , agent : Agent ) -> bool : \"\"\" Remove an agent from the active list and move to the inactive list. Args: agent (Agent): The agent to be removed. Returns: bool: True if removal was successful. Raises: ValueError: If the agent is not in the active list. \"\"\" if agent not in self . active_agents : raise ValueError ( f \"Agent { agent . id } is not an active Agent.\" ) self . inactive_agents . append ( self . active_agents . pop ( self . active_agents . index ( agent ))) return True set_cbf_system ( cbf_system ) Set an external CBF system to be used during simulation. Parameters: cbf_system ( CBFSystem ) \u2013 A configured CBFSystem instance. Source code in kamaji/simulation/simulator.py 52 53 54 55 56 57 58 59 def set_cbf_system ( self , cbf_system ): \"\"\" Set an external CBF system to be used during simulation. Args: cbf_system (CBFSystem): A configured CBFSystem instance. \"\"\" self . cbf_system = cbf_system set_manual_control ( agent_id , control ) Manually assign a control input to a specific agent. Parameters: agent_id ( str ) \u2013 ID of the agent. control ( ndarray ) \u2013 Manual control input. Raises: ValueError \u2013 If the agent ID is not found. Source code in kamaji/simulation/simulator.py 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 def set_manual_control ( self , agent_id : str , control : np . ndarray ) -> None : \"\"\" Manually assign a control input to a specific agent. Args: agent_id (str): ID of the agent. control (np.ndarray): Manual control input. Raises: ValueError: If the agent ID is not found. \"\"\" for agent in self . active_agents : if agent . _id == agent_id : agent . manual_control_input = control if self . verbose : print ( f \"[Simulator] Manual control set for agent ' { agent_id } '.\" ) return raise ValueError ( f \"Agent with ID ' { agent_id } ' not found.\" ) set_sim_params ( sim_params = None ) Set core simulation parameters such as timestep, duration, and integration method. Parameters: sim_params ( dict , default: None ) \u2013 Dictionary with keys 'time_step', 'duration', and 'integrator'. Raises: ValueError \u2013 If required parameters are missing or invalid. TypeError \u2013 If parameter types are incorrect. Source code in kamaji/simulation/simulator.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 def set_sim_params ( self , sim_params = None ): \"\"\" Set core simulation parameters such as timestep, duration, and integration method. Args: sim_params (dict, optional): Dictionary with keys 'time_step', 'duration', and 'integrator'. Raises: ValueError: If required parameters are missing or invalid. TypeError: If parameter types are incorrect. \"\"\" if sim_params is None : self . dt = 0.01 self . duration = 10.0 self . num_timesteps = int ( self . duration / self . dt ) self . integrator = 'RK4' self . verbose = True return self . verbose = sim_params . get ( 'verbose' , True ) required = [ 'time_step' , 'duration' , 'integrator' ] missing = [ key for key in required if key not in sim_params ] if missing : raise ValueError ( f \"Missing simulation parameters: { missing } \" ) time_step = sim_params [ 'time_step' ] duration = sim_params [ 'duration' ] integrator = sim_params [ 'integrator' ] if not isinstance ( time_step , ( float , int )) or time_step <= 0 : raise ValueError ( \"'time_step' must be a positive number.\" ) if not isinstance ( duration , ( float , int )) or duration <= 0 : raise ValueError ( \"'duration' must be a positive, nonzero number.\" ) if not isinstance ( integrator , str ): raise TypeError ( \"'integrator' must be a string.\" ) valid_integrators = { 'RK4' , 'Euler' , 'RK2' , 'RK45' } if integrator not in valid_integrators : raise ValueError ( f \"Unsupported integrator ' { integrator } '. Valid options: { valid_integrators } \" ) self . dt = float ( time_step ) self . duration = float ( duration ) self . num_timesteps = max ( 1 , int ( self . duration / self . dt )) self . integrator = integrator simulate ( on_step = None ) Run the simulation loop for all time steps. Parameters: on_step ( Callable [[ Simulator , int ], None] , default: None ) \u2013 Callback executed before each step. Source code in kamaji/simulation/simulator.py 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 def simulate ( self , on_step = None ) -> None : \"\"\" Run the simulation loop for all time steps. Args: on_step (Callable[[Simulator, int], None], optional): Callback executed before each step. \"\"\" start_time = time () iterator = tqdm ( range ( self . num_timesteps ), desc = \"Simulating\" , unit = \"step\" ) if self . verbose else range ( self . num_timesteps ) for step_idx in iterator : if on_step : on_step ( self , step_idx ) self . step () self . sim_time = time () - start_time self . inactive_agents . extend ( self . active_agents ) self . active_agents . clear () if self . logging_params . get ( \"enabled\" , True ): if self . logging_params . get ( \"format\" , \"hdf5\" ) == \"hdf5\" : self . logger . log_to_hdf5 () if self . verbose : print ( f \"Sim time: { self . sim_time : .4f } \" ) step () Advance the simulation by one time step, updating agent states using control input. Source code in kamaji/simulation/simulator.py 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 def step ( self ) -> None : \"\"\" Advance the simulation by one time step, updating agent states using control input. \"\"\" state_values = {} all_controls = [] control_dims = [] # 1. Gather state values and nominal control for each agent for idx , agent in enumerate ( self . active_agents ): state_values [ f \"x { idx } \" ] = agent . state [ \"position_x\" ] state_values [ f \"y { idx } \" ] = agent . state [ \"position_y\" ] control = agent . manual_control_input if agent . manual_control_input is not None else agent . compute_control ( self . sim_time ) all_controls . append ( control ) control_dims . append ( len ( control )) u_nom = np . concatenate ( all_controls ) # 2. Filter full control vector using CBF system if available if self . cbf_system is not None : u_filtered = self . cbf_system . filter_controls ( state_values , u_nom , mode = \"all\" ) else : u_filtered = u_nom # 3. Slice filtered controls back to each agent and step them idx = 0 for agent , dim in zip ( self . active_agents , control_dims ): agent_control = u_filtered [ idx : idx + dim ] agent . step ( self . sim_time , agent_control ) idx += dim","title":"Simulator"},{"location":"api/simulator/#kamaji.simulation.simulator.Simulator","text":"A class to manage and run multi-agent simulations with configurable dynamics, control, and collision avoidance mechanisms. Includes support for agent tracking, control input updates, manual overrides, logging, and visualization. Attributes: sim_time ( float ) \u2013 Current simulation time. active_agents ( list ) \u2013 List of currently active agents. inactive_agents ( list ) \u2013 List of agents that have completed simulation. agent_ids ( set ) \u2013 Set of agent IDs in the simulation. verbose ( bool ) \u2013 Flag for printing debug/output information. plot ( SimulationPlotter ) \u2013 Visualization utility. logger ( SimulationLogger ) \u2013 Logging utility for simulation data. Source code in kamaji/simulation/simulator.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 class Simulator : \"\"\" A class to manage and run multi-agent simulations with configurable dynamics, control, and collision avoidance mechanisms. Includes support for agent tracking, control input updates, manual overrides, logging, and visualization. Attributes: sim_time (float): Current simulation time. active_agents (list): List of currently active agents. inactive_agents (list): List of agents that have completed simulation. agent_ids (set): Set of agent IDs in the simulation. verbose (bool): Flag for printing debug/output information. plot (SimulationPlotter): Visualization utility. logger (SimulationLogger): Logging utility for simulation data. \"\"\" def __init__ ( self , config = None ) -> None : \"\"\" Initialize the simulation with optional configuration parameters. Args: config (dict, optional): Dictionary containing simulation, agent, and logging parameters. \"\"\" self . _config = config self . _current_real_time = time () self . _elapsed_real_time = 0.0 self . sim_time = 0.0 self . active_agents = [] self . inactive_agents = [] self . agent_ids = set () self . verbose = True self . plot = SimulationPlotter ( self ) self . logging_params = config . get ( \"logging\" , {}) if config else {} self . logger = SimulationLogger ( self ) self . cbf_system = None # Will be set later, if needed if config is not None : self . load_from_config ( config ) else : if self . verbose : print ( \"No config provided, using default values.\" ) def set_cbf_system ( self , cbf_system ): \"\"\" Set an external CBF system to be used during simulation. Args: cbf_system (CBFSystem): A configured CBFSystem instance. \"\"\" self . cbf_system = cbf_system def set_sim_params ( self , sim_params = None ): \"\"\" Set core simulation parameters such as timestep, duration, and integration method. Args: sim_params (dict, optional): Dictionary with keys 'time_step', 'duration', and 'integrator'. Raises: ValueError: If required parameters are missing or invalid. TypeError: If parameter types are incorrect. \"\"\" if sim_params is None : self . dt = 0.01 self . duration = 10.0 self . num_timesteps = int ( self . duration / self . dt ) self . integrator = 'RK4' self . verbose = True return self . verbose = sim_params . get ( 'verbose' , True ) required = [ 'time_step' , 'duration' , 'integrator' ] missing = [ key for key in required if key not in sim_params ] if missing : raise ValueError ( f \"Missing simulation parameters: { missing } \" ) time_step = sim_params [ 'time_step' ] duration = sim_params [ 'duration' ] integrator = sim_params [ 'integrator' ] if not isinstance ( time_step , ( float , int )) or time_step <= 0 : raise ValueError ( \"'time_step' must be a positive number.\" ) if not isinstance ( duration , ( float , int )) or duration <= 0 : raise ValueError ( \"'duration' must be a positive, nonzero number.\" ) if not isinstance ( integrator , str ): raise TypeError ( \"'integrator' must be a string.\" ) valid_integrators = { 'RK4' , 'Euler' , 'RK2' , 'RK45' } if integrator not in valid_integrators : raise ValueError ( f \"Unsupported integrator ' { integrator } '. Valid options: { valid_integrators } \" ) self . dt = float ( time_step ) self . duration = float ( duration ) self . num_timesteps = max ( 1 , int ( self . duration / self . dt )) self . integrator = integrator def load_from_config ( self , config ): \"\"\" Load simulation parameters, agent configuration, environment, and logging settings. Args: config (dict): YAML-style configuration dictionary. \"\"\" self . set_sim_params ( config . get ( 'simulation' , {})) self . add_agents ( config . get ( 'agents' , {})) self . env_params = config . get ( 'environment' , {}) self . logging_params = config . get ( 'logging' , {}) def add_agents ( self , agents ) -> None : \"\"\" Add one or more agents to the simulation. Args: agents (dict | tuple | dict): Dictionary of agents, (config, id) tuple, or a single config. Raises: TypeError: If format of input is not recognized. \"\"\" if isinstance ( agents , dict ): if all ( isinstance ( v , dict ) for v in agents . values ()): for agent_id , agent_config in agents . items (): self . _add_single_agent ( agent_config , agent_id ) else : self . _add_single_agent ( agents ) elif isinstance ( agents , tuple ): if not isinstance ( agents [ 0 ], dict ) or not isinstance ( agents [ 1 ], str ): raise TypeError ( \"Expected (agent_config: dict, agent_id: str)\" ) self . _add_single_agent ( agents [ 0 ], agents [ 1 ]) else : raise TypeError ( \"Expected one of: dict of agents, (config, id) tuple, or single agent config dict.\" ) def _add_single_agent ( self , agent_config : dict , agent_id : Optional [ str ] = None ): \"\"\" Add a single agent with the provided configuration and optional ID. Args: agent_config (dict): Configuration dictionary for the agent. agent_id (str, optional): Explicit ID for the agent. Auto-generated if None. Raises: ValueError: If required fields are missing or types are invalid. RuntimeError: If the agent fails to initialize. \"\"\" required_fields = [ 'type' , 'initial_state' , 'dynamics_model' , 'controller' ] missing = [ k for k in required_fields if k not in agent_config ] if missing : raise ValueError ( f \"Missing required fields in agent config: { missing } \" ) if not isinstance ( agent_config [ 'initial_state' ], dict ): raise TypeError ( \"initial_state must be a dictionary.\" ) if not isinstance ( agent_config [ 'controller' ], dict ): raise TypeError ( \"controller must be a dictionary.\" ) controller_block = agent_config [ 'controller' ] if not isinstance ( controller_block , dict ): raise TypeError ( \"Controller block must be a dictionary of control channels.\" ) for ctrl_name , ctrl_conf in controller_block . items (): if not isinstance ( ctrl_conf , dict ): raise TypeError ( f \"Controller for ' { ctrl_name } ' must be a dict.\" ) if \"type\" not in ctrl_conf : raise ValueError ( f \"Controller ' { ctrl_name } ' must include a 'type' field.\" ) if \"specs\" not in ctrl_conf : raise ValueError ( f \"Controller ' { ctrl_name } ' must include a 'specs' field.\" ) if not isinstance ( ctrl_conf [ \"specs\" ], list ): raise TypeError ( f \"Controller ' { ctrl_name } ' 'specs' must be a list.\" ) if agent_id is None : base = \"agent\" i = 1 while f \" { base } _ { i } \" in self . agent_ids : i += 1 agent_id = f \" { base } _ { i } \" if agent_id in self . agent_ids : raise ValueError ( f \"Agent ID ' { agent_id } ' already exists.\" ) agent_config [ 'id' ] = agent_id try : self . active_agents . append ( Agent ( agent_config , self . sim_time , self . dt )) except Exception as e : raise RuntimeError ( f \"Failed to initialize Agent ' { agent_id } ': { e } \" ) self . agent_ids . add ( agent_id ) if self . verbose : print ( f \"[Simulator] Agent ' { agent_id } ' added.\" ) def simulate ( self , on_step = None ) -> None : \"\"\" Run the simulation loop for all time steps. Args: on_step (Callable[[Simulator, int], None], optional): Callback executed before each step. \"\"\" start_time = time () iterator = tqdm ( range ( self . num_timesteps ), desc = \"Simulating\" , unit = \"step\" ) if self . verbose else range ( self . num_timesteps ) for step_idx in iterator : if on_step : on_step ( self , step_idx ) self . step () self . sim_time = time () - start_time self . inactive_agents . extend ( self . active_agents ) self . active_agents . clear () if self . logging_params . get ( \"enabled\" , True ): if self . logging_params . get ( \"format\" , \"hdf5\" ) == \"hdf5\" : self . logger . log_to_hdf5 () if self . verbose : print ( f \"Sim time: { self . sim_time : .4f } \" ) def step ( self ) -> None : \"\"\" Advance the simulation by one time step, updating agent states using control input. \"\"\" state_values = {} all_controls = [] control_dims = [] # 1. Gather state values and nominal control for each agent for idx , agent in enumerate ( self . active_agents ): state_values [ f \"x { idx } \" ] = agent . state [ \"position_x\" ] state_values [ f \"y { idx } \" ] = agent . state [ \"position_y\" ] control = agent . manual_control_input if agent . manual_control_input is not None else agent . compute_control ( self . sim_time ) all_controls . append ( control ) control_dims . append ( len ( control )) u_nom = np . concatenate ( all_controls ) # 2. Filter full control vector using CBF system if available if self . cbf_system is not None : u_filtered = self . cbf_system . filter_controls ( state_values , u_nom , mode = \"all\" ) else : u_filtered = u_nom # 3. Slice filtered controls back to each agent and step them idx = 0 for agent , dim in zip ( self . active_agents , control_dims ): agent_control = u_filtered [ idx : idx + dim ] agent . step ( self . sim_time , agent_control ) idx += dim def clear_manual_control ( self , agent_id : str ) -> None : \"\"\" Clear any manually assigned control input for a specific agent. Args: agent_id (str): ID of the agent to clear manual control for. \"\"\" for agent in self . active_agents : if agent . _id == agent_id : agent . manual_control_input = None return def set_manual_control ( self , agent_id : str , control : np . ndarray ) -> None : \"\"\" Manually assign a control input to a specific agent. Args: agent_id (str): ID of the agent. control (np.ndarray): Manual control input. Raises: ValueError: If the agent ID is not found. \"\"\" for agent in self . active_agents : if agent . _id == agent_id : agent . manual_control_input = control if self . verbose : print ( f \"[Simulator] Manual control set for agent ' { agent_id } '.\" ) return raise ValueError ( f \"Agent with ID ' { agent_id } ' not found.\" ) def remove_agent ( self , agent : Agent ) -> bool : \"\"\" Remove an agent from the active list and move to the inactive list. Args: agent (Agent): The agent to be removed. Returns: bool: True if removal was successful. Raises: ValueError: If the agent is not in the active list. \"\"\" if agent not in self . active_agents : raise ValueError ( f \"Agent { agent . id } is not an active Agent.\" ) self . inactive_agents . append ( self . active_agents . pop ( self . active_agents . index ( agent ))) return True","title":"Simulator"},{"location":"api/simulator/#kamaji.simulation.simulator.Simulator.__init__","text":"Initialize the simulation with optional configuration parameters. Parameters: config ( dict , default: None ) \u2013 Dictionary containing simulation, agent, and logging parameters. Source code in kamaji/simulation/simulator.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 def __init__ ( self , config = None ) -> None : \"\"\" Initialize the simulation with optional configuration parameters. Args: config (dict, optional): Dictionary containing simulation, agent, and logging parameters. \"\"\" self . _config = config self . _current_real_time = time () self . _elapsed_real_time = 0.0 self . sim_time = 0.0 self . active_agents = [] self . inactive_agents = [] self . agent_ids = set () self . verbose = True self . plot = SimulationPlotter ( self ) self . logging_params = config . get ( \"logging\" , {}) if config else {} self . logger = SimulationLogger ( self ) self . cbf_system = None # Will be set later, if needed if config is not None : self . load_from_config ( config ) else : if self . verbose : print ( \"No config provided, using default values.\" )","title":"__init__"},{"location":"api/simulator/#kamaji.simulation.simulator.Simulator.add_agents","text":"Add one or more agents to the simulation. Parameters: agents ( dict | tuple | dict ) \u2013 Dictionary of agents, (config, id) tuple, or a single config. Raises: TypeError \u2013 If format of input is not recognized. Source code in kamaji/simulation/simulator.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 def add_agents ( self , agents ) -> None : \"\"\" Add one or more agents to the simulation. Args: agents (dict | tuple | dict): Dictionary of agents, (config, id) tuple, or a single config. Raises: TypeError: If format of input is not recognized. \"\"\" if isinstance ( agents , dict ): if all ( isinstance ( v , dict ) for v in agents . values ()): for agent_id , agent_config in agents . items (): self . _add_single_agent ( agent_config , agent_id ) else : self . _add_single_agent ( agents ) elif isinstance ( agents , tuple ): if not isinstance ( agents [ 0 ], dict ) or not isinstance ( agents [ 1 ], str ): raise TypeError ( \"Expected (agent_config: dict, agent_id: str)\" ) self . _add_single_agent ( agents [ 0 ], agents [ 1 ]) else : raise TypeError ( \"Expected one of: dict of agents, (config, id) tuple, or single agent config dict.\" )","title":"add_agents"},{"location":"api/simulator/#kamaji.simulation.simulator.Simulator.clear_manual_control","text":"Clear any manually assigned control input for a specific agent. Parameters: agent_id ( str ) \u2013 ID of the agent to clear manual control for. Source code in kamaji/simulation/simulator.py 258 259 260 261 262 263 264 265 266 267 268 def clear_manual_control ( self , agent_id : str ) -> None : \"\"\" Clear any manually assigned control input for a specific agent. Args: agent_id (str): ID of the agent to clear manual control for. \"\"\" for agent in self . active_agents : if agent . _id == agent_id : agent . manual_control_input = None return","title":"clear_manual_control"},{"location":"api/simulator/#kamaji.simulation.simulator.Simulator.load_from_config","text":"Load simulation parameters, agent configuration, environment, and logging settings. Parameters: config ( dict ) \u2013 YAML-style configuration dictionary. Source code in kamaji/simulation/simulator.py 106 107 108 109 110 111 112 113 114 115 116 def load_from_config ( self , config ): \"\"\" Load simulation parameters, agent configuration, environment, and logging settings. Args: config (dict): YAML-style configuration dictionary. \"\"\" self . set_sim_params ( config . get ( 'simulation' , {})) self . add_agents ( config . get ( 'agents' , {})) self . env_params = config . get ( 'environment' , {}) self . logging_params = config . get ( 'logging' , {})","title":"load_from_config"},{"location":"api/simulator/#kamaji.simulation.simulator.Simulator.remove_agent","text":"Remove an agent from the active list and move to the inactive list. Parameters: agent ( Agent ) \u2013 The agent to be removed. Returns: bool ( bool ) \u2013 True if removal was successful. Raises: ValueError \u2013 If the agent is not in the active list. Source code in kamaji/simulation/simulator.py 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 def remove_agent ( self , agent : Agent ) -> bool : \"\"\" Remove an agent from the active list and move to the inactive list. Args: agent (Agent): The agent to be removed. Returns: bool: True if removal was successful. Raises: ValueError: If the agent is not in the active list. \"\"\" if agent not in self . active_agents : raise ValueError ( f \"Agent { agent . id } is not an active Agent.\" ) self . inactive_agents . append ( self . active_agents . pop ( self . active_agents . index ( agent ))) return True","title":"remove_agent"},{"location":"api/simulator/#kamaji.simulation.simulator.Simulator.set_cbf_system","text":"Set an external CBF system to be used during simulation. Parameters: cbf_system ( CBFSystem ) \u2013 A configured CBFSystem instance. Source code in kamaji/simulation/simulator.py 52 53 54 55 56 57 58 59 def set_cbf_system ( self , cbf_system ): \"\"\" Set an external CBF system to be used during simulation. Args: cbf_system (CBFSystem): A configured CBFSystem instance. \"\"\" self . cbf_system = cbf_system","title":"set_cbf_system"},{"location":"api/simulator/#kamaji.simulation.simulator.Simulator.set_manual_control","text":"Manually assign a control input to a specific agent. Parameters: agent_id ( str ) \u2013 ID of the agent. control ( ndarray ) \u2013 Manual control input. Raises: ValueError \u2013 If the agent ID is not found. Source code in kamaji/simulation/simulator.py 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 def set_manual_control ( self , agent_id : str , control : np . ndarray ) -> None : \"\"\" Manually assign a control input to a specific agent. Args: agent_id (str): ID of the agent. control (np.ndarray): Manual control input. Raises: ValueError: If the agent ID is not found. \"\"\" for agent in self . active_agents : if agent . _id == agent_id : agent . manual_control_input = control if self . verbose : print ( f \"[Simulator] Manual control set for agent ' { agent_id } '.\" ) return raise ValueError ( f \"Agent with ID ' { agent_id } ' not found.\" )","title":"set_manual_control"},{"location":"api/simulator/#kamaji.simulation.simulator.Simulator.set_sim_params","text":"Set core simulation parameters such as timestep, duration, and integration method. Parameters: sim_params ( dict , default: None ) \u2013 Dictionary with keys 'time_step', 'duration', and 'integrator'. Raises: ValueError \u2013 If required parameters are missing or invalid. TypeError \u2013 If parameter types are incorrect. Source code in kamaji/simulation/simulator.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 def set_sim_params ( self , sim_params = None ): \"\"\" Set core simulation parameters such as timestep, duration, and integration method. Args: sim_params (dict, optional): Dictionary with keys 'time_step', 'duration', and 'integrator'. Raises: ValueError: If required parameters are missing or invalid. TypeError: If parameter types are incorrect. \"\"\" if sim_params is None : self . dt = 0.01 self . duration = 10.0 self . num_timesteps = int ( self . duration / self . dt ) self . integrator = 'RK4' self . verbose = True return self . verbose = sim_params . get ( 'verbose' , True ) required = [ 'time_step' , 'duration' , 'integrator' ] missing = [ key for key in required if key not in sim_params ] if missing : raise ValueError ( f \"Missing simulation parameters: { missing } \" ) time_step = sim_params [ 'time_step' ] duration = sim_params [ 'duration' ] integrator = sim_params [ 'integrator' ] if not isinstance ( time_step , ( float , int )) or time_step <= 0 : raise ValueError ( \"'time_step' must be a positive number.\" ) if not isinstance ( duration , ( float , int )) or duration <= 0 : raise ValueError ( \"'duration' must be a positive, nonzero number.\" ) if not isinstance ( integrator , str ): raise TypeError ( \"'integrator' must be a string.\" ) valid_integrators = { 'RK4' , 'Euler' , 'RK2' , 'RK45' } if integrator not in valid_integrators : raise ValueError ( f \"Unsupported integrator ' { integrator } '. Valid options: { valid_integrators } \" ) self . dt = float ( time_step ) self . duration = float ( duration ) self . num_timesteps = max ( 1 , int ( self . duration / self . dt )) self . integrator = integrator","title":"set_sim_params"},{"location":"api/simulator/#kamaji.simulation.simulator.Simulator.simulate","text":"Run the simulation loop for all time steps. Parameters: on_step ( Callable [[ Simulator , int ], None] , default: None ) \u2013 Callback executed before each step. Source code in kamaji/simulation/simulator.py 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 def simulate ( self , on_step = None ) -> None : \"\"\" Run the simulation loop for all time steps. Args: on_step (Callable[[Simulator, int], None], optional): Callback executed before each step. \"\"\" start_time = time () iterator = tqdm ( range ( self . num_timesteps ), desc = \"Simulating\" , unit = \"step\" ) if self . verbose else range ( self . num_timesteps ) for step_idx in iterator : if on_step : on_step ( self , step_idx ) self . step () self . sim_time = time () - start_time self . inactive_agents . extend ( self . active_agents ) self . active_agents . clear () if self . logging_params . get ( \"enabled\" , True ): if self . logging_params . get ( \"format\" , \"hdf5\" ) == \"hdf5\" : self . logger . log_to_hdf5 () if self . verbose : print ( f \"Sim time: { self . sim_time : .4f } \" )","title":"simulate"},{"location":"api/simulator/#kamaji.simulation.simulator.Simulator.step","text":"Advance the simulation by one time step, updating agent states using control input. Source code in kamaji/simulation/simulator.py 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 def step ( self ) -> None : \"\"\" Advance the simulation by one time step, updating agent states using control input. \"\"\" state_values = {} all_controls = [] control_dims = [] # 1. Gather state values and nominal control for each agent for idx , agent in enumerate ( self . active_agents ): state_values [ f \"x { idx } \" ] = agent . state [ \"position_x\" ] state_values [ f \"y { idx } \" ] = agent . state [ \"position_y\" ] control = agent . manual_control_input if agent . manual_control_input is not None else agent . compute_control ( self . sim_time ) all_controls . append ( control ) control_dims . append ( len ( control )) u_nom = np . concatenate ( all_controls ) # 2. Filter full control vector using CBF system if available if self . cbf_system is not None : u_filtered = self . cbf_system . filter_controls ( state_values , u_nom , mode = \"all\" ) else : u_filtered = u_nom # 3. Slice filtered controls back to each agent and step them idx = 0 for agent , dim in zip ( self . active_agents , control_dims ): agent_control = u_filtered [ idx : idx + dim ] agent . step ( self . sim_time , agent_control ) idx += dim","title":"step"},{"location":"concepts/agents/","text":"Agent API Explain the Agent interface and how to register callbacks.","title":"Agents"},{"location":"concepts/agents/#agent-api","text":"Explain the Agent interface and how to register callbacks.","title":"Agent API"},{"location":"concepts/configuration/","text":"Configuration Guide Kamaji supports YAML-based configuration files to define agents, environments, and simulation parameters. Structure A basic configuration file ( config.yaml ) may include: simulation : total_time : 20.0 dt : 0.1 agents : - id : agent1 dynamics_model : \"Unicycle\" initial_state : position_x : 0.0 position_y : 0.0 controller : velocity_x : type : \"PID\" specs : - state : position_x goal : 10.0 kp : 1.0 ki : 0.0 kd : 0.1 Key Fields dynamics_model : Must match a class from kamaji.dynamics controller.type : \"Constant\" or \"PID\" initial_state : Keys must match what the model expects You can load and run YAML configs with custom entry scripts or GUI tools.","title":"Configuration Files"},{"location":"concepts/configuration/#configuration-guide","text":"Kamaji supports YAML-based configuration files to define agents, environments, and simulation parameters.","title":"Configuration Guide"},{"location":"concepts/configuration/#structure","text":"A basic configuration file ( config.yaml ) may include: simulation : total_time : 20.0 dt : 0.1 agents : - id : agent1 dynamics_model : \"Unicycle\" initial_state : position_x : 0.0 position_y : 0.0 controller : velocity_x : type : \"PID\" specs : - state : position_x goal : 10.0 kp : 1.0 ki : 0.0 kd : 0.1","title":"Structure"},{"location":"concepts/configuration/#key-fields","text":"dynamics_model : Must match a class from kamaji.dynamics controller.type : \"Constant\" or \"PID\" initial_state : Keys must match what the model expects You can load and run YAML configs with custom entry scripts or GUI tools.","title":"Key Fields"},{"location":"concepts/controls/","text":"","title":"Controls"},{"location":"concepts/dynamics/","text":"","title":"Dynamics"},{"location":"concepts/environment/","text":"Environment Module Describe the core simulation loop and Environment API.","title":"Environment Module"},{"location":"concepts/environment/#environment-module","text":"Describe the core simulation loop and Environment API.","title":"Environment Module"},{"location":"concepts/simulator/","text":"","title":"Simulator"},{"location":"examples/CBF/","text":"CBF Example Placeholder text. Scenario Setup Agent Definitions Nominal Controls","title":"CBF Example"},{"location":"examples/CBF/#cbf-example","text":"Placeholder text.","title":"CBF Example"},{"location":"examples/CBF/#scenario-setup","text":"","title":"Scenario Setup"},{"location":"examples/CBF/#agent-definitions","text":"","title":"Agent Definitions"},{"location":"examples/CBF/#nominal-controls","text":"","title":"Nominal Controls"},{"location":"examples/auction/","text":"Auction Example Placeholder text. Scenario Setup Agent Definitions","title":"Auction Example"},{"location":"examples/auction/#auction-example","text":"Placeholder text.","title":"Auction Example"},{"location":"examples/auction/#scenario-setup","text":"","title":"Scenario Setup"},{"location":"examples/auction/#agent-definitions","text":"","title":"Agent Definitions"},{"location":"examples/sequential/","text":"Sequential Example Placeholder text. Scenario Setup Agent Definitions Nominal Controls","title":"Sequential Example"},{"location":"examples/sequential/#sequential-example","text":"Placeholder text.","title":"Sequential Example"},{"location":"examples/sequential/#scenario-setup","text":"","title":"Scenario Setup"},{"location":"examples/sequential/#agent-definitions","text":"","title":"Agent Definitions"},{"location":"examples/sequential/#nominal-controls","text":"","title":"Nominal Controls"},{"location":"started/examples/","text":"Examples Kamaji includes several examples to showcase key features and use cases. Basic Simulation File : examples/basic_simulation.py Simulates multiple agents with simple dynamics in a 2D space. PID-Controlled Navigation File : examples/pid_controller_demo.py Shows how PID controllers can be used to follow a trajectory. Auction-Based Collision Avoidance File : examples/auction_based_cbf.py Demonstrates multi-agent safety enforcement via auction-based allocation of control effort. Urban Air Mobility Scenario (3D) File : examples/uam_formation.py Simulates a UAM scenario with 3D coordinated agents using geometric controllers. Symbolic CBF-Based Collision Avoidance File : examples/cbf_simulation.py Uses a symbolic Control Barrier Function (CBF) system to enforce pairwise collision avoidance between agents based on a minimum separation distance. Agents are defined through a YAML configuration, and the CBF constraints are applied via a runtime-constructed symbolic filter. This simulation uses the example YAML file examples\\configs\\cbf_simulation.yml . Key Steps Define symbolic CBFs between all agent pairs using make_cbf_system() Load the YAML configuration to initialize agents and their controllers Inject the CBF system using sim.set_cbf_system(...) Run the simulation and visualize trajectories with guaranteed minimum separation How make_cbf_system() Works The make_cbf_system() function constructs a symbolic representation of pairwise separation constraints between agents using SymPy. The constraints are shaped like: \\[ h_{ij}(x) = \\lVert p_i - p_j \\rVert^2 - r^2 \\] This ensures each pair of agents maintains a distance of at least r . Breakdown Step Purpose 1. Symbol Assignment Creates symbolic position variables \\(x_i, y_i\\) for each agent 2. Global Dynamics Setup Constructs zero drift f and identity matrix g assuming single-integrator agents 3. Pairwise CBF Creation Defines one constraint \\(h_{ij}\\) for each agent pair using Euclidean distance 4. Matrix Slicing Extracts the relevant rows from f and g for each CBF 5. CBFSystem Population Adds each symbolic CBF to the system with cbf_sys.add_cbf(...) Highlight: Symbolic CBF Definition h = ( xi - xj ) ** 2 + ( yi - yj ) ** 2 - radius ** 2 cbf_sys . add_cbf ( cbf_id = f \"cbf_ { agent_i . _id } _ { agent_j . _id } \" , agents = [ agent_i . _id , agent_j . _id ], state_vars = [ xi , yi , xj , yj ], h_expr = h , f_expr = f_sub , g_expr = g_sub , alpha_func = lambda h : 2.0 * h ) Visualization Many examples support real-time visualization via matplotlib or the PyQt GUI: python kamaji/gui/gui_main.py","title":"Examples"},{"location":"started/examples/#examples","text":"Kamaji includes several examples to showcase key features and use cases.","title":"Examples"},{"location":"started/examples/#basic-simulation","text":"File : examples/basic_simulation.py Simulates multiple agents with simple dynamics in a 2D space.","title":"Basic Simulation"},{"location":"started/examples/#pid-controlled-navigation","text":"File : examples/pid_controller_demo.py Shows how PID controllers can be used to follow a trajectory.","title":"PID-Controlled Navigation"},{"location":"started/examples/#auction-based-collision-avoidance","text":"File : examples/auction_based_cbf.py Demonstrates multi-agent safety enforcement via auction-based allocation of control effort.","title":"Auction-Based Collision Avoidance"},{"location":"started/examples/#urban-air-mobility-scenario-3d","text":"File : examples/uam_formation.py Simulates a UAM scenario with 3D coordinated agents using geometric controllers.","title":"Urban Air Mobility Scenario (3D)"},{"location":"started/examples/#symbolic-cbf-based-collision-avoidance","text":"File : examples/cbf_simulation.py Uses a symbolic Control Barrier Function (CBF) system to enforce pairwise collision avoidance between agents based on a minimum separation distance. Agents are defined through a YAML configuration, and the CBF constraints are applied via a runtime-constructed symbolic filter. This simulation uses the example YAML file examples\\configs\\cbf_simulation.yml .","title":"Symbolic CBF-Based Collision Avoidance"},{"location":"started/examples/#key-steps","text":"Define symbolic CBFs between all agent pairs using make_cbf_system() Load the YAML configuration to initialize agents and their controllers Inject the CBF system using sim.set_cbf_system(...) Run the simulation and visualize trajectories with guaranteed minimum separation","title":"Key Steps"},{"location":"started/examples/#how-make_cbf_system-works","text":"The make_cbf_system() function constructs a symbolic representation of pairwise separation constraints between agents using SymPy. The constraints are shaped like: \\[ h_{ij}(x) = \\lVert p_i - p_j \\rVert^2 - r^2 \\] This ensures each pair of agents maintains a distance of at least r .","title":"How make_cbf_system() Works"},{"location":"started/examples/#breakdown","text":"Step Purpose 1. Symbol Assignment Creates symbolic position variables \\(x_i, y_i\\) for each agent 2. Global Dynamics Setup Constructs zero drift f and identity matrix g assuming single-integrator agents 3. Pairwise CBF Creation Defines one constraint \\(h_{ij}\\) for each agent pair using Euclidean distance 4. Matrix Slicing Extracts the relevant rows from f and g for each CBF 5. CBFSystem Population Adds each symbolic CBF to the system with cbf_sys.add_cbf(...)","title":"Breakdown"},{"location":"started/examples/#highlight-symbolic-cbf-definition","text":"h = ( xi - xj ) ** 2 + ( yi - yj ) ** 2 - radius ** 2 cbf_sys . add_cbf ( cbf_id = f \"cbf_ { agent_i . _id } _ { agent_j . _id } \" , agents = [ agent_i . _id , agent_j . _id ], state_vars = [ xi , yi , xj , yj ], h_expr = h , f_expr = f_sub , g_expr = g_sub , alpha_func = lambda h : 2.0 * h )","title":"Highlight: Symbolic CBF Definition"},{"location":"started/examples/#visualization","text":"Many examples support real-time visualization via matplotlib or the PyQt GUI: python kamaji/gui/gui_main.py","title":"Visualization"},{"location":"started/installation/","text":"Installation Guide Prerequisites Conda : Install Miniconda or Anaconda . Python 3.8+ : Kamaji requires Python 3.8 or newer. Step 1: Clone the Repository git clone https://github.com/JCorbin406/Kamaji.git cd Kamaji Step 2: Create the Conda Environment Kamaji includes an environment.yml file for easy setup. 2.1 Create the Environment conda env create -f environment.yml This creates a new Conda environment (typically named kamaji ) with all dependencies. 2.2 Activate the Environment conda activate kamaji On Windows, use Anaconda Prompt or install Git Bash for bash-style commands. Step 3: Install the Kamaji Package If you're doing development or want editable access: pip install -e . This ensures that local changes are immediately reflected when using the package. To install additional packages: conda install <package> # or pip install <package> Step 4: Verify Installation You can check that Kamaji is installed by running: python -c \"import kamaji; print(kamaji.__version__)\" If successful, you'll see the version number printed. Step 5: Running Kamaji To launch the GUI: python kamaji/gui/gui_main.py Or run a headless script: python examples/basic_simulation.py (Coming soon: More examples and CLI tools.) Step 6: Deactivate the Environment conda deactivate Step 7: Updating the Environment To sync the environment with any changes in environment.yml : conda env update -f environment.yml --prune The --prune option removes packages not listed in the file. Development Want to contribute? Fork the repo and open a pull request with: Clear, documented changes Unit tests (if applicable) A brief description in the PR Kamaji adheres to standard Python code style (PEP8). Contributions are welcome! License Kamaji is released under the MIT License .","title":"Installation"},{"location":"started/installation/#installation-guide","text":"","title":"Installation Guide"},{"location":"started/installation/#prerequisites","text":"Conda : Install Miniconda or Anaconda . Python 3.8+ : Kamaji requires Python 3.8 or newer.","title":"Prerequisites"},{"location":"started/installation/#step-1-clone-the-repository","text":"git clone https://github.com/JCorbin406/Kamaji.git cd Kamaji","title":"Step 1: Clone the Repository"},{"location":"started/installation/#step-2-create-the-conda-environment","text":"Kamaji includes an environment.yml file for easy setup.","title":"Step 2: Create the Conda Environment"},{"location":"started/installation/#21-create-the-environment","text":"conda env create -f environment.yml This creates a new Conda environment (typically named kamaji ) with all dependencies.","title":"2.1 Create the Environment"},{"location":"started/installation/#22-activate-the-environment","text":"conda activate kamaji On Windows, use Anaconda Prompt or install Git Bash for bash-style commands.","title":"2.2 Activate the Environment"},{"location":"started/installation/#step-3-install-the-kamaji-package","text":"If you're doing development or want editable access: pip install -e . This ensures that local changes are immediately reflected when using the package. To install additional packages: conda install <package> # or pip install <package>","title":"Step 3: Install the Kamaji Package"},{"location":"started/installation/#step-4-verify-installation","text":"You can check that Kamaji is installed by running: python -c \"import kamaji; print(kamaji.__version__)\" If successful, you'll see the version number printed.","title":"Step 4: Verify Installation"},{"location":"started/installation/#step-5-running-kamaji","text":"To launch the GUI: python kamaji/gui/gui_main.py Or run a headless script: python examples/basic_simulation.py (Coming soon: More examples and CLI tools.)","title":"Step 5: Running Kamaji"},{"location":"started/installation/#step-6-deactivate-the-environment","text":"conda deactivate","title":"Step 6: Deactivate the Environment"},{"location":"started/installation/#step-7-updating-the-environment","text":"To sync the environment with any changes in environment.yml : conda env update -f environment.yml --prune The --prune option removes packages not listed in the file.","title":"Step 7: Updating the Environment"},{"location":"started/installation/#development","text":"Want to contribute? Fork the repo and open a pull request with: Clear, documented changes Unit tests (if applicable) A brief description in the PR Kamaji adheres to standard Python code style (PEP8). Contributions are welcome!","title":"Development"},{"location":"started/installation/#license","text":"Kamaji is released under the MIT License .","title":"License"},{"location":"started/quickstart/","text":"Quickstart Welcome to Kamaji! This guide will help you run your first multi-agent simulation in just a few steps. Run Your First Simulation After installing Kamaji and activating your environment, try this: python examples/basic_simulation.py This runs a basic simulation with several agents navigating a 2D environment using default dynamics and controllers. What It Does Initializes a simulator instance Spawns agents with default dynamics and goals Runs a time-stepped simulation Logs trajectories and optionally visualizes them Relevant Files examples/basic_simulation.py : Script to launch the simulation kamaji/simulation/simulator.py : Main simulator engine kamaji/agent/agent.py : Defines agent behavior and integration kamaji/controllers/ : Available control models (e.g. PID, CBF) For more customization, see the Configuration Guide .","title":"Quickstart"},{"location":"started/quickstart/#quickstart","text":"Welcome to Kamaji! This guide will help you run your first multi-agent simulation in just a few steps.","title":"Quickstart"},{"location":"started/quickstart/#run-your-first-simulation","text":"After installing Kamaji and activating your environment, try this: python examples/basic_simulation.py This runs a basic simulation with several agents navigating a 2D environment using default dynamics and controllers.","title":"Run Your First Simulation"},{"location":"started/quickstart/#what-it-does","text":"Initializes a simulator instance Spawns agents with default dynamics and goals Runs a time-stepped simulation Logs trajectories and optionally visualizes them","title":"What It Does"},{"location":"started/quickstart/#relevant-files","text":"examples/basic_simulation.py : Script to launch the simulation kamaji/simulation/simulator.py : Main simulator engine kamaji/agent/agent.py : Defines agent behavior and integration kamaji/controllers/ : Available control models (e.g. PID, CBF) For more customization, see the Configuration Guide .","title":"Relevant Files"}]}